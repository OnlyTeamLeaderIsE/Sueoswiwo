{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "version = '1.0.0'\n",
    "check_data_version = '1.0.3'\n",
    "\n",
    "\n",
    "with open(f'../create_dataset/v{check_data_version}/label.json', 'r', encoding='utf-8') as file:\n",
    "    label = json.load(file)\n",
    "    \n",
    "word_count = label['label_count'] * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 10, 51)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'../create_dataset/v{check_data_version}/data'\n",
    "data_files_list = os.listdir(data_dir)\n",
    "\n",
    "\n",
    "data_files_list.sort()\n",
    "\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load(f'{data_dir}/{file}') for file in data_files_list\n",
    "], axis=0)\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7886, 10, 50)\n",
      "(7886,)\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 6.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 8.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 10.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 12.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 14.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0 16.0\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(*labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 17)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=word_count)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7097, 10, 50) (7097, 17)\n",
      "(789, 10, 50) (789, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "time_stamp = 1\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 64)                29440     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_7 (Dense)             (None, 17)                561       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32081 (125.32 KB)\n",
      "Trainable params: 32081 (125.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3], return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(word_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_version = check_data_version.replace('.', '')\n",
    "version = version.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 34.8017 - acc: 0.2869\n",
      "Epoch 1: val_acc improved from -inf to 0.61090, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 2s 4ms/step - loss: 31.6413 - acc: 0.3194 - val_loss: 2.0242 - val_acc: 0.6109 - lr: 0.0010\n",
      "Epoch 2/200\n",
      " 59/222 [======>.......................] - ETA: 0s - loss: 1.3754 - acc: 0.7076"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/222 [==========================>...] - ETA: 0s - loss: 1.0166 - acc: 0.7656\n",
      "Epoch 2: val_acc improved from 0.61090 to 0.80228, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.9793 - acc: 0.7717 - val_loss: 0.7121 - val_acc: 0.8023 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 1.3266 - acc: 0.7576\n",
      "Epoch 3: val_acc improved from 0.80228 to 0.83904, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2905 - acc: 0.7609 - val_loss: 0.6256 - val_acc: 0.8390 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 0.5382 - acc: 0.8934\n",
      "Epoch 4: val_acc improved from 0.83904 to 0.96578, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.5103 - acc: 0.8981 - val_loss: 0.1749 - val_acc: 0.9658 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9712\n",
      "Epoch 5: val_acc did not improve from 0.96578\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1342 - acc: 0.9697 - val_loss: 0.1766 - val_acc: 0.9518 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9815\n",
      "Epoch 6: val_acc improved from 0.96578 to 0.98352, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0716 - acc: 0.9820 - val_loss: 0.0619 - val_acc: 0.9835 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 0.0413 - acc: 0.9894\n",
      "Epoch 7: val_acc improved from 0.98352 to 0.99240, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0399 - acc: 0.9897 - val_loss: 0.0288 - val_acc: 0.9924 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 0.0387 - acc: 0.9896\n",
      "Epoch 8: val_acc did not improve from 0.99240\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0377 - acc: 0.9899 - val_loss: 0.0377 - val_acc: 0.9835 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9927\n",
      "Epoch 9: val_acc did not improve from 0.99240\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0223 - acc: 0.9925 - val_loss: 0.0253 - val_acc: 0.9924 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9958\n",
      "Epoch 10: val_acc did not improve from 0.99240\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0191 - acc: 0.9958 - val_loss: 0.0167 - val_acc: 0.9924 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "199/222 [=========================>....] - ETA: 0s - loss: 0.0260 - acc: 0.9917\n",
      "Epoch 11: val_acc improved from 0.99240 to 0.99620, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0161 - val_acc: 0.9962 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 0.0089 - acc: 0.9970\n",
      "Epoch 12: val_acc did not improve from 0.99620\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0094 - val_acc: 0.9949 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 0.4711 - acc: 0.9553\n",
      "Epoch 13: val_acc did not improve from 0.99620\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.7230 - acc: 0.9355 - val_loss: 2.9408 - val_acc: 0.6375 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.1180 - acc: 0.7494\n",
      "Epoch 14: val_acc did not improve from 0.99620\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0811 - acc: 0.7565 - val_loss: 0.4257 - val_acc: 0.9075 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "199/222 [=========================>....] - ETA: 0s - loss: 0.3748 - acc: 0.8997\n",
      "Epoch 15: val_acc did not improve from 0.99620\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.3546 - acc: 0.9046 - val_loss: 0.2167 - val_acc: 0.9278 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9541\n",
      "Epoch 16: val_acc did not improve from 0.99620\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1016 - acc: 0.9539 - val_loss: 0.0864 - val_acc: 0.9556 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9897\n",
      "Epoch 17: val_acc improved from 0.99620 to 0.99747, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0431 - acc: 0.9900 - val_loss: 0.0144 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 0.0123 - acc: 0.9980\n",
      "Epoch 18: val_acc improved from 0.99747 to 1.00000, saving model to ../models\\data_103_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0123 - acc: 0.9980 - val_loss: 0.0064 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 0.0055 - acc: 0.9999\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0055 - acc: 0.9999 - val_loss: 0.0053 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0033 - acc: 0.9996 - val_loss: 0.0021 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0038 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 9.2539e-04 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.3804e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 7.1435e-04 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.1839e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 5.7548e-04 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.6913e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 4.6615e-04 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.7236e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.9795e-04 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9795e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0025 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.0779e-04 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.4559e-04 - acc: 0.9999 - val_loss: 0.0315 - val_acc: 0.9886 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 0.1791 - acc: 0.9652\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1638 - acc: 0.9682 - val_loss: 0.0052 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9988\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0019 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 7.4358e-04 - acc: 0.9999\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.4358e-04 - acc: 0.9999 - val_loss: 0.0039 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 3.0054e-04 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9774e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.6909e-04 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6887e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.3354e-04 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3233e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.0970e-04 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0773e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 9.2251e-05 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.2117e-05 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 7.8973e-05 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.7705e-05 - acc: 1.0000 - val_loss: 9.9212e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 6.5975e-05 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.6563e-05 - acc: 1.0000 - val_loss: 8.8368e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 5.8243e-05 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7842e-05 - acc: 1.0000 - val_loss: 8.3769e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 5.0856e-05 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.0782e-05 - acc: 1.0000 - val_loss: 7.1530e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 4.4544e-05 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.4840e-05 - acc: 1.0000 - val_loss: 7.1780e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 4.0603e-05 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.0481e-05 - acc: 1.0000 - val_loss: 6.5326e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 3.5062e-05 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.5190e-05 - acc: 1.0000 - val_loss: 5.7946e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 3.1217e-05 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.0998e-05 - acc: 1.0000 - val_loss: 5.2178e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 2.7438e-05 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.7553e-05 - acc: 1.0000 - val_loss: 5.2734e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 2.4606e-05 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.4815e-05 - acc: 1.0000 - val_loss: 5.4967e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 2.2003e-05 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2003e-05 - acc: 1.0000 - val_loss: 5.2295e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 1.9140e-05 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9547e-05 - acc: 1.0000 - val_loss: 5.1496e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.7778e-05 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7308e-05 - acc: 1.0000 - val_loss: 4.9509e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 1.5586e-05 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5545e-05 - acc: 1.0000 - val_loss: 5.0737e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.4034e-05 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3816e-05 - acc: 1.0000 - val_loss: 5.1440e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.2143e-05 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2348e-05 - acc: 1.0000 - val_loss: 5.3390e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 1.1013e-05 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1062e-05 - acc: 1.0000 - val_loss: 5.5892e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 1.0036e-05 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.9465e-06 - acc: 1.0000 - val_loss: 5.6924e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 9.0578e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.9810e-06 - acc: 1.0000 - val_loss: 5.8213e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 8.0500e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.0591e-06 - acc: 1.0000 - val_loss: 6.0803e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 7.4372e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.3716e-06 - acc: 1.0000 - val_loss: 6.1758e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 6.6116e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.6883e-06 - acc: 1.0000 - val_loss: 6.4104e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 5.6919e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7888e-06 - acc: 1.0000 - val_loss: 5.8089e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 5.4963e-06 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.3940e-06 - acc: 1.0000 - val_loss: 6.1117e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 4.9350e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.9101e-06 - acc: 1.0000 - val_loss: 5.8386e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 4.1195e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.3136e-06 - acc: 1.0000 - val_loss: 5.7653e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 3.7801e-06 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.7610e-06 - acc: 1.0000 - val_loss: 5.9568e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.3710e-06 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.3710e-06 - acc: 1.0000 - val_loss: 5.6786e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.0489e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.0489e-06 - acc: 1.0000 - val_loss: 5.5935e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 2.6707e-06 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.7417e-06 - acc: 1.0000 - val_loss: 5.4340e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 3.2205e-06 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.2089e-06 - acc: 1.0000 - val_loss: 5.1106e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 2.3437e-06 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3288e-06 - acc: 1.0000 - val_loss: 5.3093e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 2.1376e-06 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.1239e-06 - acc: 1.0000 - val_loss: 5.3425e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.9978e-06 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9973e-06 - acc: 1.0000 - val_loss: 5.3052e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 1.8693e-06 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.8744e-06 - acc: 1.0000 - val_loss: 5.3151e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 1.7620e-06 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7567e-06 - acc: 1.0000 - val_loss: 5.1786e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.6259e-06 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6386e-06 - acc: 1.0000 - val_loss: 5.1251e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.5238e-06 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5149e-06 - acc: 1.0000 - val_loss: 5.0097e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 1.4303e-06 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4158e-06 - acc: 1.0000 - val_loss: 4.9827e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.3101e-06 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3025e-06 - acc: 1.0000 - val_loss: 4.7371e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 1.2048e-06 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2146e-06 - acc: 1.0000 - val_loss: 4.5926e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.1197e-06 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1207e-06 - acc: 1.0000 - val_loss: 4.4164e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 1.0128e-06 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0152e-06 - acc: 1.0000 - val_loss: 4.4040e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 9.3538e-07 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.2818e-07 - acc: 1.0000 - val_loss: 4.1648e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 8.3752e-07 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.4401e-07 - acc: 1.0000 - val_loss: 3.9705e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 7.7138e-07 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.6598e-07 - acc: 1.0000 - val_loss: 4.0496e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 6.8467e-07 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.0099e-07 - acc: 1.0000 - val_loss: 3.8782e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 6.1553e-07 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.3325e-07 - acc: 1.0000 - val_loss: 3.7711e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 5.7716e-07 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7291e-07 - acc: 1.0000 - val_loss: 3.7809e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 5.1455e-07 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.1760e-07 - acc: 1.0000 - val_loss: 3.5306e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 4.6300e-07 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.6760e-07 - acc: 1.0000 - val_loss: 3.4688e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 4.3346e-07 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.2706e-07 - acc: 1.0000 - val_loss: 3.3336e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 3.8657e-07 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.8663e-07 - acc: 1.0000 - val_loss: 3.2739e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 3.4504e-07 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.4612e-07 - acc: 1.0000 - val_loss: 3.0113e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 3.1258e-07 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.1187e-07 - acc: 1.0000 - val_loss: 2.8861e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 2.9299e-07 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8429e-07 - acc: 1.0000 - val_loss: 2.9459e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 2.4651e-07 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5427e-07 - acc: 1.0000 - val_loss: 3.0437e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 2.3153e-07 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3203e-07 - acc: 1.0000 - val_loss: 3.0002e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9766   \n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2384 - acc: 0.9748 - val_loss: 4.4437 - val_acc: 0.7744 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 0.3613 - acc: 0.9447\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.3332 - acc: 0.9489 - val_loss: 0.0225 - val_acc: 0.9975 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 0.0036 - acc: 0.9994\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0016 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 9.0291e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 8.2904e-04 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.1353e-04 - acc: 1.0000 - val_loss: 6.6372e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 5.7531e-04 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7531e-04 - acc: 1.0000 - val_loss: 5.0333e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 4.4196e-04 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.4243e-04 - acc: 1.0000 - val_loss: 4.1692e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 3.5413e-04 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.4708e-04 - acc: 1.0000 - val_loss: 3.4383e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 2.8317e-04 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8224e-04 - acc: 1.0000 - val_loss: 2.9269e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 2.3530e-04 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3591e-04 - acc: 1.0000 - val_loss: 2.4298e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.9376e-04 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9365e-04 - acc: 1.0000 - val_loss: 2.0336e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.7679e-04 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7098e-04 - acc: 1.0000 - val_loss: 1.8814e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 1.4808e-04 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4111e-04 - acc: 1.0000 - val_loss: 1.6792e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 1.1850e-04 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1764e-04 - acc: 1.0000 - val_loss: 1.4744e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 1.0444e-04 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0298e-04 - acc: 1.0000 - val_loss: 1.2847e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 9.0299e-05 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.0299e-05 - acc: 1.0000 - val_loss: 1.1948e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 8.0453e-05 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.8845e-05 - acc: 1.0000 - val_loss: 1.0452e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 6.8555e-05 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.7957e-05 - acc: 1.0000 - val_loss: 1.0532e-04 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 6.0320e-05 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.0320e-05 - acc: 1.0000 - val_loss: 8.6552e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 5.3494e-05 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.3350e-05 - acc: 1.0000 - val_loss: 7.2136e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 4.6181e-05 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.6404e-05 - acc: 1.0000 - val_loss: 6.8863e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 4.2178e-05 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.1114e-05 - acc: 1.0000 - val_loss: 5.7437e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 3.7298e-05 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.6954e-05 - acc: 1.0000 - val_loss: 5.2080e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 4.2533e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 3.5051e-04 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.5111e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 2.9860e-04 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9094e-04 - acc: 1.0000 - val_loss: 1.0887e-04 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.3211e-04 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3051e-04 - acc: 1.0000 - val_loss: 7.8696e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 9.7797e-05 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.9175e-05 - acc: 1.0000 - val_loss: 7.7860e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 8.5654e-05 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.2393e-05 - acc: 1.0000 - val_loss: 5.2379e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 6.4565e-05 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.6133e-05 - acc: 1.0000 - val_loss: 4.2368e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 5.3543e-05 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.4309e-05 - acc: 1.0000 - val_loss: 3.7254e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 4.6068e-05 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5743e-05 - acc: 1.0000 - val_loss: 3.0408e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 3.8382e-05 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.8463e-05 - acc: 1.0000 - val_loss: 2.7682e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "199/222 [=========================>....] - ETA: 0s - loss: 3.3071e-05 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.2909e-05 - acc: 1.0000 - val_loss: 2.2456e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "199/222 [=========================>....] - ETA: 0s - loss: 2.8176e-05 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8326e-05 - acc: 1.0000 - val_loss: 1.9253e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 2.4868e-05 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.4339e-05 - acc: 1.0000 - val_loss: 1.6529e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "198/222 [=========================>....] - ETA: 0s - loss: 2.0836e-05 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0661e-05 - acc: 1.0000 - val_loss: 1.4619e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 1.7979e-05 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7736e-05 - acc: 1.0000 - val_loss: 1.2887e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.6012e-05 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5986e-05 - acc: 1.0000 - val_loss: 1.1355e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.3989e-05 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3989e-05 - acc: 1.0000 - val_loss: 9.9704e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 1.2463e-05 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2254e-05 - acc: 1.0000 - val_loss: 8.8894e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.0924e-05 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0774e-05 - acc: 1.0000 - val_loss: 8.3324e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 9.2403e-06 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.2526e-06 - acc: 1.0000 - val_loss: 7.0562e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "198/222 [=========================>....] - ETA: 0s - loss: 8.2950e-06 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.1749e-06 - acc: 1.0000 - val_loss: 6.3004e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 7.2204e-06 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.2204e-06 - acc: 1.0000 - val_loss: 5.4253e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 6.2039e-06 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.3627e-06 - acc: 1.0000 - val_loss: 4.8225e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 5.4876e-06 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.6129e-06 - acc: 1.0000 - val_loss: 4.2600e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 4.8134e-06 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.9564e-06 - acc: 1.0000 - val_loss: 3.7560e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 4.4777e-06 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.4146e-06 - acc: 1.0000 - val_loss: 3.2076e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 3.9627e-06 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.8872e-06 - acc: 1.0000 - val_loss: 4.1342e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 3.4879e-06 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.4674e-06 - acc: 1.0000 - val_loss: 3.4395e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 2.9964e-06 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9899e-06 - acc: 1.0000 - val_loss: 3.1143e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 2.6776e-06 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.6635e-06 - acc: 1.0000 - val_loss: 2.6745e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 2.3650e-06 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3650e-06 - acc: 1.0000 - val_loss: 2.0130e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 2.1060e-06 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0902e-06 - acc: 1.0000 - val_loss: 1.7567e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 1.8930e-06 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.8740e-06 - acc: 1.0000 - val_loss: 1.6314e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.6752e-06 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6647e-06 - acc: 1.0000 - val_loss: 1.4829e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 1.5056e-06 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4748e-06 - acc: 1.0000 - val_loss: 1.3371e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "197/222 [=========================>....] - ETA: 0s - loss: 1.3042e-06 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3288e-06 - acc: 1.0000 - val_loss: 1.4398e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.2040e-06 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1724e-06 - acc: 1.0000 - val_loss: 1.4917e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 1.0518e-06 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0464e-06 - acc: 1.0000 - val_loss: 8.5803e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 9.5579e-07 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.3224e-07 - acc: 1.0000 - val_loss: 7.9230e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 7.9139e-07 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.2445e-07 - acc: 1.0000 - val_loss: 7.1072e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 7.4104e-07 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.3291e-07 - acc: 1.0000 - val_loss: 6.2520e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 6.4807e-07 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.4893e-07 - acc: 1.0000 - val_loss: 5.6265e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 5.8522e-07 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.8062e-07 - acc: 1.0000 - val_loss: 4.8681e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 5.1612e-07 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.1295e-07 - acc: 1.0000 - val_loss: 4.4919e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 4.6347e-07 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5701e-07 - acc: 1.0000 - val_loss: 3.9479e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "196/222 [=========================>....] - ETA: 0s - loss: 4.1822e-07 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.0103e-07 - acc: 1.0000 - val_loss: 3.5370e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 1.2218e-06 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2322e-06 - acc: 1.0000 - val_loss: 7.2477e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 166/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 1.0292e-06 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0226e-06 - acc: 1.0000 - val_loss: 3.7500e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 167/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 3.5625e-07 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.5474e-07 - acc: 1.0000 - val_loss: 2.6456e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 168/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 2.7611e-07 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 168: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8629e-07 - acc: 1.0000 - val_loss: 2.2089e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 169/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 2.5103e-07 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.4823e-07 - acc: 1.0000 - val_loss: 1.9732e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 2.2541e-07 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2701e-07 - acc: 1.0000 - val_loss: 1.8085e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 2.1073e-07 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0949e-07 - acc: 1.0000 - val_loss: 1.6695e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "198/222 [=========================>....] - ETA: 0s - loss: 1.9896e-07 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9189e-07 - acc: 1.0000 - val_loss: 1.5728e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.7543e-07 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7486e-07 - acc: 1.0000 - val_loss: 1.4369e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 1.6194e-07 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5929e-07 - acc: 1.0000 - val_loss: 1.3266e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.4512e-07 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4605e-07 - acc: 1.0000 - val_loss: 1.2284e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.3454e-07 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3303e-07 - acc: 1.0000 - val_loss: 1.1513e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 1.2221e-07 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2200e-07 - acc: 1.0000 - val_loss: 1.0440e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "201/222 [==========================>...] - ETA: 0s - loss: 1.1626e-07 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1167e-07 - acc: 1.0000 - val_loss: 9.6093e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.0203e-07 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0186e-07 - acc: 1.0000 - val_loss: 8.9142e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 9.2102e-08 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.2602e-08 - acc: 1.0000 - val_loss: 8.2646e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 8.4508e-08 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.3935e-08 - acc: 1.0000 - val_loss: 7.6451e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 7.8266e-08 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.7233e-08 - acc: 1.0000 - val_loss: 7.0407e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 6.9421e-08 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.0246e-08 - acc: 1.0000 - val_loss: 6.6026e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 6.3991e-08 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.3745e-08 - acc: 1.0000 - val_loss: 6.1040e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 5.7481e-08 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7900e-08 - acc: 1.0000 - val_loss: 5.6658e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 5.2324e-08 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.3264e-08 - acc: 1.0000 - val_loss: 5.3183e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 4.9041e-08 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.7754e-08 - acc: 1.0000 - val_loss: 4.8651e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 4.3736e-08 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.3404e-08 - acc: 1.0000 - val_loss: 4.5780e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 3.9464e-08 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9960e-08 - acc: 1.0000 - val_loss: 4.2909e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 3.5243e-08 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.6198e-08 - acc: 1.0000 - val_loss: 4.0945e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 3.2184e-08 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.3006e-08 - acc: 1.0000 - val_loss: 3.8377e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 2.9120e-08 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9983e-08 - acc: 1.0000 - val_loss: 3.7017e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 2.8103e-08 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8034e-08 - acc: 1.0000 - val_loss: 3.4146e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 2.5688e-08 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5582e-08 - acc: 1.0000 - val_loss: 3.3240e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 2.4004e-08 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3970e-08 - acc: 1.0000 - val_loss: 2.9916e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 2.2044e-08 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.1920e-08 - acc: 1.0000 - val_loss: 2.9009e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 2.0786e-08 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0526e-08 - acc: 1.0000 - val_loss: 2.8254e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.9242e-08 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9266e-08 - acc: 1.0000 - val_loss: 2.5836e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.7906e-08 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7906e-08 - acc: 1.0000 - val_loss: 2.4627e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.7379e-08 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7251e-08 - acc: 1.0000 - val_loss: 2.3117e-08 - val_acc: 1.0000 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(f'../models/data_{check_data_version}_train_{version}_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABU4AAANBCAYAAAA/QyQXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC3bklEQVR4nOzdeXxU9dn///eZmcwkZIMQSNh3UQRRURCxriiK2lq5W23vquWuWhXqgr9qaV1abcXlVvFuUdveLl20tbVW76qltSj6rYILiLIoiigokLAnJCQzmZnz++PkzEySyTaZZDLnvJ6Pxzwyc+bMmc8Y2pA313V9DNM0TQEAAAAAAAAAYjyZXgAAAAAAAAAA9DYEpwAAAAAAAADQDMEpAAAAAAAAADRDcAoAAAAAAAAAzRCcAgAAAAAAAEAzBKcAAAAAAAAA0AzBKQAAAAAAAAA0Q3AKAAAAAAAAAM34Mr2A7hYOh/Xuu++qrKxMHg85MQAAAAAAANAZ0WhUlZWVOuqoo+TzOT5OjHH8J3333Xc1derUTC8DAAAAAAAAyGpvvfWWjj322Ewvo8c4PjgtKyuTZH1jBw0alOHVAAAAAAAAANllx44dmjp1aixncwvHB6d2e/6gQYM0dOjQDK8GAAAAAAAAyE5uG4Pprk8LAAAAAAAAAB1AcAoAAAAAAAAAzRCcAgAAAAAAAEAzjp9x2hHRaFTBYFChUCjTS0EHeL1eeb1eGYahnJwceb3eTC8JAAAAAAAADuP64LS2tlafffaZwuGwDMPI9HLQAaZpSpJ8Pp+8Xq+GDh2qgoKCDK8KAAAAAAAATuLq4DQcDmvTpk3Kzc3VoEGDFAgECE97OdM01dDQoF27dikcDisvL09ffPGFxo0bR+UpAAAAAAAA0sbVwWltba0Mw9DgwYNVWFiY6eWgE/x+v7Zs2aK+ffvq4MGDamhoIDgFAAAAAABA2rA5lETgloU8Hv7oAgAAAAAAoPuQPgEAAAAAAABAMwSnAAAAAAAAANAMwSk0ZMgQ3X777V26xvvvv6/Kyso0rQgAAAAAAADILFdvDpWtpk6dqkmTJumRRx5Jy/XefvttNscCAAAAAAAAEhCcOlQ0GlUkElFOTk675w4ePLgHVgQAAAAAAABkD1r1E0SjpmpqIhm5RaNmh9b4H//xH3r77bf16KOPyjAMGYahjRs36sUXX5RhGHr66ad1+OGHKxAI6KWXXtKGDRs0c+ZM9e/fX3369NHEiRP13HPPNblm81Z9wzB0//3364wzzlBubq5GjBihJ598ss11/e1vf9MZZ5yhwsJClZeX64ILLtCbb76p1atXa/Xq1frkk0+0Zs0anXPOOSoqKlJhYaGOOeYYPffcc1q9erU2bNighx56KLb2gQMH6oILLtDq1au1bt06VVVVdf4bCgAAAAAAAKSIitMEBw9GVVjozch7HzgQUUFB++/9y1/+Up988okOPfRQ3X333ZKkQYMG6ZNPPpEk/ehHP9Jdd92lQw45RKWlpdq8ebPOPPNM3XnnncrNzdX//u//6oILLtDatWs1bty4Vt/nrrvu0m233ab7779f9957ry677DLNnDlTAwcOTHp+OBzWjTfeqOOOO06VlZW66qqr9P3vf19///vfZZqm3n77bX31q1/VaaedppdfflmVlZVav369Ro4cqfHjx+sXv/iFbr75Zt1555067LDDVF1drc2bN+vwww9XXV2dPB4yfgAAAAAAAPQcgtMs079/f+Xk5KhPnz4aNmxYi+dvvfVWnXfeebHHAwcO1HHHHRd7vHjxYr3wwgt6+umntXDhwlbf58ILL9Tll18ee81jjz2m//f//p/mzJmT9PyvfvWrKisrU1lZmUpLS3XdddfpkksukWmaKigo0Isvvqj8/Hw98sgj6tu3r1avXq1p06aptLRUknT//ffr+uuv1zXXXKP169dr4sSJ+o//+A9JUiAQ6PR/JwAAAAAAAKArCE4T9Onj0YEDkYy9dzpMnz69yeOqqirdcMMNeumll7Rr1y5FIhEFg0Ft3bq1zetMnjw5dr+oqEgFBQWqqKho9fwNGzbo//v//j99+OGH2rt3ryIR67/j1q1bNWHCBK1fv15HH320wuGwJKm8vFxbtmzRnj17FAqFtH37dp122mmSrLB369atqq6uVmFhofr166c+ffqk9N8DAAAAAAAASAXBaQKPx+hQu3xvVlhY2OTxVVddpddee0133HGHxo8fr/z8fM2ZM0ehUKjN6yTbVCoajSY9t7a2VldeeaVOPfVUPfHEEzIMQ+vWrdOVV14Ze5+8vLwm7zl48GCVlJSoqqpK27ZtkyQdOHBAkjRgwAAVFxdr//79qq6uVkVFhYYOHaqysrKO/4cAAAAAAAAAuoDBkVnI7/fHKjrb8/bbb+vCCy/URRddpKlTp2ro0KGxoDJdPvzwQ+3fv18/+tGP9KUvfUlHHHGEdu7c2eScww47TKtXr5bPF8/qc3NzVVZWpqOPPlpDhw7V0qVLY8/5/X4NHDhQY8eOVVlZmXbv3p3WNQMAAAAAAABtoeI0Cw0bNkyrV6/Wxo0bVVRU1OqGTZI0cuRIPf/88zr//PNlGIZ+9KMfyTTNtK5n+PDhysnJic0vXbt2rR577DFJUl1dnWprazV79mwtWbJE3/nOd3TjjTeqrq5OGzdu1PTp0zVq1Ch997vf1U9/+lMdeuihsTEBq1ev1uWXX64DBw4oNzc3rWsGAAAAAAAA2kJwmoV++MMf6qKLLtLkyZMVDAb14Ycftnruz3/+c11yySU65ZRT1K9fP11zzTWxlvh0GTBggG6//XYtWbJEjzzyiI4++mjde++9mjNnjj777DMFAgGVlZXpX//6l374wx/qlFNOkcfj0SGHHKKysjJFo1FdfPHF6t+/vx544AFt3rxZffv21amnnqpTTjlFxcXFSTfCAgAAAAAAALqLYaa7/LCX+eKLLzRs2DB9/vnnGjp0aJPnqqqqtGXLFo0dO5bNh7JMfX29Pv30Uw0ePFjbt2/XqFGjqEoFAAAAAADoBm3la07GjFMAAAAAAAAAaIbgFAAAAAAAAACaITgFAAAAAAAAgGYITgEAAAAAAACgGYJTAAAAAAAAAGiG4BQAAAAAAAAAmiE4BQAAAAAAAJA2r732ms4991wNHjxYhmHo2Wefbfc1y5cv19FHH61AIKCxY8fq8ccf7/Z1tofgFAAAAAAAAEDa1NbWavLkyVqyZEmHzv/000919tln65RTTtGaNWt07bXX6tJLL9U//vGPbl5p23wZfXd0mWlGZJqmDMMjw+h4Dj5kyBBdccUVuvnmm5M+/+mnnyoSiWjs2LHpWqoj1YfrteLzFRpePFyj+42WYRiSpLo6acsWKT9fKiy0bnWRGq3avkp9cvroyPIjZUZydOCAVF0t1dRIwaB1C4Wkg/URbapap211n/To5/EaXh3a7wiNLR2poiJDhYVSUZEUCFjrstcXDEoNDdLYsZLfH399JBrRa1te08i+IzWy78jYf49kTFPaulXas6fpdbfVfK6PqtcoYjb0wCcGANi8Hq++e8bJGjmoOKXXR82oXtvymvbW7ZVk/f/6vn3S3r3WzzrTTOdq0Z0GDpRGj27/vOpq6cMPpWi0+9cEAEA2mDJ6tC446chML6NXOOuss3TWWWd1+PyHH35Yo0aN0r333itJOuyww/Tvf/9b999/v2bNmtVdy2wXwWmWi0ZDkqKSAp0KTtE1++r26aF3HtL/vPk/qqytlCSV5ZdrpOd41X88Qxv/NUP1u8qloSul4a9Lw16Xyt+TPBHrAg150rap0tYZ0uczpIrJUumH8XOHrpRyqzPz4bZIOjBI+vz4+Pp2HCVFc1qcevzx0uuvxx//7P/9TLcuv1WSNKhgkGYMn6EZw2Zo6qDjVb/lCG1Y59PatdLatdK6ddKBmqg0YH38cw9/XSr+vIc+KACguUfvPE+VD/y1U6+pD9frd+/9Tve8/t/6eN9H3bQy9Kitkt7J9CIAAMg+Ez+8Shec1LEKy2x14MABVVfH84pAIKBAINDl665YsUIzZ85scmzWrFm69tpru3ztriA4BTpha9VWLV65WL9a9SvVNtRKkoq8paoJV6mytkKVekYqf0b6VisXqBoq+WulvH3SyFetWys84QL1qTlchtlz/zONeg/qYME6mYU7pAl/sW6StH+49Phyaf8oBQJWBWp1tfTGG9KBA1ZFbVV9le5bcZ+1dsOjHTU79PSGp/X0hqebvkl54+30VhehPrWHyxsu7KZPCQBoLuzbp7rCDdrV8JkaGqSclv9W1kKyf0RUXV9p1+GxcwxD8gckfweuh96jpiZeIez3S4MGSWVl1s/87dulqqr4uXl5ko/fKAAAkCSNLOtAy0aWmzBhQpPHt956q3784x93+boVFRUqKytrcqysrEzV1dWqq6tTXl5el98jFfw1J8vce++9uuuuu7Rjxw55vd7Y8TPOOFMlJSX605/+pA0bNujqq6/Wu+++q7q6Oo0ePVo/+9nP9JWvfKXD7/Pee+/pnnvu0caNG9XQ0KAjjzxSN9xwg4YMGaJIJKL8/HwVFhbqtttu07PPPquqqioNHz5c8+fP14wZM+T3+7V161bdc889euutt5STk6PDDz9cP/vZz9S/f38NGDBAgwYNSvm/QzQqHTxohXc9wTRNXfnClXrk3UcUjoYlSUeUHaFR227Qc7d93aokHfyO+h3xukqOfF27895QTXi/JpdP1nGDZ+jI/jM0ofB4FUaHSUZUu8yNWlf1ulbvfl0rt72hj/Z8pBHFIzRj+AwdP/R4zRg+Q5MGTpLX421nZelX11Cnt7e/rde3vq7XP39d/976b1X13aqv/XKhnvraH2V33w8eLO3YIW3YIE2bJj349oOqClZpwoAJeuvSt7Rqxyq98fkb+vfW1/XC+29IeXuTvl9RoEjTh07XjGEzNGP4DE0dMlUF/oIe/MQAgJc3v6LTfneqTCOk99+Xpkxp+/x737hXty6/NfaPiMOKhmlKaIGeveM7mnlioRYvtn5O9O0rtTG1Bb1UZaX08MPSQw9Z97fIutk8Hun886VrrpFmzOB7DACAm2zYsEFDhgyJPU5HtWlvRnCawIxGdTBYk5H37hMokOFpv9X+4osv1sKFC/XCCy/oy1/+siRp585deu211/T001ZlX3V1tc4880zdeeedys3N1f/+7//qggsu0Nq1azVu3LgOrae2tlbnn3++zj77bJmmqZ/85Ce65JJLtGbNGvXv31/bt2/XWWedpWg0qt///vfKy8vT+++/r0GDBmnixIl6++23NWfOHP3Xf/2Xbr75ZlVVVWnz5s065JBDVFRUpFAo1KF1mKapmlCNImZE+Tn5yvHmqKFB+vRTadcu6a9/9eo//7NDl+qS9bvW65erfilJOnXUqbrh+BtUUHmGTpxnSFHp6vk5uuiiEzRlygkyDGvdDdEG+b3+JFfzSDpMp+kwSZdKkoLhoAK+3vF/Nnk5eTpxxIk6ccSJkqT3Kt7TUb88Sn/+4Cl9f/v1OnbIsZKkiROt4HTtWmniUbW6b6VVbfrDE36ofH9+7BqbNkkvfCuqQFGVvvhC8jbLgosCRRkJiAEAcQFf488rb0grV7YfnN78ys2qC9dp0sBJumHGDbrg8Au08MYcKSRNniwdfnjbr0fvVlYm3Xqr9IMfSE89JT3wgLR6tRWEX3aZNG+eNGJEplcJAAAyobCwUEVFRWm/bnl5uSorK5scq6ysVFFRUcaqTSWC0yYOBmtUcHdqGyJ0Vc0NVcrPa/8P3oABA3TSSSfpiSeeaAxODT3xxFPq27evzj77bEnScccdp+OOOy72msWLF+uFF17Q008/rYULF3ZoPccff3xsc6hIJKLrr79eL7zwgtasWaNzzjlHH3/8sdavX6/XXntNM2bM0Mcff6zZs2dr5MiRkqQHH3xQxxxzjB588EFt3bpVdXV1+upXv9rqZkH19dIXX1hVpIMHS/37S5FoWFuqtmhf/b7YeQFvrsIHCxQxA5KnQVu39kyJwyd7rU2ajh50tJZdvEy1tdLkM63K14svtn6hSGQYRiuhaXK9JTRNZnL5ZH3riG/pd+//Tjf+60Ytu3iZDMPQpEnSSy9Zs0p/tepX2n1wt8b0G6MLJl7Q5PXvvy/J9GjSuH4qpZAUAHql2M+sxuB03rzWzzVNU3XhOknSSxe9pLICq6Xqiy+s54cO7c6VoicFAtbfcy66yNr0cuBAqU+fTK8KAAA40fTp0/Xiiy82OfbSSy9p+vTpGVqRhd2EstA3v/lNvfjii6qrs35peeqpp3XeeV+Jte5XVVXpu9/9rkaPHq3CwkL16dNHmzdv1tatWzv8Hrt27dKPfvQjjRs3TiUlJTrppJNUW1sbu8b777+v8vLyWHn2wIEDtXfvXq1fv15ffPGFVq9erdNOO02S1L9/f9XV1WndunXaunWrqhIGY0Ui1i9a69dL+/dbO/B+9pn0weYqrdu1Phaa5vpyJUnBSL0igd1S0TapcLs+yv1Dl/5bdtSn+z+VJI3pN0aSdMMN0iefSMOGtQxNnej2U26X3+vXK5+9oqWblkqyKk4lac26ev33iv+WJP3ghB/I52n67zHvv299nTSpx5YLAOik2D/g+YJaubLtcxuiDS1fJ4JTJzMMaeRIQlMAANBxNTU1WrNmjdasWSNJ+vTTT7VmzZpYrrRw4UJdfPHFsfOvuOIKbd68WTfccIM+/PBDPfjgg/rTn/6k6667LhPLj6HiNEGfQIFqbqhq/8Rueu+OuuCCC3T11Vfrz3/+s6ZPP1arVq3S4sX3xp6/6qqr9Nprr+mOO+7Q+PHjlZ+frzlz5nS4PV6Svv/972vfvn164IEHNHDgQH3++ee6/PLLY9doXiZdXFysSZMmqaqqStXV1TIMIxaQ5ufnN3lu8+bNKiwsUr9+Y/TFF1JD4+9fRUVSn4KIKg5+oYN5u6So5FOuxvYfpWgwX5s2hxX11cjXp0byWfMyq/zrJM3o8OdK1eZ9myVJo/qO0j/+IT34oHX8scestjWnG9F3hL439Xu6d8W9uvFfN+qMMWdo0iQrqF8dfVwHDmzX0KKhunjyxS1eawenRxzRkysGAHRGYsXppk3S7t1SaWnyc0ORUMvXieAUAAAAce+8845OOeWU2OMFCxZIki655BI9/vjj2rFjR5MCv1GjRumFF17QddddpwceeEBDhw7V//7v/2rWrFk9vvZEBKcJDI+nQ+3ymdanTx/NmjVLTzzxhD766EONHDlS06cfH3v+7bff1oUXXqiLLrpIklWBum3btk69x6pVq/TjH/9Ys2fPViQSUWVlpXbv3h17fuLEiaqoqNC2bds0cuRI1TXUqbahVv3791dpaamOPPJILV++PHa+1+tVSUmJSkpKFMgt0bb9+7R/93YpV/LmS8XFVjvY3ro9Up+g9aKagQofGKot+zyqr5dM06fCvL4aM7yvtu2VKrRdwYZwbNfX7mQHp+WB0fqvb1jHvvc9qbGo1hV++KUf6pF3H9HanWv1+/d/r69NuETyNujAEXdJkm44/oak4wkITgGg97P//9vwhWRKevNNqXECUAvJgtNoVLL/qkFwCgAAgJNPPllmG4HN448/nvQ17777bjeuqvNo1c9SF110kZYvX64nnviD/uM/zpcU/8M4cuRIPf/881qxYoVWrlyp888/v80/rMmMHDlSzz77rD744AO98847uu2225Sbm6u6ujrV1dVp5MiROvroo/Xd735XS/+xVP9a9S898cwT+v1ffq+6ujrNnTtXGzZs0FVXXaWXX35ZK1eu1D33/FxvvFGpbTV7paJdUuF2qXC7In22a2/Ddu2o2a5gJCi/169DSg7RiH7D5fV4VFcnmabUr580bpzk80n2XkJRRVRT0/1/jO1W/ed/P1rbt0uHHCLdeWe3v22vUpJXooUnWDNyb3rlJhk5dRp42pNSv8/UN2egLj360havqamxRhpItOoDQG+WGJxKarNd3w5OPYYnNp5l1y4pHLZ2Wy8v7961AgAAAD2F4DRLnXPOOSouLtZnn32mSy5puq38z3/+cxUXF+uUU07RV7/6VZ1++umaMGFCp65/5513qrq6WkcffbQuuugiXX/99SotLdXevXu1YcMGBYNBPfPMM5o6daq++c1v6munfE0//9nPtefgHn348YcaPXq0XnjhBb333nuaPXu2zjjjLD3zzAsKRkNSH6tytV+gVAP6DGhyG1w4WBMGTFBRbpEGDLDmaA4YIA0ZIo0ebf1CJkkee5MpT0R79nRv4bRpmrGK05efHi2PR/rtb9055+t7U7+noUVD9UX1F3rgzQd08Og7JElf8l6vvJyWu9ytW2d9HTTI+j4CAHqngNeaVRo1GiQj2mZwGgxbnSHJ2vTLy61/4AQAAACcgL/aZimv16udO3cqEqmXFGny3Pjx47Wy2W88P/jBD5o8bq91/5xzztE555zT5NjXv/71Fuf9/OGf66qfXiVJ8kQDinqCUkOBgjVjVF4+Vg8+eHpshqnhicpTtkERSQP6DNCIviPa/Zw5OdKIJKcZsoPTsHbv9rZ7na6oqKlQfbheinqkquFauFCaNq1b37LXysvJ0+2n3K65z83Vj17+kaK5Uamun/ptuzLp+bTpA0B2aDJqxdOgt94KKBqN/4NlIrvilPmmAAAAcDoqTpEy0zS1pWqL9aCuRNHdYyXTUCSnSnXmfgWD1sZPHo9UViaVjalUxKiXz+PTkKIhXXpvw644Nbq/4tSuNlX1MJUPzNEtt3Tr2/V6Fx1xkSYNnKSoGbUOrLxWG98vTHouwSkAZIfEELRPYUjV1dKHHyY/1w5O7SpVieAUAAAAzkRwmuXs/DATdtbu1MGGg5LplaqGqTg/T/1yrMFmvv6fa9z4iA47zArNBgyqV+XB7ZKkYUXDYjPRuqwHWvXt+abaN1qTJkn+lvsfuYrX49WdM60Br/m+QunN72n9emtjkObWrrW+EpwCQO+WGJweOaXtOafBSOut+gSnAAAAcBKCU6QkFAlp24HGdv+qocrx5mjUKGlU6SAFvAGFzZCqo9uVny95vaa2Vm2VaZoqChSpJK8kfQvxRLRnT/e26scqTveN0vjx3fpWWWP2uNl65uvP6J/f+pf80X6qqZG2bGl6jmlScQoA2cLr8cprWD9PjzzGCkZbC05p1QcAAIBbEJwiJZ9XfW61aofypYOlGjWqcbd7j0fDi4dLkiprK3UwdFD76vepOlgtQ4aGFw+Pt9l3QUZa9feNJjhN8NXDvqrjR0zVoYdaj+2NoGxffCHt32/9ubDPAQD0XnYQOvnotitOY636Plr1AQAA4GwEp+i0/fX7ta9+n2RKqhqhsjJDRUXx54tzi9Uvt58k6bOqz/R51eeSpEGFg5Try03LGhI3h+rJVn2C05YmTbK+2m35Nrva9LDDGG8AANnADk4nTLKC0XXrpAMHWp4XDLds1bf3nBzStRHmAAAAQK9CcCprk6Ps1bNDTiPRiLZWbbUe1JYpz9cn6S9Jw4qHyWt4dbDhoBqiDcr15aq8oDytazFlyjTC3d+qv7ex4nQ/rfrJTJxofW1ecUqbPgBkFzsI7ds/pBEjrJErb7/d8rzmrfqmScUpAAAAnMnVwWleXp5M01RtbW2ml5I19tTtsX5hivhl1AzW6NGSJ8mfIr/XryFF8UR1ePFweYz0/XEL1YcUioS0u36P9uzxyevtnvC0Plwfm+WaWzeaXwiTaK/i1H4eANC72a33wXBQxx1nHUvWrh9r1fda5+/bJ9XVWc8NHtztywQAAAB6TPf2OPdyfr9feXl5qqyslCTl5+enZf5mT4pGGyRFZBgRGUZDt7/fvupqKSyptlhlA4MyTengweTn5itfpTml8nq88kV8OtjaiZ1gmqYOHjyo3bt26/+2/J8ORmqlPT75fN3zfduyf4tMmVIoX4cMHZA0JHY7u+L0ww+lUCjelk/FKQBkF7uCNBQJ6bjjpKeeSh6cBiNNW/XtatMBA6Tc9EzkAQAAAHoFVwenkjR27Fht2rRJO3bsyLrQVJJMMyJr2KhHRhorOluzo2a3TCOknAZT/oYq7d3bsdft0760rcE0TW2v3a7HNj0meSbo4EGPDh6U8vPT9hYxifNNDx2ffX8+esLw4VJhoTUH76OPrCC1vl7auNF6nuAUALJD8+BUkt5802rFT/wrUvNWfdr0AQAA4FSuD049Ho8OOeQQhUIh1dl9Zlnk888Xa9++f6qs7BKVlV3Qre/1xbaovvvqBVJOne4/5jkdM2JEt75fa3w+n3Zt3yVTpgxvWKaknTulUaPS/16b9zXON93HfNPWGIYVlq5YYc05nThR+uADKRKRSkpo2wSAbNEkOD3K6iDYuVP67LOmP2NjrfqNrf0EpwAAAHAq1wenNr/fL38Wbv1dUfGFIpE3FAjMVnFxcbe+13W3f6IthR/KUx/QuSceLp8nc3988nOt8lJvTlhhSZWV3R2cjtahh6b/+k4xaZIVnK5dK114YdM2/Sws5AYAV7JnlgYjQQUC0lFHWRWnK1c2/RkbDCdv1Sc4BQAAgNMwsTHrWd9C04x267tUVUl/eNna/WdkwWEZDU0lyeuxNoPy+MKSrOC0OyS26lNx2jp7zum6ddZX5psCQPZJrDiVpGnTrOPN55y21qo/ZIgAAAAARyE4zXL2XFNr1mn3+fWvpfpCKxWbMTbz26TbwW13B6cf726sON0/Socc0j3v4QSTGv9IrLWydYJTAMhCzYNTe85pa8GpXaG6bZt1nIpTAAAAOA3Badazv4XdV3Ha0CA98ICkgVYqNnHgxG57r46yg1PD233BqWmasVb9Ab7RKixM/3s4hV1x+umnUk0NwSkAZKPWgtN337U2/bMFI7TqAwAAwB0ITrOcYVgt693Zqv/nP1u/FHkHWxWnkwb2nopTebovON1bt1e14WpJ0mGDRqb/DRyktFQqL7fuv/KKtZmIYUiHH57ZdQEAOs7e7MmeYTpypDRwoPUPqO++Gz+vtVZ9glMAAAA4DcFp1uveilPTlO69V5I3KLNko6TeVXFqB6c7d6b/PWLzTQ8M0oRxfdL/Bg5jV50++aT1ddw4qQ//2QAgazSvODWM5O36ia361dVStfVvjMw4BQAAgOMQnGa5+IzT7glOX31VWr1aCgzZqKgiKg4Ua2hR5ktK7OA0qu6rOLXb9LVvFBtDdYA95/S556yvtOkDQHZpHpxK8Q2i3norfp5dker3+mPzTfv2lQoKemKVAAAAQM8hOM163Vtxeu+91tcT5sTnmxqG0S3v1Rk9G5yOJjjtALvitK7O+kpwCgDZJVlwOnWq9fXNN+PnJbbq06YPAAAAJyM4zXLdWXH64YfS889brXpjpvee+aZSPDg1FZHUTcHp3sZWfYLTDpk0qe3HAIDeLeBtnHHauPmTJB17rPX100+lXbus+8mCU9r0AQAA4EQEp1mv+ypO77/f+vrlL0vbGuIVp72BHZyGzbAkU/v3S8Fgmy/ptA07rIpTX80ojRiR3ms70YQJVshuo+IUALJLsorT4mLp0EOt+2+/bX21g9WAL0DFKQAAAByN4DTLxStOI2m97oED0m9/a92//npp3c7GitOy3lFGGNscSpI3xwqN071B1CeNrfpD80fL603vtZ0oP18aPdq6X1Bg7cYMAMgeyYJTqWW7fmLFqT3jlOAUAAAATkRwmuUMw0700ltxunWrVF8vlZRIRxxbrS1VWyT1vopTSRpYZs05TWdwGo6GtTNofeZDy0en78IOZ885nTRJ8vD/LgCQVVoLTptvEMWMUwAAALhFRqONhx56SEcccYSKiopUVFSk6dOn6+9//3vs+fr6es2bN0/9+/dXQUGB5syZo8ruGGaZ1bpnxunu3dbXAQOkDbvWS5IGFw5WSV5JWt8nVYnB6YDy9G8Q9UX1F4oqIoX9OmrM4PRd2OHsWXh2dRIAIHvEZpyGm86+sf8//a23JNNMaNX30qoPAAAAZ8tocDp06FDdeeedWrVqld555x2deuqp+spXvqL1662g7rrrrtPf/vY3/fnPf9arr76q7du36/zzz8/kknsdu1W/qxWnzatL7OC0tFRau7N3zTeVmgWnZekPTjc3tulr/0gdOp7SyY5asEB66CHp1lszvRIAQGe1VnF6xBFSICDt3St98gkVpwAAAHCPjCZC5557rmbPnq1x48bpkEMO0c9+9jMVFBRo5cqVqqqq0iOPPKL77rtPp556qqZMmaLHHntMb7zxhlauXJnJZfcyXa84vXbptRpwzwCtrVwbO2YHp/37J8w3Hdg75ptKTYPT0oHdGJzuG63x49N3XafLy5OuuELq1y/TKwEAdFYsOI02DU79fumoo6z7b72VEKxG/Nqzx7pLcAoAAAAn6jWldJFIRH/84x9VW1ur6dOna9WqVWpoaNDMmTNj5xx66KEaPny4VqxY0ep1gsGgqqurY7cDBw70xPIzJh0Vp8s/W67qYLUeePOB2DH7F6HeWnHqMTwyZG3hXjog/cHpxspPrTsEpwAAl2it4lRqukGU/fyB/VZrf58+UnFxz6wRAAAA6EkZD07Xrl2rgoICBQIBXXHFFfrrX/+qCRMmqKKiQn6/X3379m1yfllZmSoqKlq93qJFi1RcXBy7TZgwoZs/QaZ1veK0tqFWkvTHdX9UdbBaUkLFaakZq0TtTRWnUrzqtH83BKfvf2FVnBaER6nZH0EAABwp4Es+41RqukGU/XzVXitoHTpUMoyeWSMAAADQkzIenI4fP15r1qzRm2++qSuvvFKXXHKJNmzYkPL1Fi5cqKqqqtitK9fKBnbFqWlGUr5GbcgKTmsbavWHtX+QFA9Oc/tXak/dHhkydNiAw7q22DSzg9N+/a3gdOfO9F37kz1WcDqsYHT6LgoAQC/WkYrTd9+VgmHr+f174sEpAAAA4EQZD079fr/Gjh2rKVOmaNGiRZo8ebIeeOABlZeXKxQKaf/+/U3Or6ysVHl5eavXCwQCKioqit0KCwu7+RNkmrfxa9crTiXp16t/LSneqn+wwJpvOrZkrPrk9En5PbpDLDgtTX/F6Y56q1X/0DKCUwCAO7QVnI4ZI5WUSMGgVFNnPb9vt1WhSnAKAAAAp8p4cNpcNBpVMBjUlClTlJOTo2XLlsWe27hxo7Zu3arp06dncIW9S7ziNLXg1DTNWMWpJK3asUrv7ng3VnG6z9/75pvavB4rNO5Xkt7g9EDwgA4auyRJR40alZ6LAgDQy7UVnBpGvOq0pt5q1d9TScUpAAAAnC2jwenChQv12muv6bPPPtPatWu1cOFCLV++XP/5n/+p4uJifec739GCBQv0yiuvaNWqVZo7d66mT5+u4447LpPL7mW6tjlUKBJSpLHN/8yxZ0qyqk7t4HSnaVWc9rb5plK84rS4MTjdvVsKh7t+3U/3N24MdbBERx7KbhcAAHcIeBtnnEZazjiV4sFpfcgKVncRnAIAAMDhfJl88507d+riiy/Wjh07VFxcrCOOOEL/+Mc/dPrpp0uS7r//fnk8Hs2ZM0fBYFCzZs3Sgw8+mMkl9zpdrTitCdXE7l8z7Rot3bRUT6x9Qqq6R1K+ttT33opTOzgtLA7L45GiUSs8bWOSQ4dsapxvqn2jNX58FxcJAECWaKviVIpvEBWKNganO2jVBwAAgLNlNDh95JFH2nw+NzdXS5Ys0ZIlS3poRdmoaxWn9nxTv9evM8acodH9Rmvzvs3SsD9Ley/WJ9XrJUmTynpvxampsEpLrc2hKiu7Hpyu2WJVnBr7R4tOfQCAW7QXnB57rPU1algVqRXbrfOHDOn+tQEAAACZ0OtmnKJzulpxas83zc/Jl8fw6NKjLrWeOPrXMko+1cHwQQW8AY0tGZuW9aaTHZyGo2ENHGgd27mz69d9f6tVcdrPGKWcnK5fDwCAbNBecDpggKx/UPRaz++uoFUfAAAAzkZwmvXsb2EkpVfbFaf5/nxJ0reP/La8hlca/oZyj3lKknTYgMNiIWVvkhiclpVZx9KxQdTHja36wwpGd/1iAABkiYCvccZpOPmMU0k6dlpE8jT+nSMckN8vlZb2xOoAAACAnkdwmuUMw9pZPh0Vp5I0qHCQpvc/V5JUf8wiSb1zvqnUfcHptvqNkqRDB47p+sUAAMgS7VWcStLRxyY8F/FryBDJw98mAQAA4FD8VTfL2a36XZ1xalecStKJ+ZdJkswca+OoSQN733xTKR6cRsxI2oLT/fX7VeX9RJJ0/Ogju3YxAACySEeC0yOnNA1OadMHAACAkxGcZr30zTi1Da2fJVUNiz12U8Xpuzvete7sH6Ejx/fv2sUAAMgiHQlOD5tIcAoAAAD3IDjNct1Rcbpvr1da/Z3Y495ecZrO4PSd7ausO9unaNiwts8FAMBJAt7GGaeR1mecenIan4vkSDIITgEAAOBoBKdZr2sVpzUhqx0/seJ0925J7/6XcswCjek3RkOLeudvRcmC0507u3bNlVtWW3d2TNGQIV27FgAA2cSuOA1Hw4q28veKWDVqxDqXn5UAAABwMoLTLNflitPGVv0Cf0Hs2O7dkqqH6fq8tfr3f/1bhmF0cZXdIzE4HTjQOtbVitNVjRWnfeuOlt/ftWsBAJBN7OBUkhoiDUnPiQWnYas6lYpTAAAAOJkv0wtAV3VxxmlDyxmne/ZYX8cNGKnygmSv6h1aqziNRlPb4bc6WK0ttR9Jkkb4j07XMgEAyAqJwWkoElLAF2hxTjBst+pb5xKcAgAAwMmoOM1yhuGVJJlmJKXXxzaH8jdr1ZdUWtq1tXW3ZBWn4bC0b19q11tTsca6UzVUo+wLAgDgEonBaWtzTu2KU4/8ysmRxo7tkaUBAAAAGUFwmvXStDlU8xmnyq7g1O+X+vWzjqfarr96R3y+KRtDAQDcxuvxytv4D7Kxlvxm7OPDBvn1xhtS//49tjwAAACgxxGcZjl7xmmXW/WTVJz29l+GEoNTSbF2/VSD01U7rPmm2nE0rYcAAFeyq05bC07tStSCvICOOabHlgUAAABkBMFp1kvP5lB2xWlDg1RdbT2XTRWnkprMOU1FrOJ0OxWnAAB3ai84tY8ntvUDAAAATkVwmuXSXXFqbwzl8Uh9+3Z5ed3Kbie0g1N7LGkqFae1oVp9uPtD6wGt+gAAl7I3hIptAtUMwSkAAADchOA063Wt4rQmVCMpXnFqt+n36yd5vV1dW/dKZ6v+e5XvKWpGpQODpJpyWvUBAK7Ubqt+Y6BqB6wAAACAkxGcZrkuV5w2tuoX+AskxStOe3ubvpTe4HTV9sb5ptunyDCkwYPTsUIAALILrfoAAABAHMFp1rO/hZGUXt28Vd+uOHVdcJqwMVRZmeTn90EAgAsRnAIAAABxBKdZzmic89nVitPmrfr9+3d9bd0tncFpbGMo5psCAFws4G2ccRppe8apfR4AAADgZASnWc5u1U91xqkTK0537uzcdeoa6rRh1wbrwfYpzDcFALhWuzNOGwNVKk4BAADgBgSnWS/1GaemabaoOM3mGacDB1rHKysl0+z4dd6vfF8RM6I+5kDpwGAqTgEArkWrPgAAABBHcJrlulJxGoqEFDGt2ajZXHEaiVqfwa44ra+XDhzo+HXs+abFB6dIMghOAQCu1dHglFZ9AAAAuAHBadZLveLUbtOXnDHjtE8fqaDAeq4zc07t+aa+nUdLEq36AADXCvgaZ5yGk884tY9TcQoAAAA3IDjNcl2pOLXb9HM8Ocrx5kjK7lZ9KbUNouyK0+BnUySJilMAgGvRqg8AAADEEZxmPbviNNLpV9aEaiRJBf6C2LFsbNVPDE5LSqyv+/d37BrBcFDrdq6TJO1dR8UpAMDdOtyq76NVHwAAAM5HcJrlDMMrqWut+vZ8Uym7W/UlKTfX+hpM3mHYwtqdaxWOhtUvt7/Ce4bLMKTBg9O9UgAAskN7wWkwQqs+AAAA3IPgNOt1vVXfnm/a0CBVV1vPZWvFqR2c1td37Br2fNPxBdbGUIMGSTk56VwlAADZw970yQ5Im6NVHwAAAG5CcJrl7Bmn6ag4teebejxS375pWV63Skdwumq7Nd90sEGbPgAAHW7V99KqDwAAAOcjOM166as4tdv0+/WTvN50rK17xYJTswvBaePGUMV1bAwFAACt+gAAAEAcwWmWS2fFaTZtDCV1veI0FAlp7c611rV2UnEKAEBHK04JTgEAAOAGBKdZL30Vp3arfjYHp4HGzsGObA61fud6hSIh9c3tq+qtoyRRcQoAcLfYjNNw2zNOAz5a9QEAAOB8BKdZLl5xGun0a7O94tRrWPMEUq04tdv0jx50tLZ9YUii4hQA4G7ttuqHadUHAACAexCcZjnDsIeRdr7itCZUI0kqyCmQFA9O+/dPx8q6X1db9V/d8qok6bghx+nzz61jVJwCANyMVn0AAAAgjuA063VhxmmoacWpE1r1Oxqcmqaplz55SZJ02qjTtW2bdZzgFADgZrHgNNp2cGq39AMAAABORnCa5exW/ZRmnDY0nXGaba36XQlO1+5cq8raSuXn5Gu0f7rCYcnjkQYN6q7VAgDQ+9mzS1ubcRqM0KoPAAAA9yA4zXpdqDhtZcapG1r1//nJPyVJJ408Sbt2WL8kDhok+XzpXycAANmCVn0AAAAgjuA0y3Wp4jTUtOLUTa36L2222vTPGH1GbL4pG0MBANyO4BQAAACIIzjNeumvOHV6cFofrtdrW16TJJ0+5nQ2hgIAoFF7wandwm+39AMAAABORnCa5dJZcZqtrfqRaCR2LND4e1xbwem/t/5b9eF6DSkcosNKD9MXX1jHCU4BAG5nb/pkzzJtjopTAAAAuAnBadbzSpJMM9LOeS0lVpyGQlJ1tXXcCRWnweS/70mKzzc9fczpMgyDVn0AABrRqg8AAADEEZxmuXjFqSnTNDv12ppQjSSpwF+gvXutYx6P1Ldv+tbXnVJt1U+cbyqJilMAABq126rfWIlqV6YCAAAATkZwmvUSv4WdC04TW/XtNv1+/SSvN01L62apBKeVNZVaU7FGknTa6NMkiYpTAAAa2bNLqTgFAAAACE6zXrzitPMbRCW26mfbxlBSasHpvzb/S5J0VPlRGpg/UJGItG2b9RwVpwAAt7MDUXsTqESmaRKcAgAAwFUITrNe4rew48GpaZpNKk737LGOOz04tdv0Tx99uiSpslKKRKwRBeXl3bdWAACyQVut+ok/b+3KVAAAAMDJCE6zXKoVp6FISJHGDaXcUnFqmmZsY6gzxljzTe02/cGDJZ+v+9YKAEA2aCs4teebJp4HAAAAOBnBadZLreLUbtOXms447d8/TcvqAZ0NTjfs2qAdNTuU68vVjOEzJLExFAAAiexNn5IFp4nHCE4BAADgBgSnWc4w4js5mY0VpB1ht+nneHKU481xTKt+oLFzMFlwalebnjTiJOX6rISVjaEAAIiLzTiNtJxxagenHsMT+xkMAAAAOBnBaZZLbNVPpeI0358vSY5r1Q+FJNNsen7z+aZSPDil4hQAgHZa9Rs3jKLaFAAAAG5BcJr1UptxalecFvgLJCkrW/W9HqvaNllwKknBhGKZYDio5Z8tlxSfbyrFW/WpOAUAIB6KhqNhRZv9vcIOUwlOAQAA4BYEp1ku1YrTmlCNJGu+qeS8ilOpabv+G5+/obpwncoLyjVx4MTYcSpOAQCIC/gCsfsNkYYmz9nBqT0HFQAAAHA6gtOsl2LFabNWfafMOPX5JE/jf5LE4NSeb3r66NNlGEbsOBWnAADEJVaTNp9zaj+m4hQAAABuQXCa5RJDwE7NOG1s1W9ecZpNrfrJglPDiFedJgan9nzTxDb9SETavt26T8UpAADWppG25nNOadUHAACA2xCcOoL1bUy14jQUkqqrrePZWHEaMSMyE3aCah6c7qvbp9U7VkuSZo6eGTtvxw4rPPV6pfLynlkzAAC9mdfjldewZoi3FpwmtvMDAAAATkZw6gD2nFPTjHT4NYkVp3v3Wsc8Hqlv33SvrvvYwalkhae25sHproO7ZMpUcaBY5QXxhNRu0x882ApPAQBAPBhtHpwGw7TqAwAAwF0ITh3BTv1Sqzi12/T79cuuADExOE1s1w80FsLYwam9uUXzX/TYGAoAgJbsn5d2UGqjVR8AAABuQ3DqAPGK09RmnNrBaTa16UutB6d2xWmw8fc9+xe9HG98bpvExlAAACRjB6Ottup7adUHAACAOxCcOoL9bex8xWmBv8ARwWkk2nqrfkPUqjhN3PBCkqqqrK8lJd23RgAAsk1rwWkwQqs+AAAAOmfJkiUaOXKkcnNzNW3aNL311lutntvQ0KDbbrtNY8aMUW5uriZPnqylS5f24GpbIjh1gFQqTmtCNZKsitM9e6xj2RycJqs4bd6q37zitK7O+pqX131rBAAg29gVpa1VnBKcAgAAoCOeeuopLViwQLfeeqtWr16tyZMna9asWdq5c2fS82+66Sb98pe/1M9//nNt2LBBV1xxhb761a/q3Xff7eGVxxGcOkLqFaeJM07790/zsrqZx/DIkCGpneA0mnzG6cGD1tc+fbp3nQAAZJPYjNNI8hmn9uZRAAAAQFvuu+8+XXbZZZo7d64mTJighx9+WH369NGjjz6a9Pzf/e53+uEPf6jZs2dr9OjRuvLKKzV79mzde++9PbzyOIJTB3DrjFMpXnXaVnAam3HqoeIUAID2tNqqH6ZVHwAAAB0TCoW0atUqzZw5M3bM4/Fo5syZWrFiRdLXBINB5dqhTqO8vDz9+9//7ta1toXg1BG6VnGara36UseC09Za9ak4BQCgpfY2hyI4BQAAcK8DBw6ouro6dgsGg0nP2717tyKRiMrKypocLysrU0VFRdLXzJo1S/fdd58+/vhjRaNRvfTSS3rmmWe0Y8eOtH+OjiI4dQDD8EqSTDPSzplxySpOs61VX+pgcNrK5lBUnAIA0JLdik9wCgAAgOYmTJig4uLi2G3RokVpu/YDDzygcePG6dBDD5Xf79f8+fM1d+5ceTyZiy997Z+C3s5u1U+14nTvXutYNu4u35mKU2acAgDQvtiM03DT6gF75qm9eRQAAADcZ8OGDRoyZEjscSCQ/O+GpaWl8nq9qqysbHK8srJS5eXlSV8zYMAAPfvss6qvr9eePXs0ePBg/eAHP9Do0aPT9wE6iYpTR+jajNNa664KC9O+sG6XLDi1/zdrV4vHKk69VJwCANAeWvUBAADQmsLCQhUVFcVurQWnfr9fU6ZM0bJly2LHotGoli1bpunTp7f5Hrm5uRoyZIjC4bD+8pe/6Ctf+UpaP0NnUHHqAF2pOC3wF8SC02ysvOzK5lBUnAIA0BLBKQAAANJhwYIFuuSSS3TMMcdo6tSpWrx4sWprazV37lxJ0sUXX6whQ4bE2v3ffPNNbdu2TUceeaS2bdumH//4x4pGo7rhhhsy9hkITh2h8xWnNaEaSVarvh0g5uenfWHdriubQ9kVpwSnAADE2a34zYNTu3WfVn0AAAB0xAUXXKBdu3bplltuUUVFhY488kgtXbo0tmHU1q1bm8wvra+v10033aTNmzeroKBAs2fP1u9+9zv17ds3Q5+A4NQROltxappmk1b9bK689HqsjbFS2RzK/ty06gMAEBebcRppOuOUilMAAAB01vz58zV//vykzy1fvrzJ45NOOkkbNmzogVV1HDNOHaFzFaehSEgRMyJJ6pMw4zQbg1M2hwIAIL1o1QcAAAAsBKcOYBhW1aXZGIa2x55vKkk5Zr6ijXlrNgaInZpxyuZQAAC0q9XgNGo9Dvho1QcAAIA7EJw6Quda9e02/RxPjhqC8TDRsTNO22nVz8bAGACA7tLejFMqTgEAAOAWBKcOYM847Wirvl1xmrgxlM8n5eS08aJeqlObQyUEpw0NUqSxQJeKUwAA4mIzTsPMOAUAAIC7EZw6QmoVp/lZPt9USh6cBho7CJtXnCb+omcHxlL2fnYAALpDezNO7YpUAAAAwOkITh0g1YrTAn9B1rert1VxGmwslIlVnCbMOLXnmxpGPGgFAACtB6fBCK36AAAAcBeCU0dIseI0oVU/G+ebSvHgNJKwMVarm0MltOrbnzsvzwpPAQCAxd78qbWKU4JTAAAAuAXBqQN0tuK0JlQjyWrVd3LFaYvNoZJUnDLfFACApmIzTiPJZ5zawSoAAADgdASnDmAY3sZ7kTbPsyVuDuXEGacd2Rwq2wNjAAC6S6ut+mFa9QEAAOAuBKeO0MkZpwmbQzmlVb8jFaeJv+hRcQoAQHLtbQ5FcAoAAAC3IDh1ALtVv8MzThtazjjN1srLjgSnsRmnXipOAQBoT8Db9oxT+3kAAADA6QhOHSH1ilNXtOpHW7bqU3EKAEByrc04tR9TcQoAAAC3IDh1gJQrTh26OVSgsRCmxYxTKk4BAGgXrfoAAACAheDUEVKrOC3wFzh6xmk0KoXDVJwCANAZ7QWnAR+t+gAAAHAHglMHYMZp8uBUsqpOk1XIZPvnBgCgu9jBaPPgNBimVR8AAADuQnDqCF5JkmlGOnR2TahGknNnnAYSCmHq65O36lNxCgBAcrEZp+GmM05p1QcAAIDbEJw6gF1x2uFWfQdVnHoNKzRODE49Hsnf+DtdfX3yVv1s/9wAAHSXZK36kWhEkcZ/oA14adUHAACAOxCcOkInW/VDLTeHctKMUynerk/FKQAAnZMsOE28T8UpAAAA3ILg1AHcXHHaoeC0seKUGacAALTPriglOAUAAIDbEZw6QuoVp06ccSo1DU7tX/YSW/WpOAUAILnYjNNIfMYpwSkAAADciODUAdJRceq2Vn0qTgEASC5Zq74douZ4cmQYRkbWBQAAAPQ0glNHSK3itMBfkPUBYmvBaaBx34pgMPnmUHbFabZ+bgAAuktbM06pNgUAAICbEJw6QGcqTk3TjFecuqRVv62KU1r1AQBoKuCz/vUxHA0r2vh3C4JTAAAAuBHBqQMYhrfxXqTdc0ORUCxkdMvmUMl+2aPiFACA5BJ/Xto/Q4Nhq1XfDlUBAAAANyA4dYSOV5za1aaSVXHqlBmnkWjT0LhJxWmSVn0qTgEASC5ZcErFKQAAANyI4NQB7Fb9jsw4teeb5nhy5PPkuKLilM2hAADoOIJTAAAAwEJw6gidrzjN9+crGJSijS/J1gAxFpyabQSnbWwORcUpAABNeQxP7Odr8+A04KVVHwAAAO5BcOoAqVScJrbpSw4ITjtQcZpYJUPFKQAArbN/ZtqzTYORYJPjAAAAgBsQnDpCahWndniYk2PdslF7wenBuqgipjX/NLFVn4pTAABaZwektOoDAADAzQhOHSCVitMCf4Ejqi5bC04DjZ2EdaGG2DG7Vd80qTgFAKAtrQWnAR+t+gAAAHAPglNH8EqSTDPSznkJFac5+aq17mZ1eNhuxWl9QnDaWHHa0BCf7UrFKQAALdmzTO3A1G7Zp+IUAAAAbkJw6gB2xWmHWvVDLVv18/O7bWndrt3gNNiy4tQJs10BAOhOsRmnjbNNadUHAACAGxGcOkLHW/VrQjWSmm4Olc3hYfvBaajFufZ8U8OQ/Pz+BwBAC6226ntp1QcAAIB7ZDQ4XbRokY499lgVFhZq4MCBOu+887Rx48Ym55x88skyDKPJ7YorrsjQinunTlWcJtkcKpuDU69hjSloLTita6w4zfHkyDAMSU3nmzYeAgAACZoHp3blKRWnAAAAcJOMBqevvvqq5s2bp5UrV+qll15SQ0ODzjjjDNXawzcbXXbZZdqxY0fsdvfdd2doxb1V5zeHcsuM0/rGzaHs+aZSvOKU+aYAACRnbwLVvOKU4BQAAABu4svkmy9durTJ48cff1wDBw7UqlWrdOKJJ8aO9+nTR+Xl5T29vKyRUsVpjjtmnNaF4hWnNidU2gIA0J1iM07DTWec0qoPAAAAN+lVM06rqqokSSUlJU2OP/HEEyotLdXEiRO1cOFCHUzc3QdKqeLUIa36Ha04TayQoeIUAIC2tWjVD9OqDwAAAPfJaMVpomg0qmuvvVYzZszQxIkTY8e/+c1vasSIERo8eLDef/993Xjjjdq4caOeeeaZpNcJBoMKBoOxxwcOHOj2tWea0Tjn0zQj7Z5rV5wW+Asc3aofaCyIqW+wfuFLbNV3QmAMAEB3am1zKIJTAAAAuEmvCU7nzZundevW6d///neT45dffnns/qRJkzRo0CCddtpp+uSTTzRmzJgW11m0aJF+8pOfdPt6exO7Vb9DFacJrfrbHRAgtldxGgy3bNWn4hQAgLbZLfnNg1N79ikAAADgBr2iVX/+/Pl6/vnn9corr2jo0KFtnjtt2jRJ0qZNm5I+v3DhQlVVVcVuGzZsSPt6e59OzDhN0qrv5BmnwYaWm0NRcQoAQNtiM04jwSZfqTgFAACAm2S04tQ0TX3ve9/TX//6Vy1fvlyjRo1q9zVr1qyRJA0aNCjp84FAQIFAvBqiuro6LWvtzTpTcVoTqpHUdHOobA4QqTgFACD9aNUHAAAAMhyczps3T08++aSee+45FRYWqqKiQpJUXFysvLw8ffLJJ3ryySc1e/Zs9e/fX++//76uu+46nXjiiTriiCMyufRephMVpw3xilMnzTiNRJvOd40Hpy1/0XNCYAwAQHdqLTi1W/gBAAAAN8hocPrQQw9Jkk4++eQmxx977DF9+9vflt/v17/+9S8tXrxYtbW1GjZsmObMmaObbropA6vtvTo14zQUn3Hqhlb9UKRlqz4VpwAAtK35jFNa9QEAAOBGGW/Vb8uwYcP06quv9tBqsllqFadOqLxsNzhN0qrvhM8NAEB3is04DVuBKa36AAAAcKNesTkUusYwvJIk04y0c2byitNsDhDbC04b2qg4zebPDQBAd2q1Vd9Hqz4AAADcg+DUETrRqt9YcVrgL3DUjNPmwam9P1jYbH3GKa36AAAk1zw4tStPqTgFAACAmxCcOoA947S9Vv1QJBQLGBNb9Z0841Telq36VJwCANA2u7K0ecUpwSkAAADchODUETpWcWq36UvuadWXp2WrPhWnAAC0LTbjNMKMUwAAALgXwakDdLTitCZUI8mqvszx5ji6Vd/nkzweJa04dUJgDABAd2rRqt8YoAa8zDgFAACAexCcOkIHK04b55vm+63efCcEiK0Fp4bRWHWapOLUbtWn4hQAgORa2xyKilMAAAC4CcGpA3S04tRu1c/PyZdpylEzTiNmRKZpNnkuN1eSt/XNobI5MAYAoDvZlaUEpwAAAHAzglMHMAxv472OV5wGg5KdM2ZzgOj1eGP3I2akyXNWcNr65lBUnAIAkFxrM07tTaMAAAAANyA4dQS74jTS5lmJFae18X2isjo4tStOpVY2iPIw4xQAgM5qMeM0HGxyHAAAAHADglMHsFv1O1pxWuAviIWHfr+1kVK2ajc49TLjFACAzmLGKQAAAEBw6hCdnHHqz3dM1WVbwWkgIGacAgCQArslv3lwas8+BQAAANyA4NQBOltxmp/jjuC0tVZ9Kk4BAGhbi1b9CK36AAAAcB+CU0foWMXprtpdkqS+uX1jM06zPTj1GB4ZMiR1rFXfNKk4BQCgPbHNocJBmaZJqz4AAABcieDUATpacfrx3o8lSeNKxsXCw/z8blxYD7GrTjtScRoKWeGpRMUpAACtSaw4Tfz5arfwAwAAAG5AcOoIHas43bhnoyRpfOl4R1Vd2sFpJBppcjxZxan9uSVnfHYAALqDPcs0FAnF2vQlKk4BAADgLgSnDmAYXkmSaUZaPcc0TX205yNJ0iH9D3FMq77UTsVps82h7PmmHo+UkyMAAJBEYsWp3aafeBwAAABwA4JTR2i/VX9n7U5VB6vlMTwa02+MIytOO9Kqn/i5DaPHlggAQFaJzTiNBGPBqcfwNNmUEQAAAHA6glMHsGecttWqb7fpj+w7UgFfwD0zTpu16tsVp8w3BQCgdYkVp8FwsMkxAAAAwC0ITh2h/YrTxDZ9yVk7y7cWnAYCarPiFAAAJGdvApXYqk9wCgAAALchOHWAjlScxoLTEis4dfuMUypOAQBonf1zMxwNqz5cLym+YRQAAADgFgSnjtB+xandqj++dLwkubZVn4pTAADal1hdWhOqaXEMAAAAcAOCUwfoVMWpi1r1k20OZVecOuFzAwDQXRJD0gOhAy2OAQAAAG5AcOoAhuFtvBdJ+nw4GtYnez+R5MLgtJWKU1r1AQBoXbKKU3vuKQAAAOAWBKeO0HbF6Wf7P1NDtEF5vjwNLRoqyUUzTqk4BQCg0zyGJ/bz9UCQilMAAAC4E8GpA9it+q3NOLXb9Mf1HydP47lOmnHq9VgVtx3ZHIqKUwAAOsb+2UmrPgAAANyK4NQR2q443bi7cWOo/uNjx9zaqk/FKQAAHWMHpbFWfS+t+gAAAHAXglMH6GjFqT3fVHJHq34goBat+lScAgDQMXZQSqs+AAAA3Irg1BHarjj9aG/L4NStFadO+twAAHSn5hWnBKcAAABwG4JTB2iv4rStVn0nzDhtOzhtOuPUbtWn4hQAgLYx4xQAAABuR3DqCNbmSMkqTmtCNdp2YJska3Mom5MqL9sMTltp1XfC5wYAoDs1D04DPmacAgAAwF0ITh3Arjg1zUiL5zbt3SRJKu1TqpK8kthxN8w4bWtzKCpOAQBomx2U0qoPAAAAtyI4dYTWW/WTtembpota9ak4BQAgJcw4BQAAgNsRnDpAvOK0ZXD60Z6WG0PV18efd0KAaAenkWYVt4kzTqk4BQCgc2Kt+sHGVn0vrfoAAABwF4JTR2i94vSjvS2DU7vqUnJGgNhaxak/EJU81n+THI/1yx8VpwAAdAybQwEAAMDtCE4doK2K02St+vZ8U79f8vm6f33drbXg1JvTELtvRKk4BQCgM+wKU1r1AQAA4FYEp46QvOLUNM2krfpOmm8qtR6cehKC02iYGacAAHRG8xmntOoDAADAbQhOHcAwvJJaVpzurN2pqmCVDBkaWzI2dtxp4WGrwakvHpxGQlScAgDQGXZwerDhYJPHAAAAgFsQnDqA3aovNd0cya42Hdl3pAK+eJWI44JTI3lwGjZD8fsh6xynfXYAALpL86CU4BQAAABuQ3DqCMlnnCZr05fiM06dEh62VnHaEG2sOI3kKBg0JFFxCgBARzVvzU/8R1gAAADADQhOHSBecdo0ON24p+XGUJJ7Zpw2ROLBaX29ZJpUnAIA0FFUnAIAAMDtCE4doXMVp04LD9utOI1awWkwGH+OilMAANpGcAoAAAC3Izh1gNYqTt3Squ/1WJtjNQ9OQ5HGGaeNFad2YCw557MDANBdmgelzVv3AQAAAKcjOHWElhWn4WhYm/ZukiSNL3V7q75f9fXx+aZer5ST05MrBAAg+zSfaUrFKQAAANyG4NQBklWcbtm/RQ3RBuX6cjW0aGiT893Yqh8MOu9zAwDQnWjVBwAAgNsRnDqC1apumpHYEbtNf1zJOHmMpt9mpwWIHd0cyq44dcrnBgCgO7Vo1ffRqg8AAAB3ITh1ALviNLFVf+OejZJatulLzptx2tHNoezAmI2hAABoHxWnAAAAcDuCU0do2aof2xiq5JAWZ7tlxml8cyg/FacAAHRS882gCE4BAADgNgSnDpCs4tQOTpNVnLq1VZ+KUwAAOq5Fq76XVn0AAAC4C8GpI7SsOLVb9Q/p33rFqeOD02at+lScAgDQcbTqAwAAoKuWLFmikSNHKjc3V9OmTdNbb73V5vmLFy/W+PHjlZeXp2HDhum6665TfX19D622JYJTBzBimz+ZMk1TtaFafVH9haTkwalTZ5xGEjbHkqg4BQCgKwhOAQAA0BVPPfWUFixYoFtvvVWrV6/W5MmTNWvWLO3cuTPp+U8++aR+8IMf6NZbb9UHH3ygRx55RE899ZR++MMf9vDK4whOHSHx22hq18FdkqQ8X55K8kpanO26GafNNodySmAMAEB3CvgCbT4GAAAA2nLffffpsssu09y5czVhwgQ9/PDD6tOnjx599NGk57/xxhuaMWOGvvnNb2rkyJE644wz9I1vfKPdKtXuRHDqAIbhjd03zYiC4aAkKdeXm/R8pwWI7bbqR/wKBuOt+lScAgDQPipOAQAA0NyBAwdUXV0duwWDwaTnhUIhrVq1SjNnzowd83g8mjlzplasWJH0Nccff7xWrVoVC0o3b96sF198UbNnz07/B+kgglMHiLfqS1JU9WFr9kNrlSFObdXv6OZQTvncAAB0J4JTAAAANDdhwgQVFxfHbosWLUp63u7duxWJRFRWVtbkeFlZmSoqKpK+5pvf/KZuu+02nXDCCcrJydGYMWN08sknZ7RV35exd0YaxYNT04wqGOlYxanTW/Vb2xyKilMAANpHcAoAAIDmNmzYoCFDhsQeBwLpG+e0fPly3XHHHXrwwQc1bdo0bdq0Sddcc41uv/123XzzzWl7n84gOHWAVitOvcn/8Dqt8pKKUwAA0q/53yNa+3sFAAAA3KOwsFBFRUXtnldaWiqv16vKysomxysrK1VeXp70NTfffLMuuugiXXrppZKkSZMmqba2Vpdffrl+9KMfyePp+cZ5WvUdoVnFaeOM09Za9Z0WIHZ0cygqTgEA6DgqTgEAAJAqv9+vKVOmaNmyZbFj0WhUy5Yt0/Tp05O+5uDBgy3CUa/X2tfHNM3uW2wbqDh1gOYVp2216kej7glOEzeHqg8773MDANCdmgelOd6cDK0EAAAA2WjBggW65JJLdMwxx2jq1KlavHixamtrNXfuXEnSxRdfrCFDhsTmpJ577rm67777dNRRR8Va9W+++Wade+65sQC1pxGcOkLTitO2WvXr6+P3HT/jNLFVP0TFKQAAnZEYnOZ4cuQxaFQCAABAx11wwQXatWuXbrnlFlVUVOjII4/U0qVLYxtGbd26tUmF6U033STDMHTTTTdp27ZtGjBggM4991z97Gc/y9RHIDh1AsNITN3bbtW3qy4l5wSIHd0ciopTAAA6LvHvEbTpAwAAIBXz58/X/Pnzkz63fPnyJo99Pp9uvfVW3XrrrT2wso4hOHUEI3bPNCNtturb4WEgIGWoyjntvI3BcaszThs3h8pp7DB0SmAMAEB3SgxLCU4BAADgRgSnDmAYhqzw1Gy3Vb+21vrqpKrL9lv1/QoG40Gxkz47AADdJTEsbW3DSQAAAMDJCE4dwyMposRW/bYqTp0y31TqeKu+0ViYS8UpAADto+IUAAAAbkdw6hCG4ZFpRtqtOHXinM8ObQ5VL5mm9dBJnx0AgO6S+PcIglMAAAC4EcGpY9i7kEVjM06TtdW5qlW/WcVpNGo9pOIUAID25XhzYveT/WMsAAAA4HSe9k9BNjAM61tpmrTq25pvDuXEalsAALqLx/DEfsZScQoAAAA3ouLUIYzGneUlWvVtsYrTiF/19fHNoag4BQCgY/xev8LRMMEpAAAAXImKU8ewK04jbbbquyo4jcRb9UMhqa7Oeuikzw4AQHey/xE22d8pAAAAAKcjOHUIu1VfartV38kzTiPRSJPj8YrTnCbHnfTZAQDoTnalKRWnAAAAcCOCU8eIzzitj7Tfqu+qGafRpsEprfoAAHQMwSkAAADcjODUIZJVnNKqb1WcGtH4L3s5OZKPyb4AAHSIHZgm+8dYAAAAwOkITh0jXnFqzzhN1qrvquC0sVU/xxuvOKXaFACAjrP/EZaKUwAAALgRwalDJFac1odbb9V39IxTMyLTNGPH7YpTf0Jw6qTPDQBAd6NVHwAAAG5GcOoYXkmNFadtbA7l5BmnkhWe2uwZp34fFacAAKSCVn0AAAC4GcGpQ9gVp6YZiVecumzGqdS0Xd9u1U8MTp30uQEA6G5UnAIAAMDNCE4dI2FzqMYZp25r1ZeaBaeNrfqBhF/2qDgFAKDj7L9LEJwCAADAjQhOHSJeceruVv1kFaeBHCpOAQBIRaxVP0kXCwAAAOB0BKeOkWRzKJe06ns93tj9pBWnzDgFACAltOoDAADAzQhOHaJJxWkbrfpODE49hkeGDElNg1N7c6hcKk4BAEgJwSkAAADcjODUMRJmnLbRqu/EGadSvF0/Wat+bg4zTgEASEVejvWDM9nfKQAAAACn87V/CrJBYsVpR1r1nTTjVLKC04ZoQ9JW/Vw/FacAAKTiO0d9R3sO7tH5h52f6aUAAAAAPY7g1CEMw5rzaZrhWKv+6rcCGnlG0/Oc2KovtV1xmudnxikAAKk4ccSJOnHEiZleBgAAAJARtOo7hvWtbIg0KGpGJUkX/EeutmyJnxGNSnV11n03BKf2jNO8ABWnAAAAAAAA6ByCU4ewW/XtalNJCtcH9LOfxc+xQ1PJma36Ujw4jZrRWIBMxSkAAAAAAAA6i+DUMRqD03A8OFU4oMcekzZvth7abfqS8wLE5sGpPd9UkvoE4ptDUXEKAAAAAACAjiA4dYh4xam1MZQiPsn0KhyWfvpT65AdnObmSh6Hfeft4DQSjUiKzzeVmrbqOy0wBgAAAAAAQPdwWHzmZta3sj5szfVUJBALR3/7W+njj527MZTUTsVpLjNOAQAAAAAA0DkEpw5hV5yG7Bmn4Vz17y+dfbYUiUi33y7V1lpPOW2+qdQyOLU3hpKkPgFf7D4VpwAAAAAAAOgIglPH8EqS6u0Zp+GAvF7pJz+xHj7xhLR6tXXfiVWXLSpOG1v1czw5ysszYuc58bMDAAAAAAAg/QhOHcKuOI0Fp5GAfD5pyhTpK1+RotF4iOrE8LC1Vv0cb45yc+PnUXEKAAAAAACAjiA4dYzGVv1oY4t6OFdeqwhVP/6x9XX7duurK4LThIrTxODUiZ8dAAAAAAAA6Udw6hAtKk4bW/Ul6cgjpTlz4ue6acZp84pTglMAAAAAAAB0BMGpY9ibQ7WsOJWsqlOjcdSnE8PDVlv1PbTqAwAAAAAAoPMITh0iXnHaGJxGAk2C04kTpa9/3bpfXNzDi+sBrbXq+71+Kk4BAAAAAADQab5MLwDpYgWnwVjFadPgVJIWL5ZKSqTvfrdnV9YTvB7rwybbHCoQiJ9HxSkAAAAAAAA6guDUIQzDCg6DrbTqS1J5ufTggz28sB7C5lAAAAAAAABIJ1r1HcJu1Q+20qrvdB3dHIqKUwAAAAAAAHQEwaljtGzV97monri1zaESZ5z6/XJVmAwAAAAAAIDUuShacza74jTUGBgma9V3srZa9YcOtTbEGjs2Y8sDAAAAAABAliE4dQwrOK2P0KovNd0cqqBA+vRTNWnZBwAAAAAAANpCcOoQLStO3R2cxmacenIkSf36ZWZdAAAAAAAAyE4ZnXG6aNEiHXvssSosLNTAgQN13nnnaePGjU3Oqa+v17x589S/f38VFBRozpw5qqyszNCKezNa9aUkrfrenIytCQAAAAAAANkro8Hpq6++qnnz5mnlypV66aWX1NDQoDPOOEO1tbWxc6677jr97W9/05///Ge9+uqr2r59u84///wMrrp3MgwrJQ3awSmt+pKszaEAAAAAAACAzspoq/7SpUubPH788cc1cOBArVq1SieeeKKqqqr0yCOP6Mknn9Spp54qSXrsscd02GGHaeXKlTruuOMysexeysrAg4kVpy6a6ekzrD/KETMiqenmUAAAAAAAAEBnZbTitLmqqipJUklJiSRp1apVamho0MyZM2PnHHrooRo+fLhWrFiR9BrBYFDV1dWx24EDB7p/4b2APeM0GGbGqZQw45RWfQAAAAAAAKSg1wSn0WhU1157rWbMmKGJEydKkioqKuT3+9W3b98m55aVlamioiLpdRYtWqTi4uLYbcKECd299F6iWcUprfqSqDgFAAAAAABAanpNcDpv3jytW7dOf/zjH7t0nYULF6qqqip227BhQ5pW2LvZFaehxuBQ4Vz5MjqIoWe1tjkUM04BAAAAAACQil4Rrc2fP1/PP/+8XnvtNQ0dOjR2vLy8XKFQSPv3729SdVpZWany8vKk1woEAgoEArHH1dXV3bbu3qX5jFMqTiUqTgEAAAAAAJCajFacmqap+fPn669//atefvlljRo1qsnzU6ZMUU5OjpYtWxY7tnHjRm3dulXTp0/v6eX2arGK00hjxanbW/XtzaGYcQoAAAAAAIAUZLTidN68eXryySf13HPPqbCwMDa3tLi4WHl5eSouLtZ3vvMdLViwQCUlJSoqKtL3vvc9TZ8+Xccdd1wml97rGIaVksaC03Cuq4PT2OZQVJwCAAAAAAAgBRkNTh966CFJ0sknn9zk+GOPPaZvf/vbkqT7779fHo9Hc+bMUTAY1KxZs/Tggw/28EqzgVVxWh8LTl1ecRqh4hQAAAAAAACpy2hwappmu+fk5uZqyZIlWrJkSQ+sKHu5vVXf67E+LJtDAQAAAAAAIB0yOuMU6WRvDkWrvsTmUAAAAAAAAOgaglOHiFWcRmnVl6RQtHHGKa36AAAAAAAASAHBqWPYrfoR62E4V76MDmLoWVScAgAAAAAAIJ0ITh3CrjgNunTGaYvglBmnAAAAAAAA6AKCU8fwyDSlUNSuOHV5cGpXnNKqDwAAAAAAgBQQnDqEYXgVNhMOuH1zqCit+gAAAAAAAEgdwaljeBSKJjx0eat+KMLmUAAAAAAAAEgdwalDGIZHDU2CU7+rg1M2hwIAAAAAAEBXEJw6hkcNja36HtMvmR5XBqcR05rxyuZQAAAAAAAA6AqCU4cwjHirvtcMWF9dGJyyORQAAAAAAADSgeDUMQhOpSQzTmnVBwAAAAAAQAoITh2iacVpriTJ58vggnpYi4rTKBWnAAAAAAAASB3BqUMYhje2OZSHitNYqz4zTgEAAAAAAJAKglPH8MSD06hVcerq4NSuOKVVHwAAAAAAACkgOHWIxFZ9Kk7ZHAoAAAAAAABdQ3DqGB41mI33ogSnbA4FAAAAAACAriA4dYgmFae06rM5FAAAAAAAALqE4NQx4sGp4cKKU69hfVg2hwIAAAAAAEA6EJw6hGHEN4cyIu4LTtkcCgAAAAAAAOlEcOoY3hat+j5fBpfTw1qdcUqrPgAAAAAAAFJAcOoQhhHfHEourziNmlFFTStFpuIUAAAAAAAAqSA4dQxa9SUrOLXnm0pUnAIAAAAAACA1BKcOYRgJm0NFrFZ91wan0XhwyuZQAAAAAAAASAXBqWPEK07d3qrfpOKUVn0AAAAAAACkgODUIQzDo1DjjFMj7O6KU3tjqMTjAAAAAAAAQGcQnDpGvFXfzRWnUTMaa9X3eXwyDCOTywIAAAAAAECWIjh1CMPwxlr1zbB7g1NJqmuok8R8UwAAAAAAAKSO4NQhDCNhxqmLW/UlqS5sBafMNwUAAAAAAECqCE4dI6FVv7Hi1Oei8Z6JwenBhoOSpBwvwSkAAAAAAABSQ3DqEIkVp2YDrfoSFacAAAAAAABIHcGpY8QrTk0Xtup7PfEPG2vVp+IUAAAAAAAAKSI4dQjD8KjBtO67seLUY3jkMaw/zmwOBQAAAAAAgK4iOHWMxIpT9wWnUrxdPzbjlFZ9AAAAAAAApIjg1CEMwxsPTkPua9WX4sEprfoAAAAAAADoKoJTx4hvDhV1Yau+JHkN6wOzORQAAAAAAAC6iuDUIRJnnEapOJXEjFMAAAAAAACkjuDUMeIzTt1acRoLThto1QcAAAAAAEDXEJw6hGEktOqHrODU58vggjKAzaEAAAAAAACQLgSnjpFQcUqrviQqTgEAAAAAAJA6glOHMCWFYzNOadWXqDgFAAAAAABA6ghOHSIUicTuR9wenLI5FAAAAAAAQMYtWbJEI0eOVG5urqZNm6a33nqr1XNPPvlkGYbR4nb22Wf34IqbIjh1iGBicBp0d6t+bMYprfoAAAAAAAAZ8dRTT2nBggW69dZbtXr1ak2ePFmzZs3Szp07k57/zDPPaMeOHbHbunXr5PV69bWvfa2HVx5HcOoQDdFw7H6kwQoM3Rqc1ofrJdGqDwAAAAAAkCn33XefLrvsMs2dO1cTJkzQww8/rD59+ujRRx9Nen5JSYnKy8tjt5deekl9+vQhOEXX2RWnfo8hM2pIcm9wGtsciuAUAAAAAAAgbQ4cOKDq6urYLRgMJj0vFApp1apVmjlzZuyYx+PRzJkztWLFig691yOPPKILL7xQ+fn5aVl7KghOHSIYbZAk+RO+o64NThuYcQoAAAAAAJBuEyZMUHFxcey2aNGipOft3r1bkUhEZWVlTY6XlZWpoqKi3fd56623tG7dOl166aVpWXeqfBl9d6RNKGy16ucYRuyYz2Xf3RYVp8w4BQAAAAAASJsNGzZoyJAhsceBQKBb3ueRRx7RpEmTNHXq1G65fke5LFpzrlDjjNMcTzw4dWvFaWxzKFr1AQAAAAAA0qawsFBFRUXtnldaWiqv16vKysomxysrK1VeXt7ma2tra/XHP/5Rt912W5fWmg606jtEfdhq1U+sOHVrcGq36lNxCgAAAAAA0PP8fr+mTJmiZcuWxY5Fo1EtW7ZM06dPb/O1f/7znxUMBvWtb32ru5fZLipOHSIUtTaHIjhlcygAAAAAAIBMW7BggS655BIdc8wxmjp1qhYvXqza2lrNnTtXknTxxRdryJAhLeakPvLIIzrvvPPUv3//TCy7CYJThwiGQ5KkHCNeROza4JTNoQAAAAAAADLqggsu0K5du3TLLbeooqJCRx55pJYuXRrbMGrr1q3yeJo2w2/cuFH//ve/9c9//jMTS26B4NQh7BmnvoSKU4/LBjHYwWkwEpREqz4AAAAAAEAmzZ8/X/Pnz0/63PLly1scGz9+vEzT7OZVdZzLojXnCkasGad2cOrxSAkZqit4PU1LbGnVBwAAAAAAQKoITh0iFpw2fkvd1qYvxStObVScAgAAAAAAIFUEpw4RDNvBqVVmSnDKjFMAAAAAAACkjuDUIULRphWnPhdOr21RcUqrPgAAAAAAAFJEcOoQwUhIUnzGKRWntOoDAAAAAAAgdQSnDmG36ntNF884Nag4BQAAAAAAcKNXXnkl7dckOHUIKk6pOAUAAAAAAHCrM888U2PGjNFPf/pTff7552m5JsGpQ9jBqde0ElOCUzaHAgAAAAAAcItt27Zp/vz5evrppzV69GjNmjVLf/rTnxQKhVK+JsGpQ4Qidqs+wamNVn0AAAAAAAB3KC0t1XXXXac1a9bozTff1CGHHKKrrrpKgwcP1tVXX6333nuv09ckOHWI+nBQkuQTwamNVn0AAAAAAAD3Ofroo7Vw4ULNnz9fNTU1evTRRzVlyhR96Utf0vr16zt8HYJTh6BVn4pTAAAAAAAAN2toaNDTTz+t2bNna8SIEfrHP/6hX/ziF6qsrNSmTZs0YsQIfe1rX+vw9Xztn4JsEGvVb/yW+lz4nWXGKQAAAAAAgDt973vf0x/+8AeZpqmLLrpId999tyZOnBh7Pj8/X//93/+twYMHd/iaLozXnMlu1afiNI5WfQAAAAAAAHfYsGGDfv7zn+v8889XIBBIek5paaleeeWVDl+T4NQh7FZ9j2l9SwlOadUHAAAAAABwi2XLlrV7js/n00knndThazLj1CFCsRmnBKc2Kk4BAAAAAADcYdGiRXr00UdbHH/00Ud11113pXRNglOHqA/XSyI4TUTFKQAAAAAAgDv88pe/1KGHHtri+OGHH66HH344pWsSnDqE3apvRAlObWwOBQAAAAAA4A4VFRUaNGhQi+MDBgzQjh07UromwalD2BWnnqhVZUlwSqs+AAAAAACAWwwbNkyvv/56i+Ovv/66Bg8enNI12RzKIYLhoCR3B6deT9MPTas+AAAAAACAO1x22WW69tpr1dDQoFNPPVWStWHUDTfcoOuvvz6laxKcOkQw0hicMuM0hopTAAAAAAAAd/j+97+vPXv26KqrrlIoZI20zM3N1Y033qiFCxemdE2CU4eIt+pbcz19LvzOMuMUAAAAAADAnQzD0F133aWbb75ZH3zwgfLy8jRu3DgFAoGUr+nCeM2Z7FZ9I+LeVv0WFae06gMAAAAAALhKQUGBjj322LRci+DUIWKt+i6ecdo8OG3+GAAAAAAAAM71zjvv6E9/+pO2bt0aa9e3PfPMM52+niddC0PmRKIRhaNhSQSnifcNw8jgagAAAAAAANBT/vjHP+r444/XBx98oL/+9a9qaGjQ+vXr9fLLL6u4uDilaxKcOoBdbSpJRuOMU7cHp7TpAwAAAAAAuMcdd9yh+++/X3/729/k9/v1wAMP6MMPP9TXv/51DR8+PKVrphSc/uY3v9ELL7wQe3zDDTeob9++Ov7447Vly5aUFoLU2fNNJcmIWANv3R6csjEUAAAAAACAe3zyySc6++yzJUl+v1+1tbUyDEPXXXedfvWrX6V0zZSC0zvuuEN5eXmSpBUrVmjJkiW6++67VVpaquuuuy6lhSB19eF6SdY302RzKElSjpeKUwAAAAAAALfo16+fDhw4IEkaMmSI1q1bJ0nav3+/Dh48mNI1U9o95/PPP9fYsWMlSc8++6zmzJmjyy+/XDNmzNDJJ5+c0kKQOrtVP8cjRaNWYur64JRWfQAAAAAAANc48cQT9dJLL2nSpEn62te+pmuuuUYvv/yyXnrpJZ122mkpXTOl4LSgoEB79uzR8OHD9c9//lMLFiyQJOXm5qquri6lhSB1dsWp32PEglOfCzeUp+IUAAAAAADAnX7xi1+ovt7KyH70ox8pJydHb7zxhubMmaObbroppWumFK+dfvrpuvTSS3XUUUfpo48+0uzZsyVJ69ev18iRI1NaCFJnzzhNDE7dXnHKjFMAAAAAAAB3CIfDev755zVr1ixJksfj0Q9+8IMuXzelGadLlizR9OnTtWvXLv3lL39R//79JUmrVq3SN77xjS4vCp0Tb9UnOLXRqg8AAAAAAOAOPp9PV1xxRaziNG3XTeVFffv21S9+8YsWx3/yk590eUHovMRW/UiE4FSiVR8AAAAAAMBNpk6dqjVr1mjEiBFpu2ZKwenSpUtVUFCgE044QZJVgfrrX/9aEyZM0JIlS9SvX7+0LRDto1XfQsUpAAAAAACAO1111VVasGCBPv/8c02ZMkX5+flNnj/iiCM6fc2UgtPvf//7uuuuuyRJa9eu1fXXX68FCxbolVde0YIFC/TYY4+lclmkKN6q7yE4bUTFKQAAAAAAgHtceOGFkqSrr746dswwDJmmKcMwFIlEOn3NlILTTz/9VBMmTJAk/eUvf9E555yjO+64Q6tXr45tFIWeY7fqB7yGIhHrW+r24JTNoQAAAAAAANzj008/Tfs1UwpO/X6/Dh48KEn617/+pYsvvliSVFJSourq6vStDh1it+q7veLUa8Q/NK36AAAAAAAA7pHO2aa2lILTE044QQsWLNCMGTP01ltv6amnnpIkffTRRxo6dGhaF4j2xSpO2Rwqdp9WfQAAAAAAAPf47W9/2+bzduFnZ6QUnP7iF7/QVVddpaeffloPPfSQhgwZIkn6+9//rjPPPDOVS6ILks049aX0nc1ubA4FAAAAAADgTtdcc02Txw0NDTp48KD8fr/69OnTc8Hp8OHD9fzzz7c4fv/996dyOXSR3arv97q7VZ8ZpwAAAAAAAO60b9++Fsc+/vhjXXnllfr+97+f0jVTrkuMRCJ69tln9cEHH0iSDj/8cH35y1+W142JXYbZrfp+l884pVUfAAAAAAAAtnHjxunOO+/Ut771LX344Yedfn1KwemmTZs0e/Zsbdu2TePHj5ckLVq0SMOGDdMLL7ygMWPGpHJZpMhu1fd7vGpgxqkkWvUBAAAAAAAg+Xw+bd++PbXXpvKiq6++WmPGjNHKlStVUlIiSdqzZ4++9a1v6eqrr9YLL7yQ0mKQmsRW/SAVp5IITgEAAAAAANzk//7v/5o8Nk1TO3bs0C9+8QvNmDEjpWumFJy++uqrTUJTSerfv7/uvPPOlBeC1Nmt+gGPR/sj1rfU9cEprfoAAAAAAACucd555zV5bBiGBgwYoFNPPVX33ntvStdMKTgNBAI6cOBAi+M1NTXy+9mUp6fZrfo5Hi8zThuxORQAAAAAAIB7RKPRtF/Tk8qLzjnnHF1++eV68803ZZqmTNPUypUrdcUVV+jLX/5yuteIdtit+gGvu4NTryf+oWnVBwAAAAAAQFekFJz+z//8j8aMGaPp06crNzdXubm5Ov744zV27FgtXrw4zUtEe+ojVqu+3+NRxMWbQ3kMjzyG9UeaVn0AAAAAAAD3mDNnju66664Wx++++2597WtfS+maKbXq9+3bV88995w2bdqkDz74QJJ02GGHaezYsSktAl0T3xwqXnHqS+k7m/18Hp9CkRAVpwAAAAAAAC7y2muv6cc//nGL42eddVb3zzhdsGBBm8+/8sorsfv33XdfSotBamKbQ3l9rm7VlxKCUypOAQAAAAAAXKO1vZdycnJUXV2d0jU7HJy+++67HTrPMIyUFoLU2ZtD+V2+OZQU3yCKzaEAAAAAAADcY9KkSXrqqad0yy23NDn+xz/+URMmTEjpmh0OThMrStPltdde0z333KNVq1Zpx44d+utf/6rzzjsv9vy3v/1t/eY3v2nymlmzZmnp0qVpX0s2S9aq7/bglFZ9AAAAAAAA97j55pt1/vnn65NPPtGpp54qSVq2bJn+8Ic/6M9//nNK18zoJMza2lpNnjxZ//Vf/6Xzzz8/6TlnnnmmHnvssdjjQCDQU8vLGomt+m7eHEpKCE5p1QcAAAAAAHCNc889V88++6zuuOMOPf3008rLy9MRRxyhf/3rXzrppJNSumZGg9OzzjpLZ511VpvnBAIBlZeX99CKslOsVd/rVSRifUtdH5xScQoAAAAAAOAqZ599ts4+++y0Xc+Ttit1k+XLl2vgwIEaP368rrzySu3Zs6fN84PBoKqrq2O3AwcO9NBKMyfWqu9hcyivYX1wZpwCAAAAAAC4x9tvv60333yzxfE333xT77zzTkrX7NXB6Zlnnqnf/va3WrZsme666y69+uqrOuussxSJRFp9zaJFi1RcXBy7pTr8NZvEW/WZcUqrPgAAAAAAgPvMmzdPn3/+eYvj27Zt07x581K6ZkZb9dtz4YUXxu5PmjRJRxxxhMaMGaPly5frtNNOS/qahQsXasGCBbHH27Ztc3x4GmvVT6g49fXq72z3oVUfAAAAAADAfTZs2KCjjz66xfGjjjpKGzZsSOmavbritLnRo0ertLRUmzZtavWcQCCgoqKi2K2wsLAHV5gZsYpTXw6bQ1FxCgAAAAAA4DqBQECVlZUtju/YsUO+FCsMsyo4/eKLL7Rnzx4NGjQo00vpVZhxGkfFKQAAAAAAgPucccYZWrhwoaqqqmLH9u/frx/+8Ic6/fTTU7pmRhu6a2pqmlSPfvrpp1qzZo1KSkpUUlKin/zkJ5ozZ47Ky8v1ySef6IYbbtDYsWM1a9asDK66dzFNM9aqH/ASnBYFiiRJxbnFGV4JAAAAAAAAesp///d/68QTT9SIESN01FFHSZLWrFmjsrIy/e53v0vpmhkNTt955x2dcsopscf2bNJLLrlEDz30kN5//3395je/0f79+zV48GCdccYZuv322xUIBDK15F4nHA0rakYlSX5vjuuD03vPuFevfPaKThh+QqaXAgAAAAAAgB4yZMgQvf/++3riiSf03nvvKS8vT3PnztU3vvEN5eSk1pmc0eD05JNPlmmarT7/j3/8owdXk53salPJqjiNRKxvqVuD02lDp2na0GmZXgYAAAAAAAB6WH5+vk444QQNHz5coVBIkvT3v/9dkvTlL3+509dz6d7rzmHPN5Ukv9fn+s2hAAAAAAAA4D6bN2/WV7/6Va1du1aGYcg0TRmGEXs+Eol0+ppZtTkUWqoP10uyNkXysTkUAAAAAAAAXOiaa67RqFGjtHPnTvXp00fr1q3Tq6++qmOOOUbLly9P6ZpUnGa5+MZQARmGl+AUAAAAAAAArrNixQq9/PLLKi0tlcfjkdfr1QknnKBFixbp6quv1rvvvtvpa1JxmuXsVv2ALyDJEwtOfUTiAAAAAAAAcIlIJKLCwkJJUmlpqbZv3y5JGjFihDZu3JjSNYnXspzdqp/ry5VheKg4BQAAAAAAgOtMnDhR7733nkaNGqVp06bp7rvvlt/v169+9SuNHj06pWsSnGa5xFZ9ycPmUAAAAAAAAHCdm266SbW1tZKk2267Teecc46+9KUvqX///nrqqadSuibBaZaj4hQAAAAAAABuN2vWrNj9sWPH6sMPP9TevXvVr18/GYaR0jUJTrNcazNOCU4BAAAAAADgZiUlJV16PZtDZbnEVn3D8CgSsbJwglMAAAAAAAAgdQSnWS6xVV/yUnEKAAAAAAAApAHBaZZLbNW3Kk4JTgEAAAAAAICuIjjNcomt+okzTn1MrwUAAAAAAABSRnCa5RJb9Q2DzaEAAAAAAACAdCA4zXKJrfqJFacEpwAAAAAAAEDqCE6znF1x2rxVn+AUAAAAAAAASB3BaZazZ5zm+nJjoalEcAoAAAAAAAB0BcFplou16nsDikRyYscJTgEAAAAAAIDUEZxmucTNoUyTilMAAAAAAAAgHQhOs5zdqh/wBRSJ+GLHCU4BAAAAAACA1BGcZrlYcOoNMOMUAAAAAAAASBNf+6egN0ts1Y9GzdhxH99ZAAAAAAAAIGVUnGa52OZQvqYVpx6+swAAAAAAAEDKiNeyXGKrfiRiBaceT1SGkclVAQAAAAAAANmN4DTLJbbqm6bVn+/xRDO5JAAAAAAAACDrEZxmucRW/XDYCk69XoJTAAAAAAAAoCsITrOcx/DI5/Ep4I3POKXiFAAAAAAAAOga9l7Pcq/NfU2SZJqm/l/FE5KoOAUAAAAAAAC6iopThzAMI6HiNJLh1QAAAAAAAADZjeDUQSIR69vp81FxCgAAAAAAAHQFwamDUHEKAAAAAAAApAfBqYOwORQAAAAAAACQHgSnDhKNWnt9sTkUAAAAAAAA0DUEpw4SjVrfTlr1AQAAAAAAkGlLlizRyJEjlZubq2nTpumtt95q8/z9+/dr3rx5GjRokAKBgA455BC9+OKLPbTalnwZe2ekXThMqz4AAAAAAAAy76mnntKCBQv08MMPa9q0aVq8eLFmzZqljRs3auDAgS3OD4VCOv300zVw4EA9/fTTGjJkiLZs2aK+ffv2/OIbEZw6iD3j1Oul4hQAAAAAAACZc9999+myyy7T3LlzJUkPP/ywXnjhBT366KP6wQ9+0OL8Rx99VHv37tUbb7yhnJwcSdLIkSN7cskt0KrvIGwOBQAAAAAAgO5y4MABVVdXx27BYDDpeaFQSKtWrdLMmTNjxzwej2bOnKkVK1Ykfc3//d//afr06Zo3b57Kyso0ceJE3XHHHYpEMlcgSHDqIPaMUypOAQAAAAAAkG4TJkxQcXFx7LZo0aKk5+3evVuRSERlZWVNjpeVlamioiLpazZv3qynn35akUhEL774om6++Wbde++9+ulPf5r2z9FRtOo7SCRCcAoAAAAAAIDusWHDBg0ZMiT2OBAIpO3a0WhUAwcO1K9+9St5vV5NmTJF27Zt0z333KNbb701be/TGQSnDhKNWt9Oj4fgFAAAAAAAAOlVWFiooqKids8rLS2V1+tVZWVlk+OVlZUqLy9P+ppBgwYpJydHXq83duywww5TRUWFQqGQ/H5/1xafAlr1HcSuOGXGKQAAAAAAADLF7/drypQpWrZsWexYNBrVsmXLNH369KSvmTFjhjZt2qRoNJ5rffTRRxo0aFBGQlOJ4NRR7BmnVJwCAAAAAAAgkxYsWKBf//rX+s1vfqMPPvhAV155pWprazV37lxJ0sUXX6yFCxfGzr/yyiu1d+9eXXPNNfroo4/0wgsv6I477tC8efMy9RFo1XeScNgqZWbGKQAAAAAAADLpggsu0K5du3TLLbeooqJCRx55pJYuXRrbMGrr1q3yeOI1ncOGDdM//vEPXXfddTriiCM0ZMgQXXPNNbrxxhsz9REITp2EilMAAAAAAAD0FvPnz9f8+fOTPrd8+fIWx6ZPn66VK1d286o6jlZ9B4nPOCU4BQAAAAAAALqC4NRBqDgFAAAAAAAA0oPg1EGiUWvGqc8XzvBKAAAAAAAAgOxGcOogtOoDAAAAAAAA6UFw6iC06gMAAAAAAADpQXDqIPGKU1r1AQAAAAAAgK4gOHUQKk4BAAAAAACA9CA4dZBwmOAUAAAAAAAASAeCUweJRg1JktdLcAoAAAAAAAB0BcGpg0QiXknMOAUAAAAAAAC6iuDUQeyKU1r1AQAAAAAAgK4hOHWQSMT6dnq9VJwCAAAAAAAAXUFw6iDRqPXtNAyCUwAAAAAAAKArCE4dJBKxN4ciOAUAAAAAAAC6guDUQeyKUzaHAgAAAAAAALqG4NRBwmE2hwIAAAAAAADSgeDUQezNoag4BQAAAAAAALqG4NRBolG74pTgFAAAAAAAAOgKglMHsTeHolUfAAAAAAAA6BqCUweJbw7VkOGVAAAAAAAAANmN4NRB7IpTr5fgFAAAAAAAAOgKglMHibfqM+MUAAAAAAAA6AqCUwchOAUAAAAAAADSg+DUQaJRglMAAAAAAAAgHQhOHSQctoPTiEzTzPBqAAAAAAAAgOxFcOog8Vb9iKRoZhcDAAAAAAAAZDGCUwdJDE5NM5Lh1QAAAAAAAADZi+DUQewZp15vRKZJxSkAAAAAAACQKoJTB7ErTr3esGjVBwAAAAAAAFJHcOogTVv1CU4BAAAAAACAVBGcOkikcawpm0MBAAAAAAAAXUNw6iBUnAIAAAAAAADpQXDqIPEZp1ScAgAAAAAAAF1BcOogia36VJwCAAAAAAAAqSM4dZDEVn0pktnFAAAAAAAAAFmM4NRBqDgFAAAAAAAA0oPg1EHs4JQZpwAAAAAAAEDXEJw6SDw4DVNxCgAAAAAAAHQBwamDJLbqU3EKAAAAAAAApI7g1EGYcQoAAAAAAACkB8Gpg1BxCgAAAAAAAKQHwamDhMPWV683ItOMZHYxAAAAAAAAQBYjOHUQWvUBAAAAAACA9CA4dRBa9QEAAAAAAID0IDh1ECpOAQAAAAAAgPQgOHUQOzj1esOi4hQAAAAAAABIHcGpg8SDUypOAQAAAAAAgK4gOHUQZpwCAAAAAAAA6UFw6iBNZ5xGMrsYAAAAAAAAIIsRnDpIOGx9peIUAAAAAAAA6BqCUwdhxikAAAAAAACQHgSnDsKMUwAAAAAAACA9CE4dpOmMU4JTAAAAAAAAIFUEpw5hmlK0MSul4hQAAAAAAADoGoJTh4gm5KReb5iKUwAAAAAAAKALCE4dwm7Tl6zNoag4BQAAAAAAAFKX0eD0tdde07nnnqvBgwfLMAw9++yzTZ43TVO33HKLBg0apLy8PM2cOVMff/xxZhbbyyUGp9aM00jrJwMAAAAAAABoU0aD09raWk2ePFlLlixJ+vzdd9+t//mf/9HDDz+sN998U/n5+Zo1a5bq6+t7eKW9Xzgcv8/mUAAAAAAAAEDX+DL55meddZbOOuuspM+ZpqnFixfrpptu0le+8hVJ0m9/+1uVlZXp2Wef1YUXXtiTS+31mlec0qoPAAAAAAAApK7Xzjj99NNPVVFRoZkzZ8aOFRcXa9q0aVqxYkWrrwsGg6quro7dDhw40BPLzbjmM06pOAUAAAAAAABS12uD04qKCklSWVlZk+NlZWWx55JZtGiRiouLY7cJEyZ06zp7CypOAQAAAAAAgPTptcFpqhYuXKiqqqrYbcOGDZleUo+wg1PDiMowRMUpAAAAAAAA0AW9NjgtLy+XJFVWVjY5XllZGXsumUAgoKKiotitsLCwW9fZW9jBqddrl54SnAIAAAAAAACp6rXB6ahRo1ReXq5ly5bFjlVXV+vNN9/U9OnTM7iy3ikenFqBqWlG2jgbAAAAAAAAQFt8mXzzmpoabdq0Kfb4008/1Zo1a1RSUqLhw4fr2muv1U9/+lONGzdOo0aN0s0336zBgwfrvPPOy9yieyk7OPV47EpTKk4BAAAAAACAVGU0OH3nnXd0yimnxB4vWLBAknTJJZfo8ccf1w033KDa2lpdfvnl2r9/v0444QQtXbpUubm5mVpyr9W8VZ8ZpwAAAAAAAEDqMhqcnnzyyTJNs9XnDcPQbbfdpttuu60HV5WdwmHrKxWnAAAAAAAAQNf12hmn6JyWM04JTgEAAAAAAIBUEZw6BDNOAQAAAAAAgPQhOHWIeHBqjT6g4hQAAAAAAABIHcGpQ7Rs1Y9kcDUAAAAAAABAdiM4dYh4cGoHplScAgAAAAAAAKkiOHUINocCAAAAAAAA0ofg1CGazzil4hQAAAAAAABIHcGpQ4TD1lcqTgEAAAAAAICuIzh1iHirPhWnAAAAAAAAQFcRnDpEvFWfilMAAAAAAACgqwhOHaL55lBSJGNrAQAAAAAAALIdwalDNN8ciopTAAAAAAAAIHUEpw7BjFMAAAAAAAAgfQhOHaJ5qz4VpwAAAAAAAEDqCE4dgopTAAAAAAAAIH0ITh2CilMAAAAAAAAgfQhOHSIctr5ScQoAAAAAAAB0HcGpQ9gVpx6PFZxScQoAAAAAAACkjuDUIZrPODXNSAZXAwAAAAAAAGQ3glOHaF5xSqs+AAAAAAAAkDqCU4doWXFKcAoAAAAAAACkiuDUIezg1OezA1OCUwAAAAAAACBVBKcOQcUpAAAAAAAAkD4Epw4RD07tIwSnAAAAAAAAQKoITh0iHLa+2ptDUXEKAAAAAAAApI7g1CGat+pLkYytBQAAAAAAAFiyZIlGjhyp3NxcTZs2TW+99Var5z7++OMyDKPJLTc3twdX2xLBqUMw4xQAAAAAAAC9xVNPPaUFCxbo1ltv1erVqzV58mTNmjVLO3fubPU1RUVF2rFjR+y2ZcuWHlxxSwSnDsGMUwAAAAAAAPQW9913ny677DLNnTtXEyZM0MMPP6w+ffro0UcfbfU1hmGovLw8disrK+vBFbdEcOoQdnDKjFMAAAAAAAB0hwMHDqi6ujp2CwaDSc8LhUJatWqVZs6cGTvm8Xg0c+ZMrVixotXr19TUaMSIERo2bJi+8pWvaP369Wn/DJ1BcOoQVJwCAAAAAACgO02YMEHFxcWx26JFi5Ket3v3bkUikRYVo2VlZaqoqEj6mvHjx+vRRx/Vc889p9///veKRqM6/vjj9cUXX6T9c3SUL2PvjLSyg1Ofj4pTAAAAAAAApN+GDRs0ZMiQ2ONAIJC2a0+fPl3Tp0+PPT7++ON12GGH6Ze//KVuv/32tL1PZxCcOkTzzaGoOAUAAAAAAEA6FRYWqqioqN3zSktL5fV6VVlZ2eR4ZWWlysvLO/ReOTk5Ouqoo7Rp06aU1poOtOo7RPNWfdOMZG4xAAAAAAAAcC2/368pU6Zo2bJlsWPRaFTLli1rUlXalkgkorVr12rQoEHdtcx2UXHqEOGw9dWuOKVVHwAAAAAAAJmyYMECXXLJJTrmmGM0depULV68WLW1tZo7d64k6eKLL9aQIUNic1Jvu+02HXfccRo7dqz279+ve+65R1u2bNGll16asc9AcOoQdsWpJ1ZDTHAKAAAAAACAzLjgggu0a9cu3XLLLaqoqNCRRx6ppUuXxjaM2rp1qzzxIEv79u3TZZddpoqKCvXr109TpkzRG2+8oQkTJmTqIxCcOkV8cyjrKxWnAAAAAAAAyKT58+dr/vz5SZ9bvnx5k8f333+/7r///h5YVccx49Qhms84peIUAAAAAAAASB3BqUM0b9Wn4hQAAAAAAABIHcGpQ9jBaU6O2XiE4BQAAAAAAABIFcGpQ1BxCgAAAAAAAKQPwalDtJxxGsnUUgAAAAAAAICsR3DqEOGw9dUOTqk4BQAAAAAAAFJHcOoQLStOCU4BAAAAAACAVBGcOkQ8ODUkUXEKAAAAAAAAdAXBqUNQcQoAAAAAAACkD8GpQzQPTqk4BQAAAAAAAFJHcOoQdnDq89lHCE4BAAAAAACAVBGcOkTLitNI5hYDAAAAAAAAZDmCU4eIV5yyORQAAAAAAADQVQSnDmEHp57Yd5TgFAAAAAAAAEgVwalDhMPWVypOAQAAAAAAgK4jOHWI+IxTo/EIwSkAAAAAAACQKoJTh2i5ORTBKQAAAAAAAJAqglOHaL45FBWnAAAAAAAAQOoITh0ivjmUPeM0ksHVAAAAAAAAANmN4NQh7OA0J8c+QsUpAAAAAAAAkCqCU4dovjkUM04BAAAAAACA1BGcOkTz4JSKUwAAAAAAACB1BKcOEQ5bX6k4BQAAAAAAALqO4NQh7IpTn4+KUwAAAAAAAKCrCE4dwg5OPR4qTgEAAAAAAICuIjh1iOYVp6YZyeBqAAAAAAAAgOxGcOoQbA4FAAAAAAAApA/BqUO0rDglOAUAAAAAAABSRXDqEFScAgAAAAAAAOlDcOoQ8YpT61tKxSkAAAAAAACQOoJThwiHra92q/7/396dx0dV3/3ff5+ZSSYhZCGELIR9E1ABAYnUvaJovd1qK1JURKu9KlgVtW4VXHoZb71s/VmpePlTaW3rWq23S20FRVsNYKFUZImALLIkJIGQjSwz59x/TGYyM1kZkpnMzOv5eMxjzpxzZvIZOZ7MvPP5fg8dpwAAAAAAAEDoCE5jRMtQfTpOAQAAAAAAgGNFcBoDLEsym3NS5jgFAAAAAAAAjh3BaQww/TJSb3BqWe4IVQMAAAAAAABEP4LTGOD2y0i9F4ei4xQAAAAAAAAIHcFpDPAPTls6TglOAQAAAAAAgFARnMaAwI5Te/MSwSkAAAAAAAAQKoLTGBAYnNJxCgAAAAAAABwrgtMYwBynAAAAAAAAQPciOI0BLlfLst3u+Sel4xQAAAAAAAAIHcFpDPB2nBqGZLO1dJxalhWxmgAAAAAAAIBoRnAaA7zBqd0uBf6TEpwCAAAAAAAAoSA4jQH+walhtPyTMlwfAAAAAAAACA3BaQwIDE7tflsITgEAAAAAAIBQEJzGgPaG6tNxCgAAAAAAAISG4DQGeINThyNwqD4dpwAAAAAAAEBoCE5jAB2nAAAAAAAAQPciOI0BLpfnPvjiUJI7IvUAAAAAAAAA0Y7gNAbQcQoAAAAAAAB0L4LTGOAfnDLHKQAAAAAAAHDsCE5jAB2nAAAAAAAAQPciOI0BgR2nhiSjeQvBKQAAAAAAABAKgtMYENhxKnn/Wek4BQAAAAAAAEJDcBoDgoPTlnlOCU4BAAAAAACAUBCcxgBvcOpweNd4O07dEakHAAAAAAAAiHYEpzGgvY5ThuoDAAAAAAAAoSE4jQEul+c+eI5ThuoDAAAAAAAAoSE4jQF0nAIAAAAAAADdi+A0BrQOTr2tpwSnAAAAAAAAQCgITmNAcHDacnEoglMAAAAAAAAgFASnMaC9ofp0nAIAAAAAAAChITiNAXScAgAAAAAAAN2L4DQGeINTh8Nz39Jx6o5IPQAAAAAAAEC0IziNAXScAgAAAAAAAN2rVwenDzzwgAzDCLiNHTs20mX1Oi6X5545TgEAAAAAAIDu4Yh0AZ05/vjjtXz5ct9jh6PXlxx2rTtOPQt0nAIAAAAAAACh6fUppMPhUG5ubqTL6NWCg1M6TgEAAAAAAIBj06uH6kvS1q1bNXDgQI0YMUJz5szR7t27O9y/oaFBVVVVvlt1dXWYKo0c5jgFAAAAAAAAulevDk4LCgq0bNkyffDBB3rmmWe0Y8cOnX766R2GoYWFhUpPT/fdxo8fH8aKI4OOUwAAAAAAAKB79erg9IILLtAPf/hDTZgwQTNnztT777+vyspKvfbaa+0+55577tHhw4d9t02bNoWx4shov+PUHZF6AAAAAAAAgGjX6+c49ZeRkaExY8Zo27Zt7e7jdDrldDp9j6uqqsJRWkS113HKUH0AAAAAAAAgNL264zRYTU2Ntm/frry8vEiX0qt4g1OHLwZnqD4AAAAAAABwLHp1cHrHHXfok08+0c6dO/X555/rsssuk91u1+zZsyNdWq/SuuPUs0DHKQAAAAAAABCaXj1Uf8+ePZo9e7YqKio0YMAAnXbaaVq1apUGDBgQ6dJ6FZfLc8/FoQAAAAAAAIDu0auD01deeSXSJUSF9i8ORXAKAAAAAAAAhKJXD9VH17R3cSg6TgEAAAAAAIDQEJzGgPY7Tt0RqQcAAAAAAACIdgSnMYCOUwAAAAAAAKB7EZzGAOY4BQAAAAAAALoXwWkM8AanjuZLfRmGN0ElOAUAAMeguFi65x6poiLSlQAAAABhR3AaA+g4BQAAPeKxx6RHH5VeeinSlQAAAABhR3AaA1wuzz1znAIAgG514IDnvqwssnUAAAAAEUBwGgPoOAUAAD3i8OHAewAAACCOEJzGgODglI5TAADQLaqqPPcEpwAAAIhDBKcxoP2OU3dE6gEAADHCG5h6A1QAAAAgjhCcxoD2Ok4Zqg8AAI4JQ/UBAAAQxwhOY0Dr4NTbekpwCgAAQmRZDNUHAABAXCM4jQFcHAoAAHS7urqWDxkEpwAAAIhDBKcxwPudxuHw3HNxKAAAcMz8w1KCUwAAAMQhgtMY4HJ57uk4BQAA3cY/LK2q8gzdBwAAAOIIwWkMaO/iUHScAgCAkPkHpy6XdORI5GoBAAAAIoDgNAa0P8epOyL1AACAGOC9MJQXw/UBAAAQZwhOYwAdpwAAoNsFB6UEpwAAADhKS5Ys0bBhw5SUlKSCggKtWbOmS8975ZVXZBiGLr300p4tsBMEpzGg/Y5TglMAABAiglMAAAAcg1dffVULFy7U4sWLtW7dOk2cOFEzZ87UgQMHOnzezp07dccdd+j0008PU6XtIziNAa07Tr0JKsEpAAAIEcEpAAAAjsGvfvUr3XDDDZo3b57Gjx+vpUuXqk+fPnrhhRfafY7b7dacOXP04IMPasSIEWGstm0EpzGAjlMAANDtguc4DX4MAACAuFNdXa2qqirfraGhoc39GhsbtXbtWs2YMcO3zmazacaMGSoqKmr39R966CFlZ2fr+uuv7/baQ0FwGgO8wanD4blnjlMAAHDM6DgFAABAkPHjxys9Pd13KywsbHO/8vJyud1u5eTkBKzPyclRSUlJm8/55z//qeeff17PPfdct9cdKkekC8Cxo+MUAAB0O4JTAAAABNm0aZPy8/N9j51OZ7e8bnV1ta6++mo999xzysrK6pbX7A4EpzHA5fLct8xx6g1O3RGqCAAARD1vUGqzSaZJcAoAAAClpqYqLS2t0/2ysrJkt9tVWloasL60tFS5ubmt9t++fbt27typiy66yLfOND0NgQ6HQ8XFxRo5cuQxVn/0GKofA9rrOGWoPgAACJl3TlNvRwHBKQAAALooMTFRU6ZM0YoVK3zrTNPUihUrNH369Fb7jx07Vhs2bND69et9t4svvlhnn3221q9fr8GDB4ezfB86TmNAcHDa0nFKcAoAAELkDUqHDJG+/ZaLQwEAAOCoLFy4UHPnztXUqVM1bdo0Pfnkk6qtrdW8efMkSddcc43y8/NVWFiopKQknXDCCQHPz8jIkKRW68OJ4DQGtA5Ova2nBKcAACBE3uDU+9d9Ok4BAABwFGbNmqWysjItWrRIJSUlmjRpkj744APfBaN2794tm613D4YnOI0BXBwKAAB0O/+OU//HAAAAQBctWLBACxYsaHPbypUrO3zusmXLur+go9S7Y110SXtD9ek4BQAAIfMOzafjFAAAAHGK4DQG0HEKAAC6VWOjVF/vWabjFAAAAHGK4DQGeINTR/PECy0dp+6I1AMAAKKcf0g6aFDrdQAAAEAcIDiNAS6X556OUwAA0C28IWnfvlJmpmfZO3QfAAAAiBMEpzGAOU4BAEC38oakaWlSerpnub7eM4QfAAAAiBMEpzGg9RynngU6TgEAQEi8Hafp6Z7wNHg9AAAAEAcITmMAHacAAKBb+QendruUkhK4HgAAAIgDBKcxoHXHKXOcAgCAY+AfnPrfE5wCAAAgjhCcxgA6TgEAQLfyn+NUaglOuUAUAAAA4gjBaQyg49RPSYn00UeRrgIAgOhGxykAAABAcBoL2us4tSx3hCqKoGuukc45R1qzJtKVAAAQvQhOAQAAAILTaGdZLcGpw+FdG8dD9YuLPfebN0e2DgAAohnBKQAAAEBwGu1Mv2y0pePUsxB3Q/UtSyot9Szv2xfZWgAAiGbBc5x67wlOAQAAEEcITqOc2280ftxfHKq6Wmpo8CwTnAIAEDo6TgEAAACC02jXVnAatxeH8nabSgSnAAAci/aCU28nKgAAABAHCE6jHB2nfg4caFkmOAUAIHR0nAIAAAAEp9GOjlM/BKcAAHSP4DlOCU4BAAAQhwhOo1zHHafuVvvHNP+h+vv3B145CwAAdB0dpwAAAADBabSj49SPf8dpU5NUXh65WgAAiFZut+eCi1JLYOrtPCU4BQAAQBwhOI1y3uDUMCSbzbvsTVDjODiVGK4PAEAovKGpxMWhAAAAENcITqOcy+W5b+k2leK249R/qL5EcAoAQCi84WhiouR0epYZqg8AAIA4RHAa5bwdp/7Bacscp3EWnNJxCgDAsQue39R/uaYmcJ4gAAAAIIYRnEa5toLTuO049Qano0d77glOAQA4em0Fp945TiWG6wMAACBuEJxGOTpO/XiH6k+a5LknOAUA4Oi1FZw6nS3D9hmuDwAAgDhBcBrlOu44jaOhdI2N0qFDnmWCUwAAQucNRv27TCXmOQUAAEDcITiNch11nMbVUP3ycs+93S6dcIJnmeAUAICj5x2K799x6v+YofoAAACIEwSnUa6jjtO4GqrvHaY/YIA0aJBnmeAUAICj19ZQff/HdJwCAAAgThCcRrm2O049D+Kq49R7YajsbGngQM9yaankckWuJgAAohHBKQAAACCJ4DTqeYNTh6NlXVxeHMrbcZqT4+k6tdsl02wJVAEAQNcwxykAAAAgieA06rnqPR2Vdpt/SBqHc5z6d5za7VJurucxw/UBADg67c1x6g1SCU4BAAAQJwhOo5z7R1dLkuyuBt+6uOw49Q9OpZbh+gSnAAAcnc6G6nNxKAAAAMQJgtMo5x4yXJJkb6z3W+vtOHVHoKII8R+qLxGcAgAQKuY4BQAAACQRnEY99+ixkiR7Y51vHR2nIjgFACBUzHEKAAAASCI4jXrukWMkSfb6Or+1cT7HqURwCgBAqNqb45TgFAAAAHGG4DTKuUeMliTZG2qlOk94ahj25q1xFJy2N1R/797I1AMAQLRiqD4AAAAgieA06rnTMyVJdrmlDRua18ZZx6llte44zc/33NNxCgBA11lW+8Gpd+g+wSkAAADiBMFplHObhiTJIZe0bp2kOJzj9PBhqanJs8xQfQAAQldXJ7mbLy7ZXsepdyg/AAAAEOMITqOcy+W5t8vtC07jruPUO0w/LU1KSvIse4PT8nKpoSEydQEAEG28oajNJqWkBG5jqD4AAADiDMFplPM2hfgHp3HXcRo8TF+SMjOlxETPcklJ+GsCACAaeUPRtDTJMAK3+XecWlZ46wIAAAAigOA0ygUEpxs2SI2Nauk4dUeusHBqKzg1DIbrAwBwtNqb39R/nWlKNTXhqwkAAACIEILTKOcLTh2GZ57PjRt9HadxN1Q/JydwPcEpAABHp6PgNDlZstsD9wMAAABiGMFplPMFp6nN85CtWyfDaP5SE89D9SWCUwAAjpZ3jtO0tNbbDIMLRAEAACCuEJxGOV9wmt7Xs7BuneL24lB0nAIAcGw66jj1X0/HKQAAAOIAwWmU8wWn/VI9C+vWcXEoL4JTAACODsEpAAAA4ENwGuVagtPmIXX/+Y/k8gSmcdNxSnAKAED3IDgFAAAAfAhOo5w3OHWk95X69pWOHJF92+7mrXESnDJUHwCA7tHRHKcSwSkAAADiCsFplHO5PPd2hyFNmiRJsq0vliRZljtg36qq1Vq3brrKy98JZ4k9j45TAAC6R2cdp95AleAUAAAAcYDgNMr5hurbJU2e7Fn+srh5a0vHaX39bm3YcLGqqlZp584Hw1tkT2poaPny1l5wWlkp1dWFtSwAAKJSV4fqeztTAQAAgBhGcBrl2gpObes3S2qZ49TtrtVXX12ipiZPZ2ZNzVodObIj7LX2CG+3qcMh9esXuC0tTUpJ8Szv3x/eugAAiEbMcQoAAAD4EJxGuTaD0y83NzebmrIsU1u2XKuamvVKSMhW374nSZLKyv4ckXq7nf8wfcMI3GYYDNcHAOBoMMcpAAAA4ENwGuUCgtNx46SkJBlVNUre7+k43bXrYZWVvSHDSNAJJ7ypvLwbJEllZW9Eruju1N78pl7NwWnTzq/U1FQZnpoAAIhWdJwCAAAAPgSnUS4gOHU4pAkTJEl9v5bc7irt3PmAJGnMmKVKTz9VWVmXSTJUXb1a9fW7I1Jztyot9dzn5LS9vTk43b3qFq1bd0qrC2YBAAA/BKcAAACAD8FplAsITiXfcP3UrS37DBp0q/LyrpMkOZ25Sk8/XZJUVvZmuMrsOZ10nJq5AyRJieVNOnKkWJWVn4arMgAAok9nwal3CD8XhwIAAEAcIDiNct7g1OFoXtEcnPZtDk779TtXI0Y8HvCcAQN+IClGhut3EpyWO7+QJCWWex6Xlv4xHFUBABB9Ghul+nrPMnOcAgAAAASn0c7l8ty37ji1qW/KRI0f/6psNkfAcwYM+L4kqarqMzU07A1XqT2jg6H65eVvqzyhSJKUVjtEkicsNs2GsJUHAEDU8O8iJTgFAAAACE6jXauh+iecIDkcSjhsakr2W0pI6NfqOU5nvtLSviNJKit7K0yV9pB2Ok4bGvZpy5br1dDf8zjpoFOJiflyuw+rouKvYS4SAIAo4A1DU1L8hrIE8Q9OLSs8dQEAAAARQnAa5VoFp06nJzyVZPz7P+0+L2aG67cRnFqWqS1b5srlqpBjyDhJkrFvn7IHzGp+yp/CXiYAAL1eZ/Ob+m9ramoZ1g8AAADEKILTKNcqOJV8w/W1bl27zxsw4HJJ0uHDn6qxsbSHqguDNobq79nzax06tFw2W7JGnPoHz8raWuX0uVSSVFHxjlwuLmoBAEAA71D99obpS1LfvpJheJYZrg8AAIAYR3Aa5UINTpOShig1dZokK3qH65umVFbmWW7uOK2u/re++eYeSdKoUb9WSvZkX3dM36os9ekzVqZZr/LyKH3PAAD0lK50nNpsUmqqZ7mKP0ICAAAgthGcRrkOg9MVK6Qbb5SWL2+5ipSfqB+uf+hQy/saMECStHXrfFlWk/r3v0R5eTd6tg0cKEky9u9XdvaPJEmlpQzXBwAgQFeCU//tdJwCAAAgxhGcRrl2g9Nx4zxzjz33nHTuuZ7w8Kc/lT7+2HcxB+9w/crKlWpsLAtz5d3AO79pRobkdKqu7mtVVRVJsmvMmGdkeIcSNgen2rdP2dmzJUmHDi2P7ikKAADobgSnAAAAQACC0yjXZnDqdEobNrR0nPbv7xnSvnSp9N3vSnffLUlKTh6hvn0nS3KrvPztsNd+zIIuDFVa+kdJUmbmuXI681r28wtO+/QZpdTUAkmmDhx4NYzFAgDQy3VljlOJ4BQAAABxg+A0ynlHqjscQRvsdk9I+uyz0v790t/+Jl17rWfbE09ImzZJivLh+t4LQ2Vny7IsX3Cak3NV4H75+Z77ffuatzNcHwCAVug4BQAAAAIQnEa5NjtOgyUkSOedJ734onTJJZ4n3XGHJP/h+ivU1HSwh6vtZt6O05wcVVWtVn39dtlsKcrKujRwP7+OU0kaMOAKSTZVV6/WkSPbw1YuAAC9WleDU29HKheHAgAAQIwjOI1yXQpO/T3+uCdI/etfpQ8+UJ8+Y5SSMlGW5dLOnQ/1WJ09wm+ofmnpHyRJAwZcJrs9JXC/oODU6cxVv37nSJJKS18OS6kAAPR6dJwCAAAAAQhOo9xRB6ejR0s33+xZvv12yeXSiBGPSpL27v0/OnTo4+4vsqc0D9U3s7NUVuaZrzQ7e07r/bzB6a5dvrkNcnI8+x048EdZzRfLAgAgrjHHKQAAABCA4DTKHXVwKkn33++5YNSmTdL//q/69z9feXk3SpK2bJknlytKht41d5zWpVSoqalcCQnZ6tdvRuv9Ro/2XDBrzx7pe9+TDh5UVtZlMgyn6uq2qKZmfXjrBgCgN6LjFAAAAAhAcBrlQgpOMzKkh5qH5S9aJB06pJEj/0dJScPV0LBL27Yt7O4ye0ZzcHoo4T+SpOzs2bLZgq+SJSkrS3r5ZSklRfrwQ6mgQI6v9ygr6yJJ0s6dD8g0XWErGwCAXqmLwWlDUo0kqXbf57Isd09XBQAAAEQMwWmUCyk4laQbb5TGj5cqKqRf/lIOR6rGjn1RkqGSkudVUfFed5fa/ZqH6lc4vpAk5eRc1f6+l10mff65NGyYtG2bdMopGrbhZBlGgioq/j9t3jxbptkUhqIBAOilOghOGxsP6Ntvn9S//nWSvqkolCQ1lG3Rzp0PhLFAAAAAILwITqNcyMGpwyH96lee5d/8Rtq6VRkZZ2rQoFslScXFP1ZTU0W31dkjmjtOG9IblZx8nFJTp3S8/4QJ0hdfSGedJVVXK+VHd2vq36+UoQSVlb2hTZuulGk29nzdAAD0Rt7g1G+O05qaDdqw4WJ9/vlAbd9+m2pq1sud4vnQ4aiVdu36pcrL341EtQAAAECPIziNciEHp5I0c6Znzs+mJunWW6W1azW8/DIN2DFUSetLtOe1K6Wysu4st/scOSJVV0uSmvp5LvZkGEbnz8vKkv7+d+mmmyTLUsojL+k7d41Sv3UJKi97Uxs3XkF4CgCIP6bp+73q7TitrPyH/v3v01RR8Y4kt1JTp2n06CUaW/CmJCmpIUOStGXL1Tpy5JsIFA0AAAD0LILTKNd8kXg52pjas0v+5388qev770tTp8o+/Qwdf90uTZ4vDb9quaz8PFnXzpW+/LLbau4Wzd2mZoLkSvEEp12WkCAtWSI9+6yUlKSENZs18fYmTbrNkOujt7Vx4w9kmg09VHjsMs0m7dr1iFatGq7t2++W210b6ZIAAF3lDU0lKT1dFRXv68svz5PbXaX09DN08smbNWXKauXn3yRH/yGSpIQjSUpLO0UuV6U2brxcbveRCBUPAAAA9IyoCE6XLFmiYcOGKSkpSQUFBVqzZk2kS+o1jqnjVJLGjZMeeUQaPFgaNEgaMkQaNkxNgzNUny0ZTW4Zv/u9NHGi6s84TrVv/kamuxfMBdocnDZmSGnp31Fy8oijf40bb5S++Ub62c+kxERl/MfSSbdKg659R98sO03lB/6ixsZe2nHby1RVrdbatZO1Y8d9qq/fqW+//X+1Zs3x0TFXLgCgZZh+YqJKD7+lr766RKZZr/79/x9NmPCBUlLGtuzb3JFqHD6s8eNfV0LCANXUrNfWrfNlWVYEigcAAAB6hmH18k+4r776qq655hotXbpUBQUFevLJJ/X666+ruLhY2dnZnT5/z549Gjx4sL799lsNGjQoDBWH15lnSp9+Kr36qnTFFd33uqbZqK+//omOrHxF+a/Ua8A/JMP0bKsdblPtlEy5h+ZKw4bJNnKsHKMnKSF7tAzLJtU3yah3ydbYJB1plD0hRbbUHDnScmSk9D2GlNfPu+9KF12k6tFS1ce/VX7+T4/t9fbskR55RNb/fU5Gk6eNtzFDOniyVHNqrqxzz1LKsO+qb9+JSkoaqoSE7K5NDRDLLEsuV7V27PyF9u59WpKlhIQs5ef/TPv3/181NOyWJGVlfV+jRv0fJSXF3v9/ABAzNmyQJkyQu39f/eONWkmWsrPnaOzYF2WzJQTue/Cg1L+/Z7mxUYdqPtV//nOeJFNjxvyvBg68IdzVAwAAoIfFer7Wnl4fnBYUFOjkk0/W008/LUkyTVODBw/WzTffrLvvvrvT58f6P+xpp0mffSa98YZ0+eXd//qm2aSamn+r+su/yPnsK8r48w452hmJZzokm6sLr5komUl2mUk2zy3Z7nmcbJeVaJdlmJIsWZYpy7AkmbIcdsnplJHolJzJStxTp76f7VVFgaHUTw8oMTGre97wrl1qfOA2OV57V7a6ls5ay5Cqx0i1wz31W4l22fqkydann2x9+smwJcow7DJsNslwSIZNhmH3u7fLsNk9y7JJhiRv8Go0N377HhvNN791nge+dYZ3n+b9rYD91FxH82Pffmpj/5Z1nv0syfLcDMuSLEmmKaOuQba9FbLvq5BtX4XseytkKzko02aqsb+lhizJGDRMfUdfIPugETITpIrKv+tQ1QqZNlNGglOZ/WfK7kiXZMgwbH73tjbWGS3/XUJxrJn2sYTixxqoH8vTI1i3Fed/R4gLAccI/+CxxrF9n1Ie+ZOODJRW/1EaOHC+Ro9+qvmcHKSpSUpM9CzPnCnl5uqw8xuV6x9yZdiVlT9bNpvTs91o/v3ledD8R8fgx/I75/tvV8fnpva2tfeUkF4rUsd6pP8fM2WajbKsJllWk0yzSZJLkk2G4ZBhJMhmS5BhJMgwHL2gXgAe/L8IRJpjzGSlnDY70mX0iFjP19rTq4PTxsZG9enTR2+88YYuvfRS3/q5c+eqsrJSb7/9dqvnNDQ0qKGhZX7KvXv3avz48TH7Dzt9urRqlfTWW5Lff6IeYx2qUONrS+Xe8h9pxzey7donx+6DchxsPSeo6fCEjIYl2eo9992t4odD1f+1nd3/wo2NUlGR3O+9JeuDd+TYwEUvAACxr+o4qeKvv9CwYQ91PLJi9Ghp27bwFQYAABAFKn90gjL+uCHSZfSIeA1OQ72kUFiUl5fL7XYrJycnYH1OTo62bNnS5nMKCwv14IMPhqO8XmHiRM/I96xuarjsjNGvv5w/ua/1htpaz9C9pCQpOVlKSpLN4fBNomu669VUUypXVancVaUyq8tk1dbKqKuT6o5ItXUyjhyR6htleLsZ5OlGNCyb5GqQWV8ts75aVn2trPoaWTZLKbc+3jNvNDFROvNM2c88U3rsSWn/fmn5cmnfPpn1dXLXlMldWyaz7qDMukpZpluy3JJleuZ3s0xZMj1XKZYpyzIly/R1c0pquZck07vc3OXpt92wJKt5vSd89ttHlmT6LXvvAp7rH1r7v758+wTUYhie7kFvx6shmU6bmrKdasxNUlOOU025TjVmJymtz0kaqEtkLz0k7d0r7dsnlZR4upHcbsnlkuV2qaFut1z1Zb4fanmK9HufQevD+fecEH5UyH8ECOV9hfNPW+F8XwB6H5sh10/naPjwhzvft6hI+vxzqazMdzNL9+rIntUyG2raeELQ766ATUG/mNo6pXR4munkHNTR5g62GXF9bvOM/DBka75vHgliWZ7PN5bZ/Du7+fMNEG/i+fQAoEPWyBCuv4JerVcHp6G45557tHDhQt9jb8dprFq6NNIVNEtJ8dzaYbMnKTF9qBLTh4axqG6UlyddfbUkyTu4PKHDJ8DLkJQU6SIAAN0rK0u6+OKAVTZJ7X8SAAAAAKJPrw5Os7KyZLfbVVpaGrC+tLRUubm5bT7H6XTK6XT6HldVVfVojQAAAAAAAABizzFcfaXnJSYmasqUKVqxYoVvnWmaWrFihaZPnx7BygAAAAAAAADEsl7dcSpJCxcu1Ny5czV16lRNmzZNTz75pGprazVv3rxIlwYAAAAAAAAgRvX64HTWrFkqKyvTokWLVFJSokmTJumDDz5odcEoAAAAAAAAAOguvT44laQFCxZowYIFkS4DAAAAAAAAQJzo1XOcAgAAAAAAAEAkEJwCAAAAAAAAQBCCUwAAAAAAAAAIQnAKAAAAAAAAAEEITgEAAAAAAAAgCMEpAAAAAAAAAAQhOAUAAAAAAACAIASnAAAAAAAAABCE4BQAAAAAAABAt1uyZImGDRumpKQkFRQUaM2aNe3u++abb2rq1KnKyMhQSkqKJk2apJdeeimM1bZGcAoAAAAAAACgW7366qtauHChFi9erHXr1mnixImaOXOmDhw40Ob+mZmZuu+++1RUVKQvv/xS8+bN07x58/S3v/0tzJW3MCzLsiL208Ngz549Gjx4sL799lsNGjQo0uUAAAAAAAAAUSWUfK2goEAnn3yynn76aUmSaZoaPHiwbr75Zt19991deo3Jkyfrwgsv1MMPPxxy7ceCjlMAAAAAAAAA3aaxsVFr167VjBkzfOtsNptmzJihoqKiTp9vWZZWrFih4uJinXHGGT1ZaoccEfvJAAAAAAAAAKJGdXW1qqqqfI+dTqecTmer/crLy+V2u5WTkxOwPicnR1u2bGn39Q8fPqz8/Hw1NDTIbrfrt7/9rc4999zuewNHiY5TAAAAAAAAAJ0aP3680tPTfbfCwsJuff3U1FStX79eX3zxhf77v/9bCxcu1MqVK7v1ZxwNOk4BAAAAAAAAdGrTpk3Kz8/3PW6r21SSsrKyZLfbVVpaGrC+tLRUubm57b6+zWbTqFGjJEmTJk3S5s2bVVhYqLPOOuvYiw8BHacAAAAAAAAAOpWamqq0tDTfrb3gNDExUVOmTNGKFSt860zT1IoVKzR9+vQu/zzTNNXQ0HDMdYeKjlMAAAAAAAAA3WrhwoWaO3eupk6dqmnTpunJJ59UbW2t5s2bJ0m65pprlJ+f7xvuX1hYqKlTp2rkyJFqaGjQ+++/r5deeknPPPNMxN4DwSkAAAAAAACAbjVr1iyVlZVp0aJFKikp0aRJk/TBBx/4Lhi1e/du2Wwtg+Fra2t10003ac+ePUpOTtbYsWP1hz/8QbNmzYrUW5BhWZYVsZ8eBnv27NHgwYP17bffatCgQZEuBwAAAAAAAIgq8ZqvMccpAAAAAAAAAAQhOAUAAAAAAACAIASnAAAAAAAAABCE4BQAAAAAAAAAghCcAgAAAAAAAEAQglMAAAAAAAAACEJwCgAAAAAAAABBCE4BAAAAAAAAIIgj0gX0NNM0JUn79++PcCUAAAAAAABA9PHmat6cLV7EfHBaWloqSZo2bVqEKwEAAAAAAACiV2lpqYYMGRLpMsLGsCzLinQRPcnlcunf//63cnJyZLPF3swE1dXVGj9+vDZt2qTU1NRIl4MowXGDUHDc4GhxzCAUHDc4WhwzCAXHDULBcYOjFUvHjGmaKi0t1UknnSSHI+b7MH1iPjiNdVVVVUpPT9fhw4eVlpYW6XIQJThuEAqOGxwtjhmEguMGR4tjBqHguEEoOG5wtDhmol/stWACAAAAAAAAwDEiOAUAAAAAAACAIASnUc7pdGrx4sVyOp2RLgVRhOMGoeC4wdHimEEoOG5wtDhmEAqOG4SC4wZHi2Mm+jHHKQAAAAAAAAAEoeMUAAAAAAAAAIIQnAIAAAAAAABAEIJTAAAAAAAAAAhCcAoAAAAAAAAAQQhOo9ySJUs0bNgwJSUlqaCgQGvWrIl0SeglCgsLdfLJJys1NVXZ2dm69NJLVVxcHLDPWWedJcMwAm7/9V//FaGK0Rs88MADrY6JsWPH+rbX19dr/vz56t+/v/r27avLL79cpaWlEawYkTZs2LBWx4xhGJo/f74kzjPw+PTTT3XRRRdp4MCBMgxDf/nLXwK2W5alRYsWKS8vT8nJyZoxY4a2bt0asM/Bgwc1Z84cpaWlKSMjQ9dff71qamrC+C4Qbh0dN01NTbrrrrt04oknKiUlRQMHDtQ111yjffv2BbxGW+eoRx99NMzvBOHS2bnm2muvbXU8nH/++QH7cK6JP50dN219zjEMQ48//rhvH8418aUr37W78r1p9+7duvDCC9WnTx9lZ2frzjvvlMvlCudbQRcQnEaxV199VQsXLtTixYu1bt06TZw4UTNnztSBAwciXRp6gU8++UTz58/XqlWr9OGHH6qpqUnnnXeeamtrA/a74YYbtH//ft/tsccei1DF6C2OP/74gGPin//8p2/bbbfdpnfeeUevv/66PvnkE+3bt0/f//73I1gtIu2LL74IOF4+/PBDSdIPf/hD3z6cZ1BbW6uJEydqyZIlbW5/7LHH9NRTT2np0qVavXq1UlJSNHPmTNXX1/v2mTNnjjZu3KgPP/xQ7777rj799FPdeOON4XoLiICOjpu6ujqtW7dO999/v9atW6c333xTxcXFuvjii1vt+9BDDwWcg26++eZwlI8I6OxcI0nnn39+wPHw8ssvB2znXBN/Ojtu/I+X/fv364UXXpBhGLr88ssD9uNcEz+68l27s+9NbrdbF154oRobG/X555/rd7/7nZYtW6ZFixZF4i2hIxai1rRp06z58+f7HrvdbmvgwIFWYWFhBKtCb3XgwAFLkvXJJ5/41p155pnWLbfcErmi0OssXrzYmjhxYpvbKisrrYSEBOv111/3rdu8ebMlySoqKgpThejtbrnlFmvkyJGWaZqWZXGeQWuSrLfeesv32DRNKzc313r88cd96yorKy2n02m9/PLLlmVZ1qZNmyxJ1hdffOHb569//atlGIa1d+/esNWOyAk+btqyZs0aS5K1a9cu37qhQ4dav/71r3u2OPRKbR0zc+fOtS655JJ2n8O5Bl0511xyySXWd7/73YB1nGviW/B37a58b3r//fctm81mlZSU+PZ55plnrLS0NKuhoSG8bwAdouM0SjU2Nmrt2rWaMWOGb53NZtOMGTNUVFQUwcrQWx0+fFiSlJmZGbD+j3/8o7KysnTCCSfonnvuUV1dXSTKQy+ydetWDRw4UCNGjNCcOXO0e/duSdLatWvV1NQUcN4ZO3ashgwZwnkHkjy/m/7whz/ouuuuk2EYvvWcZ9CRHTt2qKSkJODckp6eroKCAt+5paioSBkZGZo6dapvnxkzZshms2n16tVhrxm90+HDh2UYhjIyMgLWP/roo+rfv79OOukkPf744wyDjHMrV65Udna2jjvuOP30pz9VRUWFbxvnGnSmtLRU7733nq6//vpW2zjXxK/g79pd+d5UVFSkE088UTk5Ob59Zs6cqaqqKm3cuDGM1aMzjkgXgNCUl5fL7XYH/E8mSTk5OdqyZUuEqkJvZZqmbr31Vp166qk64YQTfOt/9KMfaejQoRo4cKC+/PJL3XXXXSouLtabb74ZwWoRSQUFBVq2bJmOO+447d+/Xw8++KBOP/10ffXVVyopKVFiYmKrL6Q5OTkqKSmJTMHoVf7yl7+osrJS1157rW8d5xl0xnv+aOszjXdbSUmJsrOzA7Y7HA5lZmZy/oEkz1xyd911l2bPnq20tDTf+p/97GeaPHmyMjMz9fnnn+uee+7R/v379atf/SqC1SJSzj//fH3/+9/X8OHDtX37dt1777264IILVFRUJLvdzrkGnfrd736n1NTUVlNVca6JX2191+7K96aSkpI2P/t4t6H3IDgF4sD8+fP11VdfBcxVKSlgvqYTTzxReXl5Ouecc7R9+3aNHDky3GWiF7jgggt8yxMmTFBBQYGGDh2q1157TcnJyRGsDNHg+eef1wUXXKCBAwf61nGeAdDTmpqadMUVV8iyLD3zzDMB2xYuXOhbnjBhghITE/WTn/xEhYWFcjqd4S4VEXbllVf6lk888URNmDBBI0eO1MqVK3XOOedEsDJEixdeeEFz5sxRUlJSwHrONfGrve/aiB0M1Y9SWVlZstvtra7KVlpaqtzc3AhVhd5owYIFevfdd/Xxxx9r0KBBHe5bUFAgSdq2bVs4SkMUyMjI0JgxY7Rt2zbl5uaqsbFRlZWVAftw3oEk7dq1S8uXL9ePf/zjDvfjPINg3vNHR59pcnNzW1380uVy6eDBg5x/4pw3NN21a5c+/PDDgG7TthQUFMjlcmnnzp3hKRC92ogRI5SVleX7ncS5Bh35xz/+oeLi4k4/60ica+JFe9+1u/K9KTc3t83PPt5t6D0ITqNUYmKipkyZohUrVvjWmaapFStWaPr06RGsDL2FZVlasGCB3nrrLX300UcaPnx4p89Zv369JCkvL6+Hq0O0qKmp0fbt25WXl6cpU6YoISEh4LxTXFys3bt3c96BXnzxRWVnZ+vCCy/scD/OMwg2fPhw5ebmBpxbqqqqtHr1at+5Zfr06aqsrNTatWt9+3z00UcyTdMXxiP+eEPTrVu3avny5erfv3+nz1m/fr1sNlur4diIT3v27FFFRYXvdxLnGnTk+eef15QpUzRx4sRO9+VcE9s6+67dle9N06dP14YNGwL+WOP9A+D48ePD80bQJQzVj2ILFy7U3LlzNXXqVE2bNk1PPvmkamtrNW/evEiXhl5g/vz5+tOf/qS3335bqampvnlS0tPTlZycrO3bt+tPf/qTvve976l///768ssvddttt+mMM87QhAkTIlw9IuWOO+7QRRddpKFDh2rfvn1avHix7Ha7Zs+erfT0dF1//fVauHChMjMzlZaWpptvvlnTp0/XKaecEunSEUGmaerFF1/U3Llz5XC0fLTgPAOvmpqagC7jHTt2aP369crMzNSQIUN066236pe//KVGjx6t4cOH6/7779fAgQN16aWXSpLGjRun888/XzfccIOWLl2qpqYmLViwQFdeeWXA1BCILR0dN3l5efrBD36gdevW6d1335Xb7fZ91snMzFRiYqKKioq0evVqnX322UpNTVVRUZFuu+02XXXVVerXr1+k3hZ6UEfHTGZmph588EFdfvnlys3N1fbt2/Xzn/9co0aN0syZMyVxrolXnf2Okjx/0Hv99df1xBNPtHo+55r409l37a58bzrvvPM0fvx4XX311XrsscdUUlKiX/ziF5o/fz7TO/Q2FqLab37zG2vIkCFWYmKiNW3aNGvVqlWRLgm9hKQ2by+++KJlWZa1e/du64wzzrAyMzMtp9NpjRo1yrrzzjutw4cPR7ZwRNSsWbOsvLw8KzEx0crPz7dmzZplbdu2zbf9yJEj1k033WT169fP6tOnj3XZZZdZ+/fvj2DF6A3+9re/WZKs4uLigPWcZ+D18ccft/k7ae7cuZZlWZZpmtb9999v5eTkWE6n0zrnnHNaHU8VFRXW7Nmzrb59+1ppaWnWvHnzrOrq6gi8G4RLR8fNjh072v2s8/HHH1uWZVlr1661CgoKrPT0dCspKckaN26c9cgjj1j19fWRfWPoMR0dM3V1ddZ5551nDRgwwEpISLCGDh1q3XDDDVZJSUnAa3CuiT+d/Y6yLMt69tlnreTkZKuysrLV8znXxJ/OvmtbVte+N+3cudO64IILrOTkZCsrK8u6/fbbraampjC/G3TGsCzL6sFcFgAAAAAAAACiDnOcAgAAAAAAAEAQglMAAAAAAAAACEJwCgAAAAAAAABBCE4BAAAAAAAAIAjBKQAAAAAAAAAEITgFAAAAAAAAgCAEpwAAAAAAAAAQhOAUAAAAUWnlypUyDEOVlZWRLgUAAAAxiOAUAAAAAAAAAIIQnAIAAAAAAABAEIJTAAAAhMQ0TRUWFmr48OFKTk7WxIkT9cYbb0hqGUb/3nvvacKECUpKStIpp5yir776KuA1/vznP+v444+X0+nUsGHD9MQTTwRsb2ho0F133aXBgwfL6XRq1KhRev755wP2Wbt2raZOnao+ffroO9/5joqLi3v2jQMAACAuEJwCAAAgJIWFhfr973+vpUuXauPGjbrtttt01VVX6ZNPPvHtc+edd+qJJ57QF198oQEDBuiiiy5SU1OTJE/gecUVV+jKK6/Uhg0b9MADD+j+++/XsmXLfM+/5ppr9PLLL+upp57S5s2b9eyzz6pv374Bddx333164okn9K9//UsOh0PXXXddWN4/AAAAYpthWZYV6SIAAAAQXRoaGpSZmanly5dr+vTpvvU//vGPVVdXpxtvvFFnn322XnnlFc2aNUuSdPDgQQ0aNEjLli3TFVdcoTlz5qisrEx///vffc//+c9/rvfee08bN27U119/reOOO04ffvihZsyY0aqGlStX6uyzz9by5ct1zjnnSJLef/99XXjhhTpy5IiSkpJ6+L8CAAAAYhkdpwAAADhq27ZtU11dnc4991z17dvXd/v973+v7du3+/bzD1UzMzN13HHHafPmzZKkzZs369RTTw143VNPPVVbt26V2+3W+vXrZbfbdeaZZ3ZYy4QJE3zLeXl5kqQDBw4c83sEAABAfHNEugAAAABEn5qaGknSe++9p/z8/IBtTqczIDwNVXJycpf2S0hI8C0bhiHJM/8qAAAAcCzoOAUAAMBRGz9+vJxOp3bv3q1Ro0YF3AYPHuzbb9WqVb7lQ4cO6euvv9a4ceMkSePGjdNnn30W8LqfffaZxowZI7vdrhNPPFGmaQbMmQoAAACECx2nAAAAOGqpqam64447dNttt8k0TZ122mk6fPiwPvvsM6WlpWno0KGSpIceekj9+/dXTk6O7rvvPmVlZenSSy+VJN1+++06+eST9fDDD2vWrFkqKirS008/rd/+9reSpGHDhmnu3Lm67rrr9NRTT2nixInatWuXDhw4oCuuuCJSbx0AAABxguAUAAAAIXn44Yc1YMAAFRYW6ptvvlFGRoYmT56se++91zdU/tFHH9Utt9yirVu3atKkSXrnnXeUmJgoSZo8ebJee+01LVq0SA8//LDy8vL00EMP6dprr/X9jGeeeUb33nuvbrrpJlVUVGjIkCG69957I/F2AQAAEGcMy7KsSBcBAACA2OK94v2hQ4eUkZER6XIAAACAo8YcpwAAAAAAAAAQhOAUAAAAAAAAAIIwVB8AAAAAAAAAgtBxCgAAAAAAAABBCE4BAAAAAAAAIAjBKQAAAAAAAAAEITgFAAAAAAAAgCAEpwAAAAAAAAAQhOAUAAAAAAAAAIIQnAIAAAAAAABAEIJTAAAAAAAAAAhCcAoAAAAAAAAAQf5/63WIL9h0Gi0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'../readme_img/data_{check_data_version}_train_{version}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[740,   0],\n",
       "        [  0,  49]],\n",
       "\n",
       "       [[749,   0],\n",
       "        [  0,  40]],\n",
       "\n",
       "       [[737,   0],\n",
       "        [  0,  52]],\n",
       "\n",
       "       [[743,   0],\n",
       "        [  0,  46]],\n",
       "\n",
       "       [[746,   0],\n",
       "        [  0,  43]],\n",
       "\n",
       "       [[735,   0],\n",
       "        [  0,  54]],\n",
       "\n",
       "       [[740,   0],\n",
       "        [  0,  49]],\n",
       "\n",
       "       [[743,   0],\n",
       "        [  0,  46]],\n",
       "\n",
       "       [[738,   0],\n",
       "        [  0,  51]],\n",
       "\n",
       "       [[742,   0],\n",
       "        [  0,  47]],\n",
       "\n",
       "       [[745,   0],\n",
       "        [  0,  44]],\n",
       "\n",
       "       [[739,   0],\n",
       "        [  0,  50]],\n",
       "\n",
       "       [[751,   0],\n",
       "        [  0,  38]],\n",
       "\n",
       "       [[749,   0],\n",
       "        [  0,  40]],\n",
       "\n",
       "       [[742,   0],\n",
       "        [  0,  47]],\n",
       "\n",
       "       [[741,   0],\n",
       "        [  0,  48]],\n",
       "\n",
       "       [[744,   0],\n",
       "        [  0,  45]]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(f'../models/data_{check_data_version}_train_{version}_model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
