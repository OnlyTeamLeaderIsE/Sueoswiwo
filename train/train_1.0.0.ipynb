{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "version = '1.0.0'\n",
    "check_data_version = '1.0.1'\n",
    "\n",
    "\n",
    "with open(f'../create_dataset/v{check_data_version}/label.json', 'r', encoding='utf-8') as file:\n",
    "    label = json.load(file)\n",
    "    \n",
    "word_count = label['label_count'] * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 10, 55)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'../create_dataset/v{check_data_version}/data'\n",
    "data_files_list = os.listdir(data_dir)\n",
    "\n",
    "\n",
    "data_files_list.sort()\n",
    "\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load(f'{data_dir}/{file}') for file in data_files_list\n",
    "], axis=0)\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2338, 10, 54)\n",
      "(2338,)\n",
      "0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 2.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0 4.0\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(*labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2338, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=word_count)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2104, 10, 54) (2104, 5)\n",
      "(234, 10, 54) (234, 5)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "time_stamp = 1\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 64)                30464     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 5)                 165       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 32709 (127.77 KB)\n",
      "Trainable params: 32709 (127.77 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3], return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(word_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_version = check_data_version.replace('.', '')\n",
    "version = version.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 8.9339e-04 - acc: 1.0000\n",
      "Epoch 1: val_acc improved from -inf to 1.00000, saving model to ../models\\data_101_train_100_model.h5\n",
      "66/66 [==============================] - 2s 12ms/step - loss: 7.4216e-04 - acc: 1.0000 - val_loss: 3.9169e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "57/66 [========================>.....] - ETA: 0s - loss: 4.3497e-04 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.1614e-04 - acc: 1.0000 - val_loss: 3.1280e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 1.6040e-04 - acc: 1.0000\n",
      "Epoch 3: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.4746e-04 - acc: 1.0000 - val_loss: 2.0901e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 9.0265e-05 - acc: 1.0000\n",
      "Epoch 4: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.7349e-05 - acc: 1.0000 - val_loss: 1.6573e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 7.5978e-05 - acc: 1.0000\n",
      "Epoch 5: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.8702e-05 - acc: 1.0000 - val_loss: 1.4815e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 6.4973e-05 - acc: 1.0000\n",
      "Epoch 6: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.1235e-05 - acc: 1.0000 - val_loss: 1.3827e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 5.5250e-05 - acc: 1.0000\n",
      "Epoch 7: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.6508e-05 - acc: 1.0000 - val_loss: 1.2356e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 5.4066e-05 - acc: 1.0000\n",
      "Epoch 8: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.2336e-05 - acc: 1.0000 - val_loss: 1.1412e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "48/66 [====================>.........] - ETA: 0s - loss: 5.4179e-05 - acc: 1.0000\n",
      "Epoch 9: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.8388e-05 - acc: 1.0000 - val_loss: 1.0368e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 4.4871e-05 - acc: 1.0000\n",
      "Epoch 10: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.4871e-05 - acc: 1.0000 - val_loss: 9.5520e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "62/66 [===========================>..] - ETA: 0s - loss: 4.2633e-05 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.1943e-05 - acc: 1.0000 - val_loss: 8.8296e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 3.9138e-05 - acc: 1.0000\n",
      "Epoch 12: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.9470e-05 - acc: 1.0000 - val_loss: 8.1998e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 3.7427e-05 - acc: 1.0000\n",
      "Epoch 13: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.6857e-05 - acc: 1.0000 - val_loss: 7.5344e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 3.6249e-05 - acc: 1.0000\n",
      "Epoch 14: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.4590e-05 - acc: 1.0000 - val_loss: 6.9986e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 3.3064e-05 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.2570e-05 - acc: 1.0000 - val_loss: 6.5031e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 3.0400e-05 - acc: 1.0000\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.0770e-05 - acc: 1.0000 - val_loss: 6.0145e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 3.0548e-05 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.9038e-05 - acc: 1.0000 - val_loss: 5.5739e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 2.8190e-05 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.7411e-05 - acc: 1.0000 - val_loss: 5.2143e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 2.5891e-05 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.5796e-05 - acc: 1.0000 - val_loss: 4.8847e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 2.3980e-05 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.4405e-05 - acc: 1.0000 - val_loss: 4.5962e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 2.1177e-05 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.3265e-05 - acc: 1.0000 - val_loss: 4.3098e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 2.3056e-05 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.1956e-05 - acc: 1.0000 - val_loss: 4.0722e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 1.7701e-05 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.0629e-05 - acc: 1.0000 - val_loss: 3.8547e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "62/66 [===========================>..] - ETA: 0s - loss: 2.0725e-05 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.9623e-05 - acc: 1.0000 - val_loss: 3.6015e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 1.5488e-05 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 1.8655e-05 - acc: 1.0000 - val_loss: 3.4197e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "47/66 [====================>.........] - ETA: 0s - loss: 1.6476e-05 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.7779e-05 - acc: 1.0000 - val_loss: 3.1919e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 1.6743e-05 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6810e-05 - acc: 1.0000 - val_loss: 3.0418e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.6054e-05 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6054e-05 - acc: 1.0000 - val_loss: 2.8757e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.6728e-05 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5203e-05 - acc: 1.0000 - val_loss: 2.7352e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 1.4705e-05 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4560e-05 - acc: 1.0000 - val_loss: 2.6033e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.4614e-05 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3915e-05 - acc: 1.0000 - val_loss: 2.4386e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.3966e-05 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3318e-05 - acc: 1.0000 - val_loss: 2.3254e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 1.3799e-05 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2742e-05 - acc: 1.0000 - val_loss: 2.2208e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 1.2960e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2150e-05 - acc: 1.0000 - val_loss: 2.1180e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.1787e-05 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1591e-05 - acc: 1.0000 - val_loss: 2.0282e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 1.1266e-05 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1009e-05 - acc: 1.0000 - val_loss: 1.9325e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 1.0449e-05 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0505e-05 - acc: 1.0000 - val_loss: 1.8505e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 1.0079e-05 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0116e-05 - acc: 1.0000 - val_loss: 1.7587e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 1.0284e-05 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.6289e-06 - acc: 1.0000 - val_loss: 1.6784e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 9.8344e-06 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.2615e-06 - acc: 1.0000 - val_loss: 1.6042e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 8.5348e-06 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.8452e-06 - acc: 1.0000 - val_loss: 1.5283e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 8.3796e-06 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.4939e-06 - acc: 1.0000 - val_loss: 1.4586e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 8.2144e-06 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.1553e-06 - acc: 1.0000 - val_loss: 1.3995e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 8.3851e-06 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.8052e-06 - acc: 1.0000 - val_loss: 1.3371e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 7.5012e-06 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.5012e-06 - acc: 1.0000 - val_loss: 1.2744e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 6.2674e-06 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.2016e-06 - acc: 1.0000 - val_loss: 1.2171e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 7.0295e-06 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.9624e-06 - acc: 1.0000 - val_loss: 1.1663e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 6.4517e-06 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.6389e-06 - acc: 1.0000 - val_loss: 1.1174e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 6.9831e-06 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.3802e-06 - acc: 1.0000 - val_loss: 1.0672e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 6.1034e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.1450e-06 - acc: 1.0000 - val_loss: 1.0277e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 6.1086e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.9051e-06 - acc: 1.0000 - val_loss: 9.8585e-06 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 5.6902e-06 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.7229e-06 - acc: 1.0000 - val_loss: 9.6339e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 53/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 5.4032e-06 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.6063e-06 - acc: 1.0000 - val_loss: 9.4546e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 54/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 4.6402e-06 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.4966e-06 - acc: 1.0000 - val_loss: 9.2519e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 55/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 5.2886e-06 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.3931e-06 - acc: 1.0000 - val_loss: 9.0629e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 56/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 5.5679e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.2801e-06 - acc: 1.0000 - val_loss: 8.8526e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 57/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 5.1145e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.1865e-06 - acc: 1.0000 - val_loss: 8.7044e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 58/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 5.1720e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 5.0633e-06 - acc: 1.0000 - val_loss: 8.5118e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 59/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 5.1026e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 4.9553e-06 - acc: 1.0000 - val_loss: 8.3280e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 60/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 4.8876e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.8614e-06 - acc: 1.0000 - val_loss: 8.1920e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 61/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 4.8800e-06 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.7465e-06 - acc: 1.0000 - val_loss: 8.0066e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 62/150\n",
      "62/66 [===========================>..] - ETA: 0s - loss: 4.6810e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.6414e-06 - acc: 1.0000 - val_loss: 7.8334e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 63/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 4.4769e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.5421e-06 - acc: 1.0000 - val_loss: 7.6490e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 64/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 3.4752e-06 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.4620e-06 - acc: 1.0000 - val_loss: 7.5461e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 65/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 4.4996e-06 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.3664e-06 - acc: 1.0000 - val_loss: 7.3393e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 4.2364e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.2497e-06 - acc: 1.0000 - val_loss: 7.1779e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 4.2514e-06 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.1616e-06 - acc: 1.0000 - val_loss: 7.0078e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 3.8803e-06 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 4.0643e-06 - acc: 1.0000 - val_loss: 6.8483e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 4.0193e-06 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.9690e-06 - acc: 1.0000 - val_loss: 6.6665e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 4.1850e-06 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.8826e-06 - acc: 1.0000 - val_loss: 6.5117e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/150\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 3.8639e-06 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.7997e-06 - acc: 1.0000 - val_loss: 6.3548e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 3.7408e-06 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.6984e-06 - acc: 1.0000 - val_loss: 6.1969e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 4.0029e-06 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.6099e-06 - acc: 1.0000 - val_loss: 6.0410e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 3.7367e-06 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.5293e-06 - acc: 1.0000 - val_loss: 5.8958e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 3.2292e-06 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.4416e-06 - acc: 1.0000 - val_loss: 5.7364e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 3.3419e-06 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.3594e-06 - acc: 1.0000 - val_loss: 5.6045e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 3.3278e-06 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.2844e-06 - acc: 1.0000 - val_loss: 5.4466e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 3.3586e-06 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.2095e-06 - acc: 1.0000 - val_loss: 5.3325e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 3.1052e-06 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.1254e-06 - acc: 1.0000 - val_loss: 5.1924e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 2.7746e-06 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 3.0542e-06 - acc: 1.0000 - val_loss: 5.0452e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 2.8549e-06 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.9615e-06 - acc: 1.0000 - val_loss: 4.9031e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 2.9230e-06 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.8985e-06 - acc: 1.0000 - val_loss: 4.7727e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/150\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 2.6238e-06 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.8247e-06 - acc: 1.0000 - val_loss: 4.6856e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 2.7451e-06 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.7432e-06 - acc: 1.0000 - val_loss: 4.5241e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 2.8848e-06 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.6666e-06 - acc: 1.0000 - val_loss: 4.3932e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 2.4177e-06 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.6079e-06 - acc: 1.0000 - val_loss: 4.2689e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 2.6915e-06 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.5309e-06 - acc: 1.0000 - val_loss: 4.1431e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 2.5581e-06 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.4673e-06 - acc: 1.0000 - val_loss: 4.0381e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/150\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 2.3914e-06 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.3995e-06 - acc: 1.0000 - val_loss: 3.9393e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 2.2858e-06 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.3396e-06 - acc: 1.0000 - val_loss: 3.8130e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 2.3123e-06 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.2737e-06 - acc: 1.0000 - val_loss: 3.6938e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 2.1323e-06 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.2144e-06 - acc: 1.0000 - val_loss: 3.5975e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 2.1594e-06 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.1547e-06 - acc: 1.0000 - val_loss: 3.4758e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 2.1157e-06 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 2.1021e-06 - acc: 1.0000 - val_loss: 3.3678e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 2.1564e-06 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 2.0429e-06 - acc: 1.0000 - val_loss: 3.2761e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 1.9132e-06 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.9819e-06 - acc: 1.0000 - val_loss: 3.1793e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 2.0365e-06 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.9355e-06 - acc: 1.0000 - val_loss: 3.0897e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/150\n",
      "58/66 [=========================>....] - ETA: 0s - loss: 1.8870e-06 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.8768e-06 - acc: 1.0000 - val_loss: 3.0143e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.9217e-06 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.8284e-06 - acc: 1.0000 - val_loss: 2.9078e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 1.6963e-06 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.7789e-06 - acc: 1.0000 - val_loss: 2.8207e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 1.7496e-06 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.7274e-06 - acc: 1.0000 - val_loss: 2.7417e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.7348e-06 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6855e-06 - acc: 1.0000 - val_loss: 2.6989e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 103/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 1.8279e-06 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6625e-06 - acc: 1.0000 - val_loss: 2.6511e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 104/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 1.7224e-06 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6404e-06 - acc: 1.0000 - val_loss: 2.6123e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 105/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.4687e-06 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.6152e-06 - acc: 1.0000 - val_loss: 2.5721e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 106/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 1.6243e-06 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5912e-06 - acc: 1.0000 - val_loss: 2.5242e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 107/150\n",
      "55/66 [========================>.....] - ETA: 0s - loss: 1.5508e-06 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5680e-06 - acc: 1.0000 - val_loss: 2.4855e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 108/150\n",
      "57/66 [========================>.....] - ETA: 0s - loss: 1.4134e-06 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5450e-06 - acc: 1.0000 - val_loss: 2.4381e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 109/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 1.5364e-06 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.5171e-06 - acc: 1.0000 - val_loss: 2.4060e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 110/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 1.3927e-06 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4927e-06 - acc: 1.0000 - val_loss: 2.3663e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 111/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.5580e-06 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4682e-06 - acc: 1.0000 - val_loss: 2.3194e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 112/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.4473e-06 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4473e-06 - acc: 1.0000 - val_loss: 2.2746e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 113/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 1.2700e-06 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.4205e-06 - acc: 1.0000 - val_loss: 2.2308e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 114/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 1.3999e-06 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3957e-06 - acc: 1.0000 - val_loss: 2.1961e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 115/150\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 1.3629e-06 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3729e-06 - acc: 1.0000 - val_loss: 2.1508e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/150\n",
      "62/66 [===========================>..] - ETA: 0s - loss: 1.2858e-06 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3483e-06 - acc: 1.0000 - val_loss: 2.1146e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/150\n",
      "57/66 [========================>.....] - ETA: 0s - loss: 1.4007e-06 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3262e-06 - acc: 1.0000 - val_loss: 2.0713e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.3975e-06 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.3006e-06 - acc: 1.0000 - val_loss: 2.0280e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.2766e-06 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2766e-06 - acc: 1.0000 - val_loss: 1.9888e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/150\n",
      "66/66 [==============================] - ETA: 0s - loss: 1.2569e-06 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2569e-06 - acc: 1.0000 - val_loss: 1.9409e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 1.2441e-06 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2326e-06 - acc: 1.0000 - val_loss: 1.9053e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.0843e-06 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.2076e-06 - acc: 1.0000 - val_loss: 1.8625e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 1.1974e-06 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1862e-06 - acc: 1.0000 - val_loss: 1.8390e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 1.1519e-06 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1592e-06 - acc: 1.0000 - val_loss: 1.7968e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/150\n",
      "47/66 [====================>.........] - ETA: 0s - loss: 1.2460e-06 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1317e-06 - acc: 1.0000 - val_loss: 1.7540e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 1.0830e-06 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.1066e-06 - acc: 1.0000 - val_loss: 1.7137e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 1.1027e-06 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0865e-06 - acc: 1.0000 - val_loss: 1.6791e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/150\n",
      "54/66 [=======================>......] - ETA: 0s - loss: 1.0528e-06 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0654e-06 - acc: 1.0000 - val_loss: 1.6450e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/150\n",
      "51/66 [======================>.......] - ETA: 0s - loss: 1.0516e-06 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0422e-06 - acc: 1.0000 - val_loss: 1.5981e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/150\n",
      "57/66 [========================>.....] - ETA: 0s - loss: 9.9698e-07 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 1.0197e-06 - acc: 1.0000 - val_loss: 1.5721e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/150\n",
      "57/66 [========================>.....] - ETA: 0s - loss: 9.8901e-07 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.9529e-07 - acc: 1.0000 - val_loss: 1.5288e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 9.5172e-07 - acc: 1.0000\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.7665e-07 - acc: 1.0000 - val_loss: 1.4901e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 133/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 9.3465e-07 - acc: 1.0000\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.5745e-07 - acc: 1.0000 - val_loss: 1.4641e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 134/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 9.5090e-07 - acc: 1.0000\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.3382e-07 - acc: 1.0000 - val_loss: 1.4259e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 9.5683e-07 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 9.1195e-07 - acc: 1.0000 - val_loss: 1.3877e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 8.3644e-07 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.9241e-07 - acc: 1.0000 - val_loss: 1.3515e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 8.8497e-07 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.6980e-07 - acc: 1.0000 - val_loss: 1.3301e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/150\n",
      "52/66 [======================>.......] - ETA: 0s - loss: 8.9534e-07 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 3ms/step - loss: 8.4980e-07 - acc: 1.0000 - val_loss: 1.2991e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/150\n",
      "60/66 [==========================>...] - ETA: 0s - loss: 8.4451e-07 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.3298e-07 - acc: 1.0000 - val_loss: 1.2552e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 8.6089e-07 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 8.1649e-07 - acc: 1.0000 - val_loss: 1.2298e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/150\n",
      "61/66 [==========================>...] - ETA: 0s - loss: 7.8608e-07 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.9309e-07 - acc: 1.0000 - val_loss: 1.1992e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 7.4656e-07 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.7360e-07 - acc: 1.0000 - val_loss: 1.1651e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 7.6573e-07 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.5796e-07 - acc: 1.0000 - val_loss: 1.1381e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/150\n",
      "59/66 [=========================>....] - ETA: 0s - loss: 7.0388e-07 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.3575e-07 - acc: 1.0000 - val_loss: 1.1070e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/150\n",
      "64/66 [============================>.] - ETA: 0s - loss: 7.3381e-07 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.1802e-07 - acc: 1.0000 - val_loss: 1.0775e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/150\n",
      "63/66 [===========================>..] - ETA: 0s - loss: 6.8958e-07 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 7.0227e-07 - acc: 1.0000 - val_loss: 1.0530e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/150\n",
      "56/66 [========================>.....] - ETA: 0s - loss: 6.3555e-07 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.8391e-07 - acc: 1.0000 - val_loss: 1.0301e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/150\n",
      "53/66 [=======================>......] - ETA: 0s - loss: 6.0595e-07 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.6550e-07 - acc: 1.0000 - val_loss: 9.9697e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/150\n",
      "65/66 [============================>.] - ETA: 0s - loss: 6.5547e-07 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.4907e-07 - acc: 1.0000 - val_loss: 9.6691e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/150\n",
      "50/66 [=====================>........] - ETA: 0s - loss: 6.3090e-07 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 0s 4ms/step - loss: 6.3252e-07 - acc: 1.0000 - val_loss: 9.4042e-07 - val_acc: 1.0000 - lr: 2.5000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=150,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(f'../models/data_{check_data_version}_train_{version}_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'../readme_img/data_{check_data_version}_train_{version}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[183,   0],\n",
       "        [  0,  51]],\n",
       "\n",
       "       [[197,   0],\n",
       "        [  0,  37]],\n",
       "\n",
       "       [[186,   0],\n",
       "        [  0,  48]],\n",
       "\n",
       "       [[193,   0],\n",
       "        [  0,  41]],\n",
       "\n",
       "       [[177,   0],\n",
       "        [  0,  57]]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(f'../models/data_{check_data_version}_train_{version}_model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
