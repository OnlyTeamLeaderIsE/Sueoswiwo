{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "version = '1.0.0'\n",
    "check_data_version = '1.0.8'\n",
    "\n",
    "\n",
    "with open(f'../create_dataset/v{check_data_version}/label.json', 'r', encoding='utf-8') as file:\n",
    "    label = json.load(file)\n",
    "    \n",
    "word_count = label['label_count'] * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 10, 37)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = f'../create_dataset/v{check_data_version}/data'\n",
    "data_files_list = os.listdir(data_dir)\n",
    "\n",
    "\n",
    "data_files_list.sort()\n",
    "\n",
    "\n",
    "data = np.concatenate([\n",
    "    np.load(f'{data_dir}/{file}') for file in data_files_list\n",
    "], axis=0)\n",
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7886, 10, 36)\n",
      "(7886,)\n",
      "-1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 -1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 1.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 3.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 5.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 7.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 9.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 11.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 13.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0 15.0\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)\n",
    "print(*labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7886, 17)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=word_count)\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7097, 10, 36) (7097, 17)\n",
      "(789, 10, 36) (789, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "time_stamp = 1\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_5 (LSTM)               (None, 64)                25856     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 17)                561       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28497 (111.32 KB)\n",
      "Trainable params: 28497 (111.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3], return_sequences=False),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(word_count, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_data_version = check_data_version.replace('.', '')\n",
    "version = version.replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 8.3200 - acc: 0.6364\n",
      "Epoch 1: val_acc improved from -inf to 0.90875, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 2s 4ms/step - loss: 8.1174 - acc: 0.6434 - val_loss: 0.3871 - val_acc: 0.9087 - lr: 0.0010\n",
      "Epoch 2/200\n",
      " 61/222 [=======>......................] - ETA: 0s - loss: 0.2137 - acc: 0.9503"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PYTHON\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/222 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9606\n",
      "Epoch 2: val_acc improved from 0.90875 to 0.97085, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.1994 - acc: 0.9607 - val_loss: 0.1249 - val_acc: 0.9708 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9867\n",
      "Epoch 3: val_acc improved from 0.97085 to 0.98859, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0611 - acc: 0.9866 - val_loss: 0.0500 - val_acc: 0.9886 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 0.0163 - acc: 0.9971\n",
      "Epoch 4: val_acc improved from 0.98859 to 0.99747, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0154 - acc: 0.9973 - val_loss: 0.0149 - val_acc: 0.9975 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 5: val_acc improved from 0.99747 to 0.99873, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0085 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 6: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0018 - acc: 0.9999 - val_loss: 0.0080 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 9.5796e-04 - acc: 1.0000\n",
      "Epoch 7: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.6098e-04 - acc: 1.0000 - val_loss: 0.0074 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 6.3672e-04 - acc: 1.0000\n",
      "Epoch 8: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.3672e-04 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 4.7683e-04 - acc: 1.0000\n",
      "Epoch 9: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.8339e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 4.2591e-04 - acc: 1.0000\n",
      "Epoch 10: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.2207e-04 - acc: 1.0000 - val_loss: 0.0067 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 3.2483e-04 - acc: 1.0000\n",
      "Epoch 11: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.2316e-04 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 0.0417 - acc: 0.9944  \n",
      "Epoch 12: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.2624 - acc: 0.9822 - val_loss: 1.8325 - val_acc: 0.8200 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 1.1762 - acc: 0.8780\n",
      "Epoch 13: val_acc did not improve from 0.99873\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1668 - acc: 0.8790 - val_loss: 0.0111 - val_acc: 0.9987 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 0.0061 - acc: 0.9994\n",
      "Epoch 14: val_acc improved from 0.99873 to 1.00000, saving model to ../models\\data_108_train_100_model.h5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0059 - acc: 0.9994 - val_loss: 0.0035 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 15: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0029 - acc: 0.9999 - val_loss: 0.0019 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9996\n",
      "Epoch 16: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0039 - acc: 0.9996 - val_loss: 0.0014 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 17: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 9.7815e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 7.8758e-04 - acc: 1.0000\n",
      "Epoch 18: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.8057e-04 - acc: 1.0000 - val_loss: 7.6015e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 6.0428e-04 - acc: 1.0000\n",
      "Epoch 19: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.0320e-04 - acc: 1.0000 - val_loss: 6.2718e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 4.8144e-04 - acc: 1.0000\n",
      "Epoch 20: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.8114e-04 - acc: 1.0000 - val_loss: 5.2324e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 3.9529e-04 - acc: 1.0000\n",
      "Epoch 21: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9229e-04 - acc: 1.0000 - val_loss: 4.2881e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 3.2712e-04 - acc: 1.0000\n",
      "Epoch 22: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.2517e-04 - acc: 1.0000 - val_loss: 3.6479e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 2.7214e-04 - acc: 1.0000\n",
      "Epoch 23: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.7214e-04 - acc: 1.0000 - val_loss: 3.1827e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 2.3152e-04 - acc: 1.0000\n",
      "Epoch 24: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2874e-04 - acc: 1.0000 - val_loss: 2.7361e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 1.9312e-04 - acc: 1.0000\n",
      "Epoch 25: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9323e-04 - acc: 1.0000 - val_loss: 2.3728e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.6475e-04 - acc: 1.0000\n",
      "Epoch 26: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6433e-04 - acc: 1.0000 - val_loss: 2.0789e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.4075e-04 - acc: 1.0000\n",
      "Epoch 27: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4099e-04 - acc: 1.0000 - val_loss: 1.7955e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.2265e-04 - acc: 1.0000\n",
      "Epoch 28: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2194e-04 - acc: 1.0000 - val_loss: 1.5524e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.0711e-04 - acc: 1.0000\n",
      "Epoch 29: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0592e-04 - acc: 1.0000 - val_loss: 1.3700e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 9.2504e-05 - acc: 1.0000\n",
      "Epoch 30: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.2276e-05 - acc: 1.0000 - val_loss: 1.1941e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 8.0953e-05 - acc: 1.0000\n",
      "Epoch 31: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.0700e-05 - acc: 1.0000 - val_loss: 1.0643e-04 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 7.0672e-05 - acc: 1.0000\n",
      "Epoch 32: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.0714e-05 - acc: 1.0000 - val_loss: 9.4132e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 6.2040e-05 - acc: 1.0000\n",
      "Epoch 33: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.2040e-05 - acc: 1.0000 - val_loss: 8.5325e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 5.3924e-05 - acc: 1.0000\n",
      "Epoch 34: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.4592e-05 - acc: 1.0000 - val_loss: 7.8539e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 4.8053e-05 - acc: 1.0000\n",
      "Epoch 35: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.8088e-05 - acc: 1.0000 - val_loss: 7.0764e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 4.2634e-05 - acc: 1.0000\n",
      "Epoch 36: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.2428e-05 - acc: 1.0000 - val_loss: 6.2936e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 3.7600e-05 - acc: 1.0000\n",
      "Epoch 37: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.7384e-05 - acc: 1.0000 - val_loss: 5.8252e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 3.3322e-05 - acc: 1.0000\n",
      "Epoch 38: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.2915e-05 - acc: 1.0000 - val_loss: 5.3646e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 2.9469e-05 - acc: 1.0000\n",
      "Epoch 39: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9086e-05 - acc: 1.0000 - val_loss: 4.8674e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 2.5663e-05 - acc: 1.0000\n",
      "Epoch 40: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5709e-05 - acc: 1.0000 - val_loss: 4.5240e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 2.2513e-05 - acc: 1.0000\n",
      "Epoch 41: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2712e-05 - acc: 1.0000 - val_loss: 4.1189e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 2.0492e-05 - acc: 1.0000\n",
      "Epoch 42: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0125e-05 - acc: 1.0000 - val_loss: 3.8664e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.7555e-05 - acc: 1.0000\n",
      "Epoch 43: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7768e-05 - acc: 1.0000 - val_loss: 3.9102e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.5778e-05 - acc: 1.0000\n",
      "Epoch 44: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5734e-05 - acc: 1.0000 - val_loss: 3.7757e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.3931e-05 - acc: 1.0000\n",
      "Epoch 45: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3912e-05 - acc: 1.0000 - val_loss: 3.3330e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.2445e-05 - acc: 1.0000\n",
      "Epoch 46: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2292e-05 - acc: 1.0000 - val_loss: 3.3463e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 1.0846e-05 - acc: 1.0000\n",
      "Epoch 47: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0880e-05 - acc: 1.0000 - val_loss: 3.3285e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 9.5941e-06 - acc: 1.0000\n",
      "Epoch 48: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.5941e-06 - acc: 1.0000 - val_loss: 3.3438e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 8.3842e-06 - acc: 1.0000\n",
      "Epoch 49: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.4821e-06 - acc: 1.0000 - val_loss: 3.0951e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 7.5023e-06 - acc: 1.0000\n",
      "Epoch 50: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.4906e-06 - acc: 1.0000 - val_loss: 3.0617e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 6.6389e-06 - acc: 1.0000\n",
      "Epoch 51: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.5989e-06 - acc: 1.0000 - val_loss: 3.0611e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 5.8818e-06 - acc: 1.0000\n",
      "Epoch 52: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.8344e-06 - acc: 1.0000 - val_loss: 3.1508e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 5.2160e-06 - acc: 1.0000\n",
      "Epoch 53: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.1642e-06 - acc: 1.0000 - val_loss: 3.6403e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 4.6164e-06 - acc: 1.0000\n",
      "Epoch 54: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5672e-06 - acc: 1.0000 - val_loss: 3.2476e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 4.1323e-06 - acc: 1.0000\n",
      "Epoch 55: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.0698e-06 - acc: 1.0000 - val_loss: 3.4022e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 3.5503e-06 - acc: 1.0000\n",
      "Epoch 56: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.5815e-06 - acc: 1.0000 - val_loss: 4.3353e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 3.2176e-06 - acc: 1.0000\n",
      "Epoch 57: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.1883e-06 - acc: 1.0000 - val_loss: 4.9119e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 2.8677e-06 - acc: 1.0000\n",
      "Epoch 58: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8291e-06 - acc: 1.0000 - val_loss: 3.4163e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 2.5064e-06 - acc: 1.0000\n",
      "Epoch 59: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5090e-06 - acc: 1.0000 - val_loss: 3.7584e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 2.2652e-06 - acc: 1.0000\n",
      "Epoch 60: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2278e-06 - acc: 1.0000 - val_loss: 4.7102e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 1.9922e-06 - acc: 1.0000\n",
      "Epoch 61: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9797e-06 - acc: 1.0000 - val_loss: 3.9554e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 1.7583e-06 - acc: 1.0000\n",
      "Epoch 62: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7561e-06 - acc: 1.0000 - val_loss: 2.8187e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.5720e-06 - acc: 1.0000\n",
      "Epoch 63: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5987e-06 - acc: 1.0000 - val_loss: 3.5660e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 1.3931e-06 - acc: 1.0000\n",
      "Epoch 64: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3938e-06 - acc: 1.0000 - val_loss: 5.6560e-05 - val_acc: 1.0000 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.2620e-06 - acc: 1.0000\n",
      "Epoch 65: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2776e-06 - acc: 1.0000 - val_loss: 4.1886e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 66/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 1.1900e-06 - acc: 1.0000\n",
      "Epoch 66: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1912e-06 - acc: 1.0000 - val_loss: 4.1470e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 67/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 1.1188e-06 - acc: 1.0000\n",
      "Epoch 67: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1196e-06 - acc: 1.0000 - val_loss: 4.5258e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 68/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 1.0134e-06 - acc: 1.0000\n",
      "Epoch 68: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0445e-06 - acc: 1.0000 - val_loss: 4.2284e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 69/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 9.7894e-07 - acc: 1.0000\n",
      "Epoch 69: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.7651e-07 - acc: 1.0000 - val_loss: 6.7998e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 70/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 9.1456e-07 - acc: 1.0000\n",
      "Epoch 70: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.0751e-07 - acc: 1.0000 - val_loss: 5.4527e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 71/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 8.4721e-07 - acc: 1.0000\n",
      "Epoch 71: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.3525e-07 - acc: 1.0000 - val_loss: 5.4056e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 72/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 7.6974e-07 - acc: 1.0000\n",
      "Epoch 72: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.6974e-07 - acc: 1.0000 - val_loss: 5.2387e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 73/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 7.2022e-07 - acc: 1.0000\n",
      "Epoch 73: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.1018e-07 - acc: 1.0000 - val_loss: 5.4804e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 74/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 6.5629e-07 - acc: 1.0000\n",
      "Epoch 74: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.5635e-07 - acc: 1.0000 - val_loss: 2.8166e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 75/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 5.9594e-07 - acc: 1.0000\n",
      "Epoch 75: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.9737e-07 - acc: 1.0000 - val_loss: 4.2458e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 76/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.4534e-07 - acc: 1.0000\n",
      "Epoch 76: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.4342e-07 - acc: 1.0000 - val_loss: 4.9337e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 77/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.0006e-07 - acc: 1.0000\n",
      "Epoch 77: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.9335e-07 - acc: 1.0000 - val_loss: 4.3356e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 78/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 4.5265e-07 - acc: 1.0000\n",
      "Epoch 78: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5001e-07 - acc: 1.0000 - val_loss: 6.8466e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 79/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 4.0722e-07 - acc: 1.0000\n",
      "Epoch 79: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.0617e-07 - acc: 1.0000 - val_loss: 3.2492e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 80/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.7515e-07 - acc: 1.0000\n",
      "Epoch 80: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.7515e-07 - acc: 1.0000 - val_loss: 5.1382e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 81/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 3.3713e-07 - acc: 1.0000\n",
      "Epoch 81: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.3159e-07 - acc: 1.0000 - val_loss: 5.1349e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 82/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 2.9861e-07 - acc: 1.0000\n",
      "Epoch 82: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9850e-07 - acc: 1.0000 - val_loss: 5.2566e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 83/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 2.7085e-07 - acc: 1.0000\n",
      "Epoch 83: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.6828e-07 - acc: 1.0000 - val_loss: 4.7175e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 84/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 2.4380e-07 - acc: 1.0000\n",
      "Epoch 84: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.4472e-07 - acc: 1.0000 - val_loss: 6.9108e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 85/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 2.2260e-07 - acc: 1.0000\n",
      "Epoch 85: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.1912e-07 - acc: 1.0000 - val_loss: 9.0449e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 86/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 2.0103e-07 - acc: 1.0000\n",
      "Epoch 86: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9879e-07 - acc: 1.0000 - val_loss: 2.5951e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 87/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.7507e-07 - acc: 1.0000\n",
      "Epoch 87: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7469e-07 - acc: 1.0000 - val_loss: 3.4635e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 88/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.5585e-07 - acc: 1.0000\n",
      "Epoch 88: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5527e-07 - acc: 1.0000 - val_loss: 4.0605e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 1.3753e-07 - acc: 1.0000\n",
      "Epoch 89: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3910e-07 - acc: 1.0000 - val_loss: 6.7024e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 1.2170e-07 - acc: 1.0000\n",
      "Epoch 90: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2348e-07 - acc: 1.0000 - val_loss: 4.0743e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 1.1127e-07 - acc: 1.0000\n",
      "Epoch 91: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0930e-07 - acc: 1.0000 - val_loss: 5.0929e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 9.8656e-08 - acc: 1.0000\n",
      "Epoch 92: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.6718e-08 - acc: 1.0000 - val_loss: 4.3871e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "213/222 [===========================>..] - ETA: 0s - loss: 8.5752e-08 - acc: 1.0000\n",
      "Epoch 93: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.6287e-08 - acc: 1.0000 - val_loss: 4.8582e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 7.8159e-08 - acc: 1.0000\n",
      "Epoch 94: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.7418e-08 - acc: 1.0000 - val_loss: 5.0749e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 7.1166e-08 - acc: 1.0000\n",
      "Epoch 95: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.9204e-08 - acc: 1.0000 - val_loss: 6.7026e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 6.2390e-08 - acc: 1.0000\n",
      "Epoch 96: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.2015e-08 - acc: 1.0000 - val_loss: 4.2357e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.5680e-08 - acc: 1.0000\n",
      "Epoch 97: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.5531e-08 - acc: 1.0000 - val_loss: 6.7524e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 98/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.0852e-08 - acc: 1.0000\n",
      "Epoch 98: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.0190e-08 - acc: 1.0000 - val_loss: 3.7107e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 4.4342e-08 - acc: 1.0000\n",
      "Epoch 99: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.3757e-08 - acc: 1.0000 - val_loss: 2.9931e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 4.0562e-08 - acc: 1.0000\n",
      "Epoch 100: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9624e-08 - acc: 1.0000 - val_loss: 4.0114e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 3.5442e-08 - acc: 1.0000\n",
      "Epoch 101: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.4972e-08 - acc: 1.0000 - val_loss: 4.0276e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.1108e-08 - acc: 1.0000\n",
      "Epoch 102: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.1108e-08 - acc: 1.0000 - val_loss: 4.4086e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 2.7259e-08 - acc: 1.0000\n",
      "Epoch 103: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.7396e-08 - acc: 1.0000 - val_loss: 5.0306e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 2.5028e-08 - acc: 1.0000\n",
      "Epoch 104: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.4490e-08 - acc: 1.0000 - val_loss: 3.2441e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 2.1301e-08 - acc: 1.0000\n",
      "Epoch 105: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.1114e-08 - acc: 1.0000 - val_loss: 3.8364e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 1.8391e-08 - acc: 1.0000\n",
      "Epoch 106: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.8628e-08 - acc: 1.0000 - val_loss: 4.3808e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.6845e-08 - acc: 1.0000\n",
      "Epoch 107: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6797e-08 - acc: 1.0000 - val_loss: 4.8104e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 1.4952e-08 - acc: 1.0000\n",
      "Epoch 108: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4983e-08 - acc: 1.0000 - val_loss: 3.7049e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 1.3438e-08 - acc: 1.0000\n",
      "Epoch 109: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3438e-08 - acc: 1.0000 - val_loss: 3.1404e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.2215e-08 - acc: 1.0000\n",
      "Epoch 110: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2212e-08 - acc: 1.0000 - val_loss: 4.4797e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 1.1349e-08 - acc: 1.0000\n",
      "Epoch 111: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1321e-08 - acc: 1.0000 - val_loss: 4.7983e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 9.8277e-09 - acc: 1.0000\n",
      "Epoch 112: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.7255e-09 - acc: 1.0000 - val_loss: 3.5281e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 9.2673e-09 - acc: 1.0000\n",
      "Epoch 113: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.7759e-09 - acc: 1.0000 - val_loss: 4.8037e-05 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.0726e-08 - acc: 1.0000\n",
      "Epoch 114: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0448e-08 - acc: 1.0000 - val_loss: 6.4630e-06 - val_acc: 1.0000 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "216/222 [============================>.] - ETA: 0s - loss: 7.9852e-09 - acc: 1.0000\n",
      "Epoch 115: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.8611e-09 - acc: 1.0000 - val_loss: 1.6279e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 116/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 6.8236e-09 - acc: 1.0000\n",
      "Epoch 116: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.7189e-09 - acc: 1.0000 - val_loss: 1.6125e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 117/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 6.6288e-09 - acc: 1.0000\n",
      "Epoch 117: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.6181e-09 - acc: 1.0000 - val_loss: 1.6929e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 118/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 6.4129e-09 - acc: 1.0000\n",
      "Epoch 118: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.3997e-09 - acc: 1.0000 - val_loss: 2.7858e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 119/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 5.9798e-09 - acc: 1.0000\n",
      "Epoch 119: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.9798e-09 - acc: 1.0000 - val_loss: 1.7037e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 120/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 6.1024e-09 - acc: 1.0000\n",
      "Epoch 120: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.9294e-09 - acc: 1.0000 - val_loss: 1.5032e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 121/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.4433e-09 - acc: 1.0000\n",
      "Epoch 121: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7110e-09 - acc: 1.0000 - val_loss: 2.6451e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 122/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 5.3919e-09 - acc: 1.0000\n",
      "Epoch 122: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.3919e-09 - acc: 1.0000 - val_loss: 2.4924e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 123/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 5.0816e-09 - acc: 1.0000\n",
      "Epoch 123: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.1399e-09 - acc: 1.0000 - val_loss: 1.1320e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 124/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 4.5794e-09 - acc: 1.0000\n",
      "Epoch 124: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.7368e-09 - acc: 1.0000 - val_loss: 2.3384e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 125/200\n",
      "217/222 [============================>.] - ETA: 0s - loss: 4.6695e-09 - acc: 1.0000\n",
      "Epoch 125: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.7704e-09 - acc: 1.0000 - val_loss: 2.4564e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 126/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 4.2292e-09 - acc: 1.0000\n",
      "Epoch 126: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.2161e-09 - acc: 1.0000 - val_loss: 1.7367e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 127/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 4.3107e-09 - acc: 1.0000\n",
      "Epoch 127: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.3169e-09 - acc: 1.0000 - val_loss: 3.5287e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 128/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 3.8954e-09 - acc: 1.0000\n",
      "Epoch 128: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9473e-09 - acc: 1.0000 - val_loss: 6.2395e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 129/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 3.4553e-09 - acc: 1.0000\n",
      "Epoch 129: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.8801e-09 - acc: 1.0000 - val_loss: 1.9806e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 130/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.7290e-09 - acc: 1.0000\n",
      "Epoch 130: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.7290e-09 - acc: 1.0000 - val_loss: 2.5770e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 131/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 3.8312e-09 - acc: 1.0000\n",
      "Epoch 131: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.6954e-09 - acc: 1.0000 - val_loss: 6.2604e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 132/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 0.0715 - acc: 0.9881\n",
      "Epoch 132: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0684 - acc: 0.9886 - val_loss: 0.0117 - val_acc: 0.9987 - lr: 2.5000e-04\n",
      "Epoch 133/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 133: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0069 - val_acc: 0.9987 - lr: 2.5000e-04\n",
      "Epoch 134/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 134: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 4.3433e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 135/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 5.6820e-05 - acc: 1.0000\n",
      "Epoch 135: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.6090e-05 - acc: 1.0000 - val_loss: 3.2896e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 136/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 3.9332e-05 - acc: 1.0000\n",
      "Epoch 136: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9191e-05 - acc: 1.0000 - val_loss: 2.7088e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 137/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 2.8456e-05 - acc: 1.0000\n",
      "Epoch 137: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9267e-05 - acc: 1.0000 - val_loss: 2.3817e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 138/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 2.4527e-05 - acc: 1.0000\n",
      "Epoch 138: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3553e-05 - acc: 1.0000 - val_loss: 2.1229e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 139/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 1.9829e-05 - acc: 1.0000\n",
      "Epoch 139: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9482e-05 - acc: 1.0000 - val_loss: 1.8797e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 140/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.6102e-05 - acc: 1.0000\n",
      "Epoch 140: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6321e-05 - acc: 1.0000 - val_loss: 1.6777e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 141/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.4078e-05 - acc: 1.0000\n",
      "Epoch 141: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3790e-05 - acc: 1.0000 - val_loss: 1.4774e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 142/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 1.1608e-05 - acc: 1.0000\n",
      "Epoch 142: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1714e-05 - acc: 1.0000 - val_loss: 1.3063e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 143/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.0366e-05 - acc: 1.0000\n",
      "Epoch 143: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0020e-05 - acc: 1.0000 - val_loss: 1.1537e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 144/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 8.6657e-06 - acc: 1.0000\n",
      "Epoch 144: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.6235e-06 - acc: 1.0000 - val_loss: 1.0157e-05 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 145/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 7.4845e-06 - acc: 1.0000\n",
      "Epoch 145: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.4692e-06 - acc: 1.0000 - val_loss: 9.1011e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 146/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 6.5138e-06 - acc: 1.0000\n",
      "Epoch 146: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.5345e-06 - acc: 1.0000 - val_loss: 8.2019e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 147/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 5.3820e-06 - acc: 1.0000\n",
      "Epoch 147: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7662e-06 - acc: 1.0000 - val_loss: 7.5996e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 148/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 5.1292e-06 - acc: 1.0000\n",
      "Epoch 148: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.1097e-06 - acc: 1.0000 - val_loss: 6.7209e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 149/200\n",
      "212/222 [===========================>..] - ETA: 0s - loss: 4.5232e-06 - acc: 1.0000\n",
      "Epoch 149: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5693e-06 - acc: 1.0000 - val_loss: 6.1724e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 150/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 4.1625e-06 - acc: 1.0000\n",
      "Epoch 150: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.1246e-06 - acc: 1.0000 - val_loss: 5.6841e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 151/200\n",
      "222/222 [==============================] - ETA: 0s - loss: 3.7298e-06 - acc: 1.0000\n",
      "Epoch 151: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.7298e-06 - acc: 1.0000 - val_loss: 5.2794e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 152/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 3.4189e-06 - acc: 1.0000\n",
      "Epoch 152: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.4158e-06 - acc: 1.0000 - val_loss: 4.8948e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 153/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 3.1978e-06 - acc: 1.0000\n",
      "Epoch 153: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.1491e-06 - acc: 1.0000 - val_loss: 4.5663e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 154/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 2.9113e-06 - acc: 1.0000\n",
      "Epoch 154: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.9183e-06 - acc: 1.0000 - val_loss: 4.2792e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 155/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 2.6343e-06 - acc: 1.0000\n",
      "Epoch 155: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.7169e-06 - acc: 1.0000 - val_loss: 3.9915e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 156/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 2.5855e-06 - acc: 1.0000\n",
      "Epoch 156: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5309e-06 - acc: 1.0000 - val_loss: 3.7346e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 157/200\n",
      "209/222 [===========================>..] - ETA: 0s - loss: 2.2881e-06 - acc: 1.0000\n",
      "Epoch 157: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3650e-06 - acc: 1.0000 - val_loss: 3.4891e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 158/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 2.2454e-06 - acc: 1.0000\n",
      "Epoch 158: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.2111e-06 - acc: 1.0000 - val_loss: 3.2775e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 159/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 2.0664e-06 - acc: 1.0000\n",
      "Epoch 159: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0645e-06 - acc: 1.0000 - val_loss: 3.0627e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 160/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 1.9726e-06 - acc: 1.0000\n",
      "Epoch 160: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.9251e-06 - acc: 1.0000 - val_loss: 2.8585e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 161/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 1.7614e-06 - acc: 1.0000\n",
      "Epoch 161: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.7941e-06 - acc: 1.0000 - val_loss: 2.6649e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 162/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.6710e-06 - acc: 1.0000\n",
      "Epoch 162: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6679e-06 - acc: 1.0000 - val_loss: 2.4961e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 163/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 1.6059e-06 - acc: 1.0000\n",
      "Epoch 163: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5513e-06 - acc: 1.0000 - val_loss: 2.3405e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 164/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 1.4607e-06 - acc: 1.0000\n",
      "Epoch 164: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 164: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4415e-06 - acc: 1.0000 - val_loss: 2.1761e-06 - val_acc: 1.0000 - lr: 2.5000e-04\n",
      "Epoch 165/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 1.3718e-06 - acc: 1.0000\n",
      "Epoch 165: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3479e-06 - acc: 1.0000 - val_loss: 2.0916e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 166/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.2895e-06 - acc: 1.0000\n",
      "Epoch 166: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2948e-06 - acc: 1.0000 - val_loss: 2.0113e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 167/200\n",
      "221/222 [============================>.] - ETA: 0s - loss: 1.2439e-06 - acc: 1.0000\n",
      "Epoch 167: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.2404e-06 - acc: 1.0000 - val_loss: 1.9280e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 168/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 1.2152e-06 - acc: 1.0000\n",
      "Epoch 168: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1815e-06 - acc: 1.0000 - val_loss: 1.8391e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 169/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 1.1107e-06 - acc: 1.0000\n",
      "Epoch 169: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1186e-06 - acc: 1.0000 - val_loss: 1.7508e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 170/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.0515e-06 - acc: 1.0000\n",
      "Epoch 170: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0583e-06 - acc: 1.0000 - val_loss: 1.6714e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 171/200\n",
      "220/222 [============================>.] - ETA: 0s - loss: 9.9612e-07 - acc: 1.0000\n",
      "Epoch 171: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.9637e-07 - acc: 1.0000 - val_loss: 1.6057e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 172/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 9.5404e-07 - acc: 1.0000\n",
      "Epoch 172: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.3751e-07 - acc: 1.0000 - val_loss: 1.5268e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 173/200\n",
      "210/222 [===========================>..] - ETA: 0s - loss: 8.9004e-07 - acc: 1.0000\n",
      "Epoch 173: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.7931e-07 - acc: 1.0000 - val_loss: 1.4707e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 174/200\n",
      "211/222 [===========================>..] - ETA: 0s - loss: 7.9337e-07 - acc: 1.0000\n",
      "Epoch 174: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 8.2420e-07 - acc: 1.0000 - val_loss: 1.4096e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 175/200\n",
      "215/222 [============================>.] - ETA: 0s - loss: 7.3705e-07 - acc: 1.0000\n",
      "Epoch 175: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.6977e-07 - acc: 1.0000 - val_loss: 1.3586e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 176/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 7.4173e-07 - acc: 1.0000\n",
      "Epoch 176: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 7.1767e-07 - acc: 1.0000 - val_loss: 1.3074e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 177/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 6.8822e-07 - acc: 1.0000\n",
      "Epoch 177: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.6619e-07 - acc: 1.0000 - val_loss: 1.2668e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 178/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 6.2347e-07 - acc: 1.0000\n",
      "Epoch 178: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 6.1912e-07 - acc: 1.0000 - val_loss: 1.1967e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 179/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 5.7318e-07 - acc: 1.0000\n",
      "Epoch 179: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.7549e-07 - acc: 1.0000 - val_loss: 1.1183e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 180/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 5.5486e-07 - acc: 1.0000\n",
      "Epoch 180: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 5.3346e-07 - acc: 1.0000 - val_loss: 1.0378e-06 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 181/200\n",
      "201/222 [==========================>...] - ETA: 0s - loss: 5.0837e-07 - acc: 1.0000\n",
      "Epoch 181: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.9337e-07 - acc: 1.0000 - val_loss: 9.9230e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 182/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 4.4100e-07 - acc: 1.0000\n",
      "Epoch 182: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.5625e-07 - acc: 1.0000 - val_loss: 9.4003e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 183/200\n",
      "214/222 [===========================>..] - ETA: 0s - loss: 4.2664e-07 - acc: 1.0000\n",
      "Epoch 183: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 4.2056e-07 - acc: 1.0000 - val_loss: 8.6600e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 184/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 3.9658e-07 - acc: 1.0000\n",
      "Epoch 184: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.9002e-07 - acc: 1.0000 - val_loss: 8.1252e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 185/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 3.5615e-07 - acc: 1.0000\n",
      "Epoch 185: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.5878e-07 - acc: 1.0000 - val_loss: 7.5572e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 186/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 3.4564e-07 - acc: 1.0000\n",
      "Epoch 186: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.3185e-07 - acc: 1.0000 - val_loss: 7.0314e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 187/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 3.2021e-07 - acc: 1.0000\n",
      "Epoch 187: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 3.0594e-07 - acc: 1.0000 - val_loss: 6.4966e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 188/200\n",
      "208/222 [===========================>..] - ETA: 0s - loss: 2.7311e-07 - acc: 1.0000\n",
      "Epoch 188: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.8313e-07 - acc: 1.0000 - val_loss: 5.8001e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 189/200\n",
      "205/222 [==========================>...] - ETA: 0s - loss: 2.6084e-07 - acc: 1.0000\n",
      "Epoch 189: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.5896e-07 - acc: 1.0000 - val_loss: 5.1263e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 190/200\n",
      "202/222 [==========================>...] - ETA: 0s - loss: 2.1387e-07 - acc: 1.0000\n",
      "Epoch 190: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.3845e-07 - acc: 1.0000 - val_loss: 4.8785e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 191/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 2.2037e-07 - acc: 1.0000\n",
      "Epoch 191: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.1908e-07 - acc: 1.0000 - val_loss: 4.5945e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 192/200\n",
      "200/222 [==========================>...] - ETA: 0s - loss: 1.6998e-07 - acc: 1.0000\n",
      "Epoch 192: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 2.0017e-07 - acc: 1.0000 - val_loss: 4.0687e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 193/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.8208e-07 - acc: 1.0000\n",
      "Epoch 193: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.8435e-07 - acc: 1.0000 - val_loss: 3.7167e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 194/200\n",
      "204/222 [==========================>...] - ETA: 0s - loss: 1.7127e-07 - acc: 1.0000\n",
      "Epoch 194: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.6903e-07 - acc: 1.0000 - val_loss: 3.5112e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 195/200\n",
      "206/222 [==========================>...] - ETA: 0s - loss: 1.5840e-07 - acc: 1.0000\n",
      "Epoch 195: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.5482e-07 - acc: 1.0000 - val_loss: 3.2620e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 196/200\n",
      "207/222 [==========================>...] - ETA: 0s - loss: 1.3729e-07 - acc: 1.0000\n",
      "Epoch 196: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.4272e-07 - acc: 1.0000 - val_loss: 2.8797e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 197/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.3120e-07 - acc: 1.0000\n",
      "Epoch 197: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.3033e-07 - acc: 1.0000 - val_loss: 2.8933e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 198/200\n",
      "218/222 [============================>.] - ETA: 0s - loss: 1.2095e-07 - acc: 1.0000\n",
      "Epoch 198: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.1934e-07 - acc: 1.0000 - val_loss: 2.4506e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 199/200\n",
      "203/222 [==========================>...] - ETA: 0s - loss: 1.0695e-07 - acc: 1.0000\n",
      "Epoch 199: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0985e-07 - acc: 1.0000 - val_loss: 2.3313e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n",
      "Epoch 200/200\n",
      "219/222 [============================>.] - ETA: 0s - loss: 1.0084e-07 - acc: 1.0000\n",
      "Epoch 200: val_acc did not improve from 1.00000\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 9.9875e-08 - acc: 1.0000 - val_loss: 1.8826e-07 - val_acc: 1.0000 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(f'../models/data_{check_data_version}_train_{version}_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.savefig(f'../readme_img/data_{check_data_version}_train_{version}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[697,   0],\n",
       "        [  0,  92]],\n",
       "\n",
       "       [[700,   0],\n",
       "        [  0,  89]],\n",
       "\n",
       "       [[686,   0],\n",
       "        [  0, 103]],\n",
       "\n",
       "       [[692,   0],\n",
       "        [  0,  97]],\n",
       "\n",
       "       [[698,   0],\n",
       "        [  0,  91]],\n",
       "\n",
       "       [[701,   0],\n",
       "        [  0,  88]],\n",
       "\n",
       "       [[702,   0],\n",
       "        [  0,  87]],\n",
       "\n",
       "       [[696,   0],\n",
       "        [  0,  93]],\n",
       "\n",
       "       [[740,   0],\n",
       "        [  0,  49]]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "model = load_model(f'../models/data_{check_data_version}_train_{version}_model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
